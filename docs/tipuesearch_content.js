var tipuesearch = {"pages":[{"title":"GitHub Page","text":"All course content (except Lectures 2-4, 12-13, and 15-17) is in: GitHub repo We suggest that you clone this repository.","tags":"pages","url":"pages/github.html"},{"title":"Modules Page","text":"Module description and details go here","tags":"pages","url":"pages/modules.html"},{"title":"Schedule","text":"Week Date Lecture (Mon) Date Lecture (Wed) Lab Advanced Section (Wed) Assignment (release and due) 1 28-Jan Lecture 1: Intro + Review of 109A Preview of 109B 30-Jan Lecture 2: Smoothing and Additive 1/3 Lab 1: Setting up enviroment 2 4-Feb Lecture 3: Smoothing and Additive 2/3 6-Feb Lecture 4: Smoothing and GAM 3/3 Lab 2: Smoothing/GAM HW1 (2/3) 3 11-Feb Lecture 5: Feed Forward + Reg + Review from NN fall 13-Feb Lecture 6: Optimization of NN (Solvers) Lab 3: Optimization Advanced Section 1: Optimization/Dropout HW2 (2/10) 4 18-Feb Holiday 20-Feb Lecture 7: AWS scalable systems SQL Lab 4: Setting UP AWS Advanced Section 2: Optimal Transport 5 25-Feb Lecture 8: CNNs-1 27-Feb Lecture 9: CNNs-2 Lab 5: CNNs Advanced Section 3: CNNs and Object Detection HW3 (2/24) 6 4-Mar Lecture 10: RNN 1 6-Mar Lecture 11: RNN 2 Lab 6: RNNS Advanced Section 4: RNNs HW4 (3/3) 7 11-Mar Lecture 12: Unsupervised learning/clustering 1 13-Mar Lecture 13: Unsupervised learning/clustering 2 Lab 7: Clusterig Advanced Section 5: Neural Style Transfer HW5 (3/10) 8 25-Mar Lecture 14: Reinforcement Learning 27-Mar Lecture 15: Bayesian 1/3 Lab 8: Bayes 1 Advanced Section 6: Deep RL 9 1-Apr Lecture 16: Bayesian 2/3 3-Apr Lecture 17: Bayesian 3/3 Lab 9: Bayes 2 HW6 (3/30) 10 8-Apr Lecture 18: Generative Models Varational Autoenders 1 10-Apr Lecture 19: Generative Models Varational Autoenders 2 Lab 10: VAE Advanced Section 7: Variational Inference HW7 (4/7) 11 15-Apr Lecture 20: GANS 17-Apr Lecture 21: GANS 2 Lab 11: Adveserial Networks Advanced Section 8: GANS","tags":"pages","url":"pages/schedule.html"},{"title":"Syllabus","text":"Course description Tentative Course Topics Course Objectives Course Components Lectures Labs In-class Quizzes Advanced Sections Exams Projects Homework Assignments Course Resources Online Materials Recommended Textbooks Getting Help Course Policies and Expectations Grading Collaboration Policy Late or Wrongly Submitted Assignments Re-grade Requests Auditing the Class Academic Integrity Accommodations for students with disabilities Diversity and Inclusion Statement Course description Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management, multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning. The programming language will be python. Tentative Course Topics Feed Forward Neural Networks Regularization of Neural Network Optimization of Neural Networks Autoencoders Convolutional Neural Networks Recurrent Neural Networks Variational AutoEncoders Generative Adversarial Networks Smoothing and Additive Models Unsupervised Learning Bayesian Inference Models, LDA SQL AWS Course Objectives Upon successful completion of this course, you should feel comfortable with the material mentioned above, plus you will have had experience in working with others on real-world problems. Both the content knowledge, the project, and teamwork, will prepare you for the professional world or further studies. Course Components There will be live video feed available only to distance education students for lectures, labs, and advanced sections. Recordings for all other students will be available within 24 hrs. Lectures The class meets twice a week for lectures. Attending lectures is a crucial component of learning the material presented in this course. Labs Lectures are supplemented by weekly programming labs. Labs are an important aspect of the course, as they supplement material from lectures with examples, discuss programming environments, and teach you important skills. In-class Quizzes At the end of each lecture, we will ask you to take a short graded quiz on the material presented in class. These quizzes will count towards your final grade. Advanced Sections The course will include advanced sections for 209 students and will cover a different topic per week. These are 75 min lectures and they will cover advanced topics like the mathematical underpinnings of the methods seen in lecture and lab and extensions of those methods. The material covered in the advanced sections is required for all ac209 students. Tentative topics are: Earth Mover's Distance Dropout ConvNets: LeNet, AlexNet, VGG-15, ResNet and Inception LSTN, GRU in NLP Neural style transfer learning Deep Reinforcement Learning Variational Inference Exams There are no exams in this course. Projects - For distant students The goal of the project is to have a complete end-to-end data science process encompassing both semesters of subject material while working as a 3-4 person team. We will supply a small set of project choices within the thematic categories. Teams may propose a different project with sufficient notice and will be subject to approval by the course staff. - For campus students During the final four (4) weeks of the course, students will be divided in break-out thematic sections where they will study topics such as medicine, law, astronomy, e-commerce, and government. Each section will include lectures by Harvard faculty, experts on the field, followed by project work also led by that faculty. You will get to present your projects in the SEAS Design Fair at the end of the semester. Homework Assignments There will be seven graded homework assignments. Some of them will be due one week after being assigned and some will be due two weeks after being assigned. For five assignments, you have the option to work and submit in pairs, the two remaining are to be completed individually. Course Resources Online Materials All course materials, including lecture notes, lab notes, and section notes will be published in the class GitHub: https://github.com/Harvard-IACS/2019-CS109B . Assignments will only be posted on Canvas. Working environment You will be working in Jupyter Notebooks which you can run in your own machine or in the SEAS JupyterHub cloud (details on this to come). Recommended Textbooks ISLR: An Introduction to Statistical Learning. by James, Witten, Hastie, Tibshirani (Springer: New York, 2013) DL: Deep Learning by Goodfellow, Bengio and Courville. Free electronic versions are available ( ISLR ), ( DL) or hard copy through Amazon ( ISLR) , ( DL ). Getting Help For questions about homework, course content, package installation, the process is: try to troubleshoot yourself by reading the lecture, lab, and section notes, and looking up online resources. go to office hours this is the best way to get help. post on the class Piazza; we want you and your peers to engage in helping each other. TFs also monitor Piazza and will respond within 24 hours. Note that Piazza questions are visible to everyone. If you are citing homework solution code you want to post privately so that only the staff sees your message. watch for official announcements via Canvas so make sure you have your Canvas notifications turned on. Piazza should always be your first resource for seeking answers to your content questions. send an email to the Helpline ( cs109b2019@gmail.com ) for administrative issues, regrade requests, and non-content specific questions we have this email account. for personal matters that you do not feel comfortable sharing with the TFs, you may send an email to either or both of the instructors. Course Policies and Expectations Grading for CS109b, STAT121b, and CS209b: <<<<<<< HEAD ======= 3aa6558f04b882eacb6af4d0b69db82445ca5329 Paired-option Homeworks 45% (5 homework for which you have the option to work in pairs) Individual Homeworks 25% (2 homework which you must complete individually) Quizzes 10% (you may drop 40% of the quizzes) Project 20% TOTAL 100% Note: Regular homework (for everyone) counts as 5 points. 209b extra homework counts as 1 point. Grading for DCE: Paired-option Homeworks 48% (5 homework for which you have the option to work in pairs) Individual Homeworks 28% (2 homework which you must complete individually) Project 24% TOTAL 100% Collaboration Policy We expect you to adhere to the Harvard Honor Code at all times. Failure to adhere to the honor code and our policies may result in serious penalties, up to and including automatic failure in the course and reference to the ad board. If you work with a partner on an assignment make sure both parties solve all the problems. Do not divide and conquer. You are expected to be intellectually honest and give credit where credit is due. In particular: if you work with a fellow student but decide to submit different papers, include the name of each other in the designated area of the submission paper. if you work with a fellow student and want to submit the same paper you need to form a group prior to the submission. Details in the assignment. Not all assignments will permit group submissions. you need to write your solutions entirely on your own or with your collaborator you are welcome to take ideas from code presented in labs, lecture, or sections but you need to change it, adapt it to your style, and ultimately write your own. We do not want to see code copied verbatim from the above sources. if you use code found on the internet, books, or other sources you need to cite those sources. you should not view any written materials or code created by other students for the same assignment; you may not provide or make available solutions to individuals who take or may take this course in the future. if the assignment allows it you may use third-party libraries and example code, so long as the material is available to all students in the class and you give proper attribution. Do not remove any original copyright notices and headers. Late or Wrongly Submitted Assignments There are no late days in homework submission. We will accept late submissions only for medical reasons and if accompanied by a doctor's note. To submit after Canvas has closed or to ask for an extension , send an email to the Helpline with subject line \"Submit HW1: Reason=the flu\" replacing 'HW1' with the name of the current assignment and \"the flu\" with your reason. You need to attach the note from your medical provider otherwise we will not accept the request. If you forgot to join a Group with your peer and are asking for the same grade we will accept this with no penalty up to HW3. For homeworks beyond that we feel that you should be familiar with the process of joining groups. After that there will be a penalty of -1 point for both members of the group provided the submission was on time. Re-grade Requests Our graders and instructors make every effort in grading accurately and in giving you a lot of feedback. If you discover that your answer to a homework problem was correct but it was marked as incorrect, send an email to the Helpline with a description of the error. Please do not submit regrade requests based on what you perceive is overly harsh grading . The points we take off are based on a grading rubric that is being applied uniformly to all assignments. If you decide to send a regrade request , send an email to the Helpline with subject line \"Regrade HW1: Grader=johnsmith\" replacing 'HW1' with the current assignment and 'johnsmith' with the name of the grader within 48 hours of the grade release . Auditing the Class If you would like to audit the class, please send an email to the Helpline indicating who you are and why you want to audit the class. You need a HUID to be included to Canvas. Academic Integrity Ethical behavior is an important trait of a Data Scientist, from ethically handling data to attribution of code and work of others. Thus, in CS109 we give a strong emphasis to Academic Honesty. As a student your best guidelines are to be reasonable and fair. We encourage teamwork for problem sets, but you should not split the homework and you should work on all the problems together. For more detailed expectations, please refer to the Collaborations section above. Accommodations for students with disabilities Students needing academic adjustments or accommodations because of a documented disability must present their Faculty Letter from the Accessible Education Office (AEO) and speak with the professor by the end of the second week of the term, (fill in specific date). Failure to do so may result in the Course Head's inability to respond in a timely manner. All discussions will remain confidential, although Faculty are invited to contact AEO to discuss appropriate implementation. Diversity and Inclusion Statement Data Science, like many fields of science, has historically only been represented by a small sliver of the population. This is despite some of the early computer scientist pioneers being women (see Ada Lovelace and Grace Hopper for two examples). Recent initiatives have attempted to overcome some barriers to entry: Made w/ Code . We would like to attempt to discuss diversity in data science from time to time where appropriate and possible. Please contact us (in person or electronically) or submit anonymous feedback if you have any suggestions to improve the diversity of the course materials. Furthermore, we would like to create a learning environment for our students that supports a diversity of thoughts, perspectives and experiences, and honors your identities (including race, gender, class, sexuality, religion, ability, etc.) To help accomplish this: If you have a name and/or set of pronouns that differ from those that appear in your official Harvard records, please let us know! If you feel like your performance in the class is being impacted by your experiences outside of class, please don't hesitate to come and talk with us. We want to be a resource for you. Remember that you can also submit anonymous feedback (which will lead to me making a general announcement to the class, if necessary to address your concerns). If you prefer to speak with someone outside of the course, you may find helpful resources at the Harvard Office of Diversity and Inclusion . We (like many people) are still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to us about it. (Again, anonymous feedback is always an option.) As a participant in course discussions, you should also strive to honor the diversity of your classmates.","tags":"pages","url":"pages/syllabus.html"},{"title":"Advanced Section: Generative Adversarial Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-209B Advanced Data Science Advanced Section 8: Generative Adversarial Networks Harvard University Spring 2019 Section instructor: Vincent Casser Instructors: Pavlos Protopapas and Mark Glickman Authors: Vincent Casser, Pavlos Protopapas We describe a minimalistic implementation of Generative Adversarial Networks (GANs) in Keras. We train a simple GAN for the task of face synthesis on the CelebA dataset. The goal of this is to enhance understanding of the concepts, and to give an easy to understand hands-on example. To increase the visual quality of samples, you are encouraged to try out some tricks you learned in class, such as switching to Wasserstein GANs (WGANs), applying label smoothing, expanding and regularizing the architecture or trying pretraining. Imports. In [12]: import keras from keras.layers import * from keras.datasets import cifar10 import glob , cv2 , os import numpy as np import matplotlib.pyplot as plt % matplotlib inline from IPython.display import clear_output Global Parameters. In [25]: SPATIAL_DIM = 64 # Spatial dimensions of the images. LATENT_DIM = 100 # Dimensionality of the noise vector. BATCH_SIZE = 32 # Batchsize to use for training. DISC_UPDATES = 1 # Number of discriminator updates per training iteration. GEN_UPDATES = 1 # Nmber of generator updates per training iteration. FILTER_SIZE = 5 # Filter size to be applied throughout all convolutional layers. NUM_LOAD = 10000 # Number of images to load from CelebA. Fit also according to the available memory on your machine. NET_CAPACITY = 16 # General factor to globally change the number of convolutional filters. PROGRESS_INTERVAL = 80 # Number of iterations after which current samples will be plotted. ROOT_DIR = 'visualization' # Directory where generated samples should be saved to. if not os . path . isdir ( ROOT_DIR ): os . mkdir ( ROOT_DIR ) Prepare Data. We use the CelebA face dataset. In [14]: def plot_image ( x ): plt . imshow ( x * 0.5 + 0.5 ) In [15]: X = [] # Reference to CelebA dataset here. faces = glob . glob ( '../Harvard/ComputeFest 2019/celeba/img_align_celeba/*.jpg' ) for i , f in enumerate ( faces ): img = cv2 . imread ( f ) img = cv2 . resize ( img , ( SPATIAL_DIM , SPATIAL_DIM )) img = np . flip ( img , axis = 2 ) img = img . astype ( np . float32 ) / 127.5 - 1.0 X . append ( img ) if i >= NUM_LOAD - 1 : break X = np . array ( X ) plot_image ( X [ 4 ]) X . shape , X . min (), X . max () Out[15]: ((10000, 64, 64, 3), -1.0, 1.0) Define Architectures. In [16]: def add_encoder_block ( x , filters , filter_size ): x = Conv2D ( filters , filter_size , padding = 'same' )( x ) x = BatchNormalization ()( x ) x = Conv2D ( filters , filter_size , padding = 'same' , strides = 2 )( x ) x = BatchNormalization ()( x ) x = LeakyReLU ( 0.3 )( x ) return x In [17]: def build_discriminator ( start_filters , spatial_dim , filter_size ): inp = Input ( shape = ( spatial_dim , spatial_dim , 3 )) # Encoding blocks downsample the image. x = add_encoder_block ( inp , start_filters , filter_size ) x = add_encoder_block ( x , start_filters * 2 , filter_size ) x = add_encoder_block ( x , start_filters * 4 , filter_size ) x = add_encoder_block ( x , start_filters * 8 , filter_size ) x = GlobalAveragePooling2D ()( x ) x = Dense ( 1 , activation = 'sigmoid' )( x ) return keras . Model ( inputs = inp , outputs = x ) In [18]: def add_decoder_block ( x , filters , filter_size ): x = Deconvolution2D ( filters , filter_size , strides = 2 , padding = 'same' )( x ) x = BatchNormalization ()( x ) x = LeakyReLU ( 0.3 )( x ) return x In [19]: def build_generator ( start_filters , filter_size , latent_dim ): inp = Input ( shape = ( latent_dim ,)) # Projection. x = Dense ( 4 * 4 * ( start_filters * 8 ), input_dim = latent_dim )( inp ) x = BatchNormalization ()( x ) x = Reshape ( target_shape = ( 4 , 4 , start_filters * 8 ))( x ) # Decoding blocks upsample the image. x = add_decoder_block ( x , start_filters * 4 , filter_size ) x = add_decoder_block ( x , start_filters * 2 , filter_size ) x = add_decoder_block ( x , start_filters , filter_size ) x = add_decoder_block ( x , start_filters , filter_size ) x = Conv2D ( 3 , kernel_size = 5 , padding = 'same' , activation = 'tanh' )( x ) return keras . Model ( inputs = inp , outputs = x ) Training. First, we construct all models. In [20]: def construct_models ( verbose = False ): # 1. Build discriminator. discriminator = build_discriminator ( NET_CAPACITY , SPATIAL_DIM , FILTER_SIZE ) discriminator . compile ( loss = 'binary_crossentropy' , optimizer = keras . optimizers . Adam ( lr = 0.0002 ), metrics = [ 'mae' ]) # 2. Build generator. generator = build_generator ( NET_CAPACITY , FILTER_SIZE , LATENT_DIM ) # 3. Build full GAN setup by stacking generator and discriminator. gan = keras . Sequential () gan . add ( generator ) gan . add ( discriminator ) discriminator . trainable = False # Fix the discriminator part in the full setup. gan . compile ( loss = 'binary_crossentropy' , optimizer = keras . optimizers . Adam ( lr = 0.0002 ), metrics = [ 'mae' ]) if verbose : # Print model summaries for debugging purposes. generator . summary () discriminator . summary () gan . summary () return generator , discriminator , gan The code below executes the main training loop. In [22]: def run_training ( start_it = 0 , num_epochs = 1000 ): config_name = 'gan_cap' + str ( NET_CAPACITY ) + '_batch' + str ( BATCH_SIZE ) + '_filt' + str ( FILTER_SIZE ) + '_disc' + str ( DISC_UPDATES ) + '_gen' + str ( GEN_UPDATES ) folder = os . path . join ( ROOT_DIR , config_name ) if not os . path . isdir ( folder ): os . mkdir ( folder ) avg_loss_discriminator = [] avg_loss_generator = [] total_it = start_it for epoch in range ( num_epochs ): loss_discriminator = [] loss_generator = [] for it in range ( 200 ): # Update discriminator. for i in range ( DISC_UPDATES ): # Fetch real examples (you could sample unique entries, too). imgs_real = X [ np . random . randint ( 0 , X . shape [ 0 ], size = BATCH_SIZE )] # Generate fake examples. noise = np . random . randn ( BATCH_SIZE , LATENT_DIM ) imgs_fake = generator . predict ( noise ) d_loss_real = discriminator . train_on_batch ( imgs_real , np . ones ([ BATCH_SIZE ]))[ 1 ] d_loss_fake = discriminator . train_on_batch ( imgs_fake , np . zeros ([ BATCH_SIZE ]))[ 1 ] # Progress visualizations. if total_it % PROGRESS_INTERVAL == 0 : plt . figure ( figsize = ( 5 , 2 )) # We sample separate images. num_vis = min ( BATCH_SIZE , 8 ) imgs_real = X [ np . random . randint ( 0 , X . shape [ 0 ], size = num_vis )] noise = np . random . randn ( num_vis , LATENT_DIM ) imgs_fake = generator . predict ( noise ) for obj_plot in [ imgs_fake , imgs_real ]: plt . figure ( figsize = ( num_vis * 3 , 3 )) for b in range ( num_vis ): disc_score = float ( discriminator . predict ( np . expand_dims ( obj_plot [ b ], axis = 0 ))[ 0 ]) plt . subplot ( 1 , num_vis , b + 1 ) plt . title ( str ( round ( disc_score , 3 ))) plot_image ( obj_plot [ b ]) if obj_plot is imgs_fake : plt . savefig ( os . path . join ( folder , str ( total_it ) . zfill ( 10 ) + '.jpg' ), format = 'jpg' , bbox_inches = 'tight' ) plt . show () # Update generator. loss = 0 y = np . ones ([ BATCH_SIZE , 1 ]) for j in range ( GEN_UPDATES ): noise = np . random . randn ( BATCH_SIZE , LATENT_DIM ) loss += gan . train_on_batch ( noise , y )[ 1 ] loss_discriminator . append (( d_loss_real + d_loss_fake ) / 2. ) loss_generator . append ( loss / GEN_UPDATES ) total_it += 1 # Progress visualization. clear_output ( True ) print ( 'Epoch' , epoch ) avg_loss_discriminator . append ( np . mean ( loss_discriminator )) avg_loss_generator . append ( np . mean ( loss_generator )) plt . plot ( range ( len ( avg_loss_discriminator )), avg_loss_discriminator ) plt . plot ( range ( len ( avg_loss_generator )), avg_loss_generator ) plt . legend ([ 'discriminator loss' , 'generator loss' ]) plt . show () In [ ]: generator , discriminator , gan = construct_models ( verbose = True ) In [ ]: run_training () Sample from Trained GAN. For this GAN, we can see instances of mode collapse below. In [10]: NUM_SAMPLES = 7 plt . figure ( figsize = ( NUM_SAMPLES * 3 , 3 )) for i in range ( NUM_SAMPLES ): noise = np . random . randn ( 1 , LATENT_DIM ) pred_raw = generator . predict ( noise )[ 0 ] pred = pred_raw * 0.5 + 0.5 plt . subplot ( 1 , NUM_SAMPLES , i + 1 ) plt . imshow ( pred ) plt . show () Out[10]: if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"a-secs","url":"a-secs/a-sec8/"},{"title":"Lab 11: Generative Adversarial Networks","text":"Notebooks Lab11 GAN Lab11 GAN with solutions","tags":"labs","url":"labs/lab11/"},{"title":"Lab 11: Generative Adversarial Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Advanced Data Science Lab 11: Generative Adversarial Networks Harvard University Spring 2019 Lab instructor: Srivatsan Srinivasan Instructors: Pavlos Protopapas and Mark Glickman Authors: Srivatsan Srinivasan, Pavlos Protopapas In [ ]: import numpy from keras.datasets import imdb from keras.models import Sequential , Model from keras.layers.core import Dense , Dropout from keras.layers import LSTM , SimpleRNN , Input from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np import matplotlib.pyplot as plt import scipy # fix random seed for reproducibility numpy . random . seed ( 1 ) Learning Goals In this lab we will look at Generative Adversarial Networks (GANs), their construction and training. By the end of this lab, you should: know how to put together the building blocks used in GANs have a good undertanding of generative models and implicit distributions that generators learn learning properties of GAN at a small scale concepts of adversarial training - min-max etc. mode collapse problems in GAN EXERCISE 1 : Generate 1-D Gaussian Distribution from Uniform Noise In this exercise, we are going to generate 1-D Gaussian distribution from a n-D uniform distribution. This is a toy exercise in order to understand the ability of GANs (generators) to generate arbitrary distributions from random noise. Generate training data - Gaussian Distribution In [2]: def generate_data ( n_samples = 10000 , n_dim = 1 ): return np . random . randn ( n_samples , n_dim ) Let us define a function that gives you a keras model of general feedforward network based on the parameters. In [ ]: #INPUT is of input dim,, goes through n_layers number of hidden layers and output is of output_dim def set_model ( input_dim , output_dim , hidden_dim = 64 , n_layers = 1 , activation = 'tanh' , optimizer = 'adam' , loss = 'binary_crossentropy' ): #### YOUR CODE HERE #### In [ ]: #INPUT (z) is of random_dim dimension #OUTPUT should be a keras model - D(G(z)) - Discriminator score for the generator's images generated #from synthetic data. def get_gan_network ( discriminator , random_dim , generator , optimizer = 'adam' ): ### YOUR CODE HERE ### Let us now write the training function for a GAN In [ ]: NOISE_DIM = 10 DATA_DIM = 1 G_LAYERS = 1 D_LAYERS = 1 In [ ]: def train_gan ( epochs = 1 , batch_size = 128 ): x_train = generate_data ( n_samples = 12800 , n_dim = DATA_DIM ) batch_count = x_train . shape [ 0 ] / batch_size generator = set_model ( NOISE_DIM , DATA_DIM , n_layers = G_LAYERS , activation = 'tanh' , loss = 'mean_squared_error' ) discriminator = set_model ( DATA_DIM , 1 , n_layers = D_LAYERS , activation = 'sigmoid' ) gan = get_gan_network ( discriminator , NOISE_DIM , generator , 'adam' ) for e in range ( 1 , epochs + 1 ): # Noise is generated from a uniform distribution noise = np . random . rand ( batch_size , NOISE_DIM ) true_batch = x_train [ np . random . choice ( x_train . shape [ 0 ], batch_size , replace = False ), :] generated_values = generator . predict ( noise ) X = np . concatenate ([ generated_values , true_batch ]) y_dis = np . zeros ( 2 * batch_size ) #One-sided label smoothing to avoid overconfidence. In GAN, if the discriminator depends on a small set of features to detect real images, #the generator may just produce these features only to exploit the discriminator. #The optimization may turn too greedy and produces no long term benefit. #To avoid the problem, we penalize the discriminator when the prediction for any real images go beyond 0.9 (D(real image)>0.9). y_dis [: batch_size ] = 0.9 discriminator . trainable = True ###YOUR CODE HERE#### # One line : Train discriminator using train_on_batch discriminator . trainable = False # Train generator. Noise is generated from a uniform distribution ### YOUR CODE HERE. Couple of lines. Should call gan.train_on_batch()### return generator , discriminator In [ ]: generator , discriminator = train_gan () Let us visualize what the generator has learned. In [ ]: noise = np . random . rand ( 10000 , NOISE_DIM ) generated_values = generator . predict ( noise ) plt . hist ( generated_values , bins = 100 ) true_gaussian = [ np . random . randn () for x in range ( 10000 )] print ( '1st order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 1 ) , ', GAN :' , scipy . stats . moment ( generated_values , 1 )) print ( '2nd order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 2 ) , ', GAN :' , scipy . stats . moment ( generated_values , 2 )) print ( '3rd order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 3 ) , ', GAN :' , scipy . stats . moment ( generated_values , 3 )) print ( '4th order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 4 ) , ', GAN :' , scipy . stats . moment ( generated_values , 4 )) plt . show () CONCLUSIONS GANs are able to learn a generative model from arbitrary noise distributions. Traditional GANs do not learn the higher-order moments well. Possible issues : Number of samples, approximating higher moments is hard. Usually known to under-predict higher order variances. For people interested in learning why, read more about divergence measures between distributions (particularly about Wasserstein etc.) PLAY WITH IT WHEN YOU HAVE TIME ! Try different noise dimensions and see what minimum dimension you need to learn this well. Try to generate multimodal distribution like a Gaussian Mixture instead of simple Gaussian and see if GAN is able to learn multimodal distributions well. EXERCISE 2 : MNIST GAN - Learn to generate MNIST digits In [ ]: from keras.datasets import mnist from keras.utils import np_utils from keras.models import Sequential , Model from keras.layers import Input , Dense , Dropout , Activation , Flatten from keras.layers.advanced_activations import LeakyReLU from keras.optimizers import Adam , RMSprop import numpy as np import matplotlib.pyplot as plt import random from tqdm import tqdm_notebook # Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. ( X_train , Y_train ), ( X_test , Y_test ) = mnist . load_data () Rescale data since we are using ReLU activations. WHY ? In [ ]: X_train = X_train . reshape ( 60000 , 784 ) X_test = X_test . reshape ( 10000 , 784 ) X_train = X_train . astype ( 'float32' ) / 255 X_test = X_test . astype ( 'float32' ) / 255 In [4]: z_dim = 100 BUILD MODEL We are using LeakyReLU activations. We will build a.) Generator b.) Discriminator c.) GAN as feedforwards with multiple layers, dropout and LeakyReLU. In [ ]: #@title adam = Adam ( lr = 0.0002 , beta_1 = 0.5 ) #GENERATOR g = Sequential () #Build your generator - noise_dim -> 256 -> 512 ->1024 ->784. LeakyRelU(0.2), adam ###YOUR CODE HERE### #DISCRIMINATOR #Build your discriminator - 784 -> 1024 -> 512 -> 256 -> 1. LeakyRelu(0.2), adam d = Sequential () ###YOUR CODE HERE### #GAN d . trainable = False inputs = Input ( shape = ( z_dim , )) hidden = g ( inputs ) output = d ( hidden ) gan = Model ( inputs , output ) gan . compile ( loss = 'binary_crossentropy' , optimizer = adam , metrics = [ 'accuracy' ]) Let us write some visualization code. In [5]: def plot_loss ( losses ): \"\"\" @losses.keys(): 0: loss 1: accuracy \"\"\" d_loss = [ v [ 0 ] for v in losses [ \"D\" ]] g_loss = [ v [ 0 ] for v in losses [ \"G\" ]] plt . figure ( figsize = ( 10 , 8 )) plt . plot ( d_loss , label = \"Discriminator loss\" ) plt . plot ( g_loss , label = \"Generator loss\" ) plt . xlabel ( 'Epochs' ) plt . ylabel ( 'Loss' ) plt . legend () plt . show () def plot_generated ( n_ex = 10 , dim = ( 1 , 10 ), figsize = ( 12 , 2 )): noise = np . random . normal ( 0 , 1 , size = ( n_ex , z_dim )) generated_images = g . predict ( noise ) generated_images = generated_images . reshape ( n_ex , 28 , 28 ) plt . figure ( figsize = figsize ) for i in range ( generated_images . shape [ 0 ]): plt . subplot ( dim [ 0 ], dim [ 1 ], i + 1 ) plt . imshow ( generated_images [ i ], interpolation = 'nearest' , cmap = 'gray_r' ) plt . axis ( 'off' ) plt . tight_layout () plt . show () TRAIN THE MODEL Generate noise, feed into generator, compare them with discriminator, train the GAN and REPEAT. In [ ]: losses = { \"D\" :[], \"G\" :[]} def train ( epochs = 1 , plt_frq = 1 , BATCH_SIZE = 128 ): batchCount = int ( X_train . shape [ 0 ] / BATCH_SIZE ) print ( 'Epochs:' , epochs ) print ( 'Batch size:' , BATCH_SIZE ) print ( 'Batches per epoch:' , batchCount ) for e in tqdm_notebook ( range ( 1 , epochs + 1 )): if e == 1 or e % plt_frq == 0: print ( '-' * 15 , 'Epoch %d ' % e , '-' * 15 ) for _ in range ( batchCount ): # tqdm_notebook(range(batchCount), leave=False): # Create a batch by drawing random index numbers from the training set image_batch = X_train [ np . random . randint ( 0 , X_train . shape [ 0 ], size = BATCH_SIZE )] # Create noise vectors for the generator noise = np . random . normal ( 0 , 1 , size = ( BATCH_SIZE , z_dim )) # Generate the images from the noise generated_images = g . predict ( noise ) X = np . concatenate (( image_batch , generated_images )) # Create Y labels similar to last exercise. ### YOUR CODE HERE #### # Train gan and disrciminator similar to last exercise. ##YOUR CODE HERE### # Only store losses from final losses [ \"D\" ] . append ( d_loss ) losses [ \"G\" ] . append ( g_loss ) # Update the plots if e == 1 or e % plt_frq == 0: plot_generated () plot_loss ( losses ) In [ ]: train ( epochs = 200 , plt_frq = 40 , BATCH_SIZE = 128 ) TAKE-HOME EXERCISE Try to build CNN models instead of feedforwards Try different noise dimensions Try implementing some training tricks suggested in https://github.com/soumith/ganhacks and study incremental improvements. DISCUSSION : Why can GANs potentially mode collapse ? Remember there is no guarantee of mode collapse. TL;DR - There is inherently no \"motivation\" for generator to produce a diverse set of samples as discriminator only penalizes for producing \"bad\" samples. It is easy to learn a few modes than all modes of a multi modal distribution. Remember, the goal of the generator G is to fool the discriminator by causing it to assign the generated sample the highest probability of being real as possible. Mathematically, G tries to minimize E_z∼p_z(z)[log(1−D(G(z)))], or in other words, to generate the point x =G(z) such that x =argmax_x D(x) (of course, we're assuming that we hold the discriminator fixed for now; we're merely describing the optimization objective at a given timestep). Note that this x is fixed regardless of the value of z, the input to the generator! x only depends on the discriminator at the given timestep. This means that on expectation, there exists a single fixed point that the generator thinks is the most optimal point to generate regardless of whatever input noise we feed it - there is nothing in the objective function that explicitly forces the generator to generate different samples given the input. During this training step, stochastic gradient descent - again, on expectation - would cause the generator to update its weights towards generating this ideal point. This by itself doesn't immediately mean mode collapse; during the entirety of the training process, mode collapse may happen only partially or not at all. Since training is a stochastic process, during the beginning stages in training the generated samples will vary depending on z and the samples drawn from the real distribution will also vary - this means that gradients backpropagated to the generator will vary between training steps depending on the generated and real samples. Moreover the discriminator, ideally, should be able to identify generator mode collapse while it's happening and assign the collapse point a low probability to force the generator to spread out. This is why we do see training runs succeed in GAN/DCGAN-based models. But in practice, especially in default GAN models, mode collapse happens quite often. The discriminator ends up not really forcing more diversity in the generator, so much as simply pushing the partially collapsed generator to a different part of output space - if it assigns the collapse point a low probability, the generator will simply move its collapsed distribution to focus on a new output point. And finally, in the case where the generator has actually collapsed to a single point, it can't get out; you'll have to restart your training. To see why this is the case, remember how I said above that the gradient updates to the generator are stochastic, because its generated outputs will vary based on z. Well, in the world where the generator is already collapsed, it will emit the same output for every z. This means that if you feed a batch of generator outputs to the discriminator and get the gradients back, the generator gradients will all essentially be identical. And they'll all be racing towards the same maximum point x*! Which means the generator will continue to generate the same output regardless of input. Even if the discriminator identifies this and sets the point to low probability, still, the identical gradient updates will cause all outputs of the generator rushing to another fixed point. At this point your training is ruined. Thanks : This version of the answer is from https://www.quora.com/What-causes-mode-collapse-in-GANs if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab11/GANS/"},{"title":"Lab 11: Generative Adversarial Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Advanced Data Science Lab 11: Generative Adversarial Networks Harvard University Spring 2019 Lab instructor: Srivatsan Srinivasan Instructors: Pavlos Protopapas and Mark Glickman Authors: Srivatsan Srinivasan, Pavlos Protopapas EXERCISE 1 : Generate 1-D Gaussian Distribution from Uniform Noise In this exercise, we are going to generate 1-D Gaussian distribution from a n-D uniform distribution. This is a toy exercise in order to understand the ability of GANs (generators) to generate arbitrary distributions from random noise. In [0]: import numpy from keras.datasets import imdb from keras.models import Sequential , Model from keras.layers.core import Dense , Dropout from keras.layers import LSTM , SimpleRNN , Input from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np import matplotlib.pyplot as plt import scipy # fix random seed for reproducibility numpy . random . seed ( 1 ) Using TensorFlow backend. Generate training data - Gaussian Distribution In [0]: def generate_data ( n_samples = 10000 , n_dim = 1 ): return np . random . randn ( n_samples , n_dim ) A general function to define feedforward architectures In [0]: def set_model ( input_dim , output_dim , hidden_dim = 64 , n_layers = 1 , activation = 'tanh' , optimizer = 'adam' , loss = 'binary_crossentropy' ): model = Sequential () model . add ( Dense ( hidden_dim , input_dim = input_dim , activation = activation )) for _ in range ( n_layers - 1 ): model . add ( Dense ( hidden_dim ), activation = activation ) model . add ( Dense ( output_dim )) model . compile ( loss = loss , optimizer = optimizer ) print ( model . summary ()) return model Setting GAN training and losses here In [0]: def get_gan_network ( discriminator , random_dim , generator , optimizer = 'adam' ): discriminator . trainable = False gan_input = Input ( shape = ( random_dim ,)) x = generator ( gan_input ) gan_output = discriminator ( x ) gan = Model ( inputs = gan_input , outputs = gan_output ) gan . compile ( loss = 'binary_crossentropy' , optimizer = optimizer ) return gan In [0]: NOISE_DIM = 10 DATA_DIM = 1 G_LAYERS = 1 D_LAYERS = 1 In [0]: def train_gan ( epochs = 1 , batch_size = 128 ): x_train = generate_data ( n_samples = 12800 , n_dim = DATA_DIM ) batch_count = x_train . shape [ 0 ] / batch_size generator = set_model ( NOISE_DIM , DATA_DIM , n_layers = G_LAYERS , activation = 'tanh' , loss = 'mean_squared_error' ) discriminator = set_model ( DATA_DIM , 1 , n_layers = D_LAYERS , activation = 'sigmoid' ) gan = get_gan_network ( discriminator , NOISE_DIM , generator , 'adam' ) for e in range ( 1 , epochs + 1 ): # Noise is generated from a uniform distribution noise = np . random . rand ( batch_size , NOISE_DIM ) true_batch = x_train [ np . random . choice ( x_train . shape [ 0 ], batch_size , replace = False ), :] generated_values = generator . predict ( noise ) X = np . concatenate ([ generated_values , true_batch ]) y_dis = np . zeros ( 2 * batch_size ) #One-sided label smoothing to avoid overconfidence. In GAN, if the discriminator depends on a small set of features to detect real images, #the generator may just produce these features only to exploit the discriminator. #The optimization may turn too greedy and produces no long term benefit. #To avoid the problem, we penalize the discriminator when the prediction for any real images go beyond 0.9 (D(real image)>0.9). y_dis [: batch_size ] = 0.9 discriminator . trainable = True disc_history = discriminator . train_on_batch ( X , y_dis ) discriminator . trainable = False # Train generator # Noise is generated from a uniform distribution noise = np . random . rand ( batch_size , NOISE_DIM ) y_gen = np . zeros ( batch_size ) gan . train_on_batch ( noise , y_gen ) return generator , discriminator In [0]: generator , discriminator = train_gan () WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version. Instructions for updating: Colocations handled automatically by placer. _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_1 (Dense) (None, 64) 704 _________________________________________________________________ dense_2 (Dense) (None, 1) 65 ================================================================= Total params: 769 Trainable params: 769 Non-trainable params: 0 _________________________________________________________________ None _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_3 (Dense) (None, 64) 128 _________________________________________________________________ dense_4 (Dense) (None, 1) 65 ================================================================= Total params: 193 Trainable params: 193 Non-trainable params: 0 _________________________________________________________________ None WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.cast instead. In [0]: noise = np . random . rand ( 10000 , NOISE_DIM ) generated_values = generator . predict ( noise ) plt . hist ( generated_values , bins = 100 ) true_gaussian = [ np . random . randn () for x in range ( 10000 )] print ( '1st order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 1 ) , ', GAN :' , scipy . stats . moment ( generated_values , 1 )) print ( '2nd order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 2 ) , ', GAN :' , scipy . stats . moment ( generated_values , 2 )) print ( '3rd order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 3 ) , ', GAN :' , scipy . stats . moment ( generated_values , 3 )) print ( '4th order moment - ' , 'True : ' , scipy . stats . moment ( true_gaussian , 4 ) , ', GAN :' , scipy . stats . moment ( generated_values , 4 )) plt . show () 1st order moment - True : 0.0 , GAN : [0.] 2nd order moment - True : 0.993800675880421 , GAN : [0.04502174] 3rd order moment - True : 0.04224919831436267 , GAN : [0.00038419] 4th order moment - True : 2.9013848672859766 , GAN : [0.00534782] CONCLUSIONS GANs are able to learn a generative model from general noise distributions. Traditional GANs do not learn the higher-order moments well. Possible issues : Number of samples, approximating higher moments is hard. Usually known to under-predict higher order variances. For people interested in learning why, read more about divergence measures between distributions (particularly about Wasserstein etc.) EXERCISE 2 : MNIST GAN - Learn to generate MNIST digits In [0]: from keras.datasets import mnist from keras.utils import np_utils from keras.models import Sequential , Model from keras.layers import Input , Dense , Dropout , Activation , Flatten from keras.layers.advanced_activations import LeakyReLU from keras.optimizers import Adam , RMSprop import numpy as np import matplotlib.pyplot as plt import random from tqdm import tqdm_notebook # Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images. ( X_train , Y_train ), ( X_test , Y_test ) = mnist . load_data () Rescale data since we are using ReLU activations. WHY ? In [0]: X_train = X_train . reshape ( 60000 , 784 ) X_test = X_test . reshape ( 10000 , 784 ) X_train = X_train . astype ( 'float32' ) / 255 X_test = X_test . astype ( 'float32' ) / 255 Set noise dimension EXERCISE : Play around with different noise dimensions and plot the performance with respect to the size of the noise vector. In [0]: z_dim = 100 BUILD MODEL We are using LeakyReLU activations. We will build a.) Generator b.) Discriminator c.) GAN as feedforwards with multiple layers, dropout and LeakyReLU. In [0]: def leakyReLU ( x , neg_scale = 0.01 ): if x > 0 : return x else : return neg_scale * x std_relu = [] leaky_relu = [] std_relu = [ leakyReLU ( x , neg_scale = 0 ) for x in np . linspace ( - 100 , 100 , 10000 )] leaky_relu = [ leakyReLU ( x , neg_scale = 0.1 ) for x in np . linspace ( - 100 , 100 , 10000 )] plt . plot ( np . linspace ( - 100 , 100 , 10000 ), std_relu , label = 'standard_RELU' ) plt . plot ( np . linspace ( - 100 , 100 , 10000 ), leaky_relu , label = 'leaky_RELU' ) plt . legend () plt . show () In [0]: #@title adam = Adam ( lr = 0.0002 , beta_1 = 0.5 ) #GENERATOR g = Sequential () g . add ( Dense ( 256 , input_dim = z_dim , activation = LeakyReLU ( alpha = 0.2 ))) g . add ( Dense ( 512 , activation = LeakyReLU ( alpha = 0.2 ))) g . add ( Dense ( 1024 , activation = LeakyReLU ( alpha = 0.2 ))) g . add ( Dense ( 784 , activation = 'sigmoid' )) # Values between 0 and 1 g . compile ( loss = 'binary_crossentropy' , optimizer = adam , metrics = [ 'accuracy' ]) #DISCRIMINATOR d = Sequential () d . add ( Dense ( 1024 , input_dim = 784 , activation = LeakyReLU ( alpha = 0.2 ))) d . add ( Dropout ( 0.3 )) d . add ( Dense ( 512 , activation = LeakyReLU ( alpha = 0.2 ))) d . add ( Dropout ( 0.3 )) d . add ( Dense ( 256 , activation = LeakyReLU ( alpha = 0.2 ))) d . add ( Dropout ( 0.3 )) d . add ( Dense ( 1 , activation = 'sigmoid' )) # Values between 0 and 1 d . compile ( loss = 'binary_crossentropy' , optimizer = adam , metrics = [ 'accuracy' ]) #GAN d . trainable = False inputs = Input ( shape = ( z_dim , )) hidden = g ( inputs ) output = d ( hidden ) gan = Model ( inputs , output ) gan . compile ( loss = 'binary_crossentropy' , optimizer = adam , metrics = [ 'accuracy' ]) WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version. Instructions for updating: Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`. /usr/local/lib/python3.6/dist-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model. identifier=identifier.__class__.__name__)) Plot losses and generated images preiodically to monitor what the model does. In [0]: def plot_loss ( losses ): \"\"\" @losses.keys(): 0: loss 1: accuracy \"\"\" d_loss = [ v [ 0 ] for v in losses [ \"D\" ]] g_loss = [ v [ 0 ] for v in losses [ \"G\" ]] plt . figure ( figsize = ( 10 , 8 )) plt . plot ( d_loss , label = \"Discriminator loss\" ) plt . plot ( g_loss , label = \"Generator loss\" ) plt . xlabel ( 'Epochs' ) plt . ylabel ( 'Loss' ) plt . legend () plt . show () def plot_generated ( n_ex = 10 , dim = ( 1 , 10 ), figsize = ( 12 , 2 )): noise = np . random . normal ( 0 , 1 , size = ( n_ex , z_dim )) generated_images = g . predict ( noise ) generated_images = generated_images . reshape ( n_ex , 28 , 28 ) plt . figure ( figsize = figsize ) for i in range ( generated_images . shape [ 0 ]): plt . subplot ( dim [ 0 ], dim [ 1 ], i + 1 ) plt . imshow ( generated_images [ i ], interpolation = 'nearest' , cmap = 'gray_r' ) plt . axis ( 'off' ) plt . tight_layout () plt . show () TRAIN THE MODEL Generate noise, feed into generator, compare them with discriminator, train the GAN and REPEAT. In [0]: losses = { \"D\" :[], \"G\" :[]} def train ( epochs = 1 , plt_frq = 1 , BATCH_SIZE = 128 ): batchCount = int ( X_train . shape [ 0 ] / BATCH_SIZE ) print ( 'Epochs:' , epochs ) print ( 'Batch size:' , BATCH_SIZE ) print ( 'Batches per epoch:' , batchCount ) for e in tqdm_notebook ( range ( 1 , epochs + 1 )): if e == 1 or e % plt_frq == 0: print ( '-' * 15 , 'Epoch %d ' % e , '-' * 15 ) for _ in range ( batchCount ): # tqdm_notebook(range(batchCount), leave=False): # Create a batch by drawing random index numbers from the training set image_batch = X_train [ np . random . randint ( 0 , X_train . shape [ 0 ], size = BATCH_SIZE )] # Create noise vectors for the generator noise = np . random . normal ( 0 , 1 , size = ( BATCH_SIZE , z_dim )) # Generate the images from the noise generated_images = g . predict ( noise ) X = np . concatenate (( image_batch , generated_images )) # Create labels y = np . zeros ( 2 * BATCH_SIZE ) y [: BATCH_SIZE ] = 0.9 # One-sided label smoothing # Train discriminator on generated images d . trainable = True d_loss = d . train_on_batch ( X , y ) # Train generator noise = np . random . normal ( 0 , 1 , size = ( BATCH_SIZE , z_dim )) y2 = np . ones ( BATCH_SIZE ) d . trainable = False g_loss = gan . train_on_batch ( noise , y2 ) # Only store losses from final losses [ \"D\" ] . append ( d_loss ) losses [ \"G\" ] . append ( g_loss ) # Update the plots if e == 1 or e % plt_frq == 0: plot_generated () plot_loss ( losses ) In [0]: train ( epochs = 200 , plt_frq = 40 , BATCH_SIZE = 128 ) Epochs: 200 Batch size: 128 Batches per epoch: 468 var element = $('#3e07c31a-d02b-4b36-9e73-a70403d321e1'); {\"model_id\": \"b2298b3b460d4442bb3ca2ed6825db6f\", \"version_major\": 2, \"version_minor\": 0} --------------- Epoch 1 --------------- --------------- Epoch 40 --------------- --------------- Epoch 80 --------------- --------------- Epoch 120 --------------- --------------- Epoch 160 --------------- --------------- Epoch 200 --------------- DISCUSSION : Why can GANs potentially mode collapse ? Remember there is no guarantee of mode collapse. TL;DR - There is inherently no \"motivation\" for generator to produce a diverse set of samples as discriminator only penalizes for producing \"bad\" samples. It is easy to learn a few modes than all modes of a multi modal distribution. Remember, the goal of the generator G is to fool the discriminator by causing it to assign the generated sample the highest probability of being real as possible. Mathematically, G tries to minimize E_z∼p_z(z)[log(1−D(G(z)))], or in other words, to generate the point x =G(z) such that x =argmax_x D(x) (of course, we're assuming that we hold the discriminator fixed for now; we're merely describing the optimization objective at a given timestep). Note that this x is fixed regardless of the value of z, the input to the generator! x only depends on the discriminator at the given timestep. This means that on expectation, there exists a single fixed point that the generator thinks is the most optimal point to generate regardless of whatever input noise we feed it - there is nothing in the objective function that explicitly forces the generator to generate different samples given the input. During this training step, stochastic gradient descent - again, on expectation - would cause the generator to update its weights towards generating this ideal point. This by itself doesn't immediately mean mode collapse; during the entirety of the training process, mode collapse may happen only partially or not at all. Since training is a stochastic process, during the beginning stages in training the generated samples will vary depending on z and the samples drawn from the real distribution will also vary - this means that gradients backpropagated to the generator will vary between training steps depending on the generated and real samples. Moreover the discriminator, ideally, should be able to identify generator mode collapse while it's happening and assign the collapse point a low probability to force the generator to spread out. This is why we do see training runs succeed in GAN/DCGAN-based models. But in practice, especially in default GAN models, mode collapse happens quite often. The discriminator ends up not really forcing more diversity in the generator, so much as simply pushing the partially collapsed generator to a different part of output space - if it assigns the collapse point a low probability, the generator will simply move its collapsed distribution to focus on a new output point. And finally, in the case where the generator has actually collapsed to a single point, it can't get out; you'll have to restart your training. To see why this is the case, remember how I said above that the gradient updates to the generator are stochastic, because its generated outputs will vary based on z. Well, in the world where the generator is already collapsed, it will emit the same output for every z. This means that if you feed a batch of generator outputs to the discriminator and get the gradients back, the generator gradients will all essentially be identical. And they'll all be racing towards the same maximum point x*! Which means the generator will continue to generate the same output regardless of input. Even if the discriminator identifies this and sets the point to low probability, still, the identical gradient updates will cause all outputs of the generator rushing to another fixed point. At this point your training is ruined. Thanks : The answer is derived from https://www.quora.com/What-causes-mode-collapse-in-GANs if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab11/GANS-sol/"},{"title":"Lab 21: Generative Adversarial Networks Example","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lecture 21: Adversarial Examples Harvard University Spring 2019 Instructors: Pavlos Protopapas and Mark Glickman Code and ideas taken/borrowed/adapted from Deep Learning From Basics to Practice, by Andrew Glassner, https://dlbasics.com , http://glassner.com , Python utilities for saving and loading files, mostly images and Keras model weights Authors: Pavlos Protopapas, Amil Merchant, Alex Lin, Thomas Chang, ZiZi Zhang In [1]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Adversarial Examples Adversarial examples for neural networks are inputs that are specifically meant to fool neural networks but be descernible to the human eye. Contents: Datasets - MNIST Cleverhans Integration FGSM (non-targeted attack) JSMA (targeted attack) Exercise: Repeat process with CIFAR Datasets - MNIST / CIFAR In this examples, we will explore some of these examples and a few attack methods on common datasets such as MNIST and CIFAR10. We first load the data in through Keras. In [2]: import numpy as np from keras.datasets import mnist from keras.datasets import cifar10 import matplotlib.pyplot as plt import tensorflow as tf import keras session = tf . Session () keras . backend . set_session ( session ) Using TensorFlow backend. /Users/pavlos/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6 return f(*args, **kwds) In [3]: ( mn_x_train , mn_y_train ), ( mn_x_test , mn_y_test ) = mnist . load_data () As a refresher, MNIST is a dataset for black and white handwritten digits. This dataset is particularly simple, as we will see, neural networks can achieve very high levels of test accuracy. Each image is 28 x 28, for a size of 784 for each input. In [4]: print ( \"Training Examples: %d \" % len ( mn_x_train )) print ( \"Test Examples: %d \" % len ( mn_x_test )) Training Examples: 60000 Test Examples: 10000 In [5]: n_classes = 10 inds = np . array ([ mn_y_train == i for i in range ( n_classes )]) f , ax = plt . subplots ( 2 , 5 , figsize = ( 10 , 5 )) ax = ax . flatten () for i in range ( n_classes ): ax [ i ] . imshow ( mn_x_train [ np . argmax ( inds [ i ])] . reshape ( 28 , 28 )) ax [ i ] . set_title ( str ( i )) plt . show () Neural Network Training Keras is a high level library which can be used to train neural network models. It simplies coding neural networks for the datasets, and as installed, uses tensorflow for the backend. We use Keras for its simplicity and because these models can easily be linked into the cleverhans library to generate adversarial examples. We shall start with MNIST as the models and the results are easy to see. The second half of the notebook will repeat the results with CIFAR10. For MNIST, we will use a very simple neural network which takes in the 28 x 28 input, uses a single hidden layer of size 512, and goes uses dense connections to lead to the 10 output classes. This should be familiar and may seem too simple, we will will build up to more complex examples when we get to CIFAR10. In [6]: from keras import models from keras import layers network = models . Sequential () network . add ( layers . Dense ( 512 , activation = 'relu' , input_shape = ( 28 * 28 ,))) network . add ( layers . Dense ( 10 , activation = 'softmax' )) network . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) The data must be pre-processed before analysis. We flatten the image and normalize the images so pixel values are between 0 and 1 instead of 0 and 255. The labels must also be inputted as one hot vectors, so we use built in keras functions. In [14]: train_images_1d = mn_x_train . reshape (( 60000 , 28 * 28 )) train_images_1d = train_images_1d . astype ( 'float32' ) / 255 test_images_1d = mn_x_test . reshape (( 10000 , 28 * 28 )) test_images_1d = test_images_1d . astype ( 'float32' ) / 255 In [15]: from keras.utils import to_categorical #this just converts the labels to one-hot class train_labels = to_categorical ( mn_y_train ) test_labels = to_categorical ( mn_y_test ) Training the network does not take long and can easily be done quickly on a CPU. Validation accuracy quickly rises to about 99%. In [16]: from keras.callbacks import ModelCheckpoint h = network . fit ( train_images_1d , train_labels , epochs = 5 , batch_size = 128 , shuffle = True , callbacks = [ ModelCheckpoint ( 'tutorial_MNIST.h5' , save_best_only = True )]) Epoch 1/5 60000/60000 [==============================] - 6s 107us/step - loss: 0.0283 - acc: 0.9920 Epoch 2/5 1152/60000 [..............................] - ETA: 7s - loss: 0.0249 - acc: 0.9931 /Users/pavlos/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:403: RuntimeWarning: Can save best model only with val_loss available, skipping. 'skipping.' % (self.monitor), RuntimeWarning) 60000/60000 [==============================] - 7s 113us/step - loss: 0.0217 - acc: 0.9935 Epoch 3/5 60000/60000 [==============================] - 5s 89us/step - loss: 0.0168 - acc: 0.9949 Epoch 4/5 60000/60000 [==============================] - 6s 92us/step - loss: 0.0127 - acc: 0.9962 Epoch 5/5 60000/60000 [==============================] - 7s 114us/step - loss: 0.0097 - acc: 0.9973 In [17]: # summarize history for accuracy plt . plot ( h . history [ 'acc' ]) plt . title ( 'model accuracy' ) plt . ylabel ( 'accuracy' ) plt . xlabel ( 'epoch' ) plt . legend ([ 'train' ], loc = 'upper left' ) plt . show () In [18]: score , acc = network . evaluate ( test_images_1d , test_labels , batch_size = 128 ) print ( \"Test Accuracy: %.5f \" % acc ) 10000/10000 [==============================] - 0s 41us/step Test Accuracy: 0.98310 In [19]: network . save ( 'tutorial_MNIST.h5' ) Cleverhans Integration Cleverhans is a library written by researchers on adversarial examples, many of whom are with Google Brain. The library has wrappers that allow us to take the Keras model that we just made (or an already trained model) and create adversarial examples. If the model has already been created and we do not want to recreate it, just run the code below to reload the model. In [20]: from keras.models import load_model network = load_model ( 'tutorial_MNIST.h5' ) In [21]: #%pip install -e git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans In [22]: from cleverhans.utils_keras import KerasModelWrapper wrap = KerasModelWrapper ( network ) FGSM The F ast G radient S ign M ethod is a non-target attack. Using the parameters in the neural network we trained, the FGSM method calculates the $\\nabla$ of the cost function for the particular input. By adding this gradient to the image times some parameter $\\epsilon$, we know that the cost function will increase. If the gradient is large enough, then the predictor is likely to change. In [23]: x = tf . placeholder ( tf . float32 , shape = ( None , 784 )) y = tf . placeholder ( tf . float32 , shape = ( None , 10 )) As mentioned above, the $\\epsilon \\nabla$ is added to the image to create the adversarial example. $\\epsilon$ is given by fgsm_rate in the code below. We chose this value since it leads low adversarial accuracy but the images are still easily discernible by eye. Too high of a value would make the images look like random noise, but too low values would leave the adversarial accuracy very high. In [24]: from cleverhans.attacks import FastGradientMethod fgsm = FastGradientMethod ( wrap , sess = session ) fgsm_rate = 0.08 fgsm_params = { 'eps' : fgsm_rate , 'clip_min' : 0. , 'clip_max' : 1. } adv_x = fgsm . generate ( x , ** fgsm_params ) adv_x = tf . stop_gradient ( adv_x ) adv_prob = network ( adv_x ) In [25]: fetches = [ adv_prob ] fetches . append ( adv_x ) outputs = session . run ( fetches = fetches , feed_dict = { x : test_images_1d }) adv_prob = outputs [ 0 ] adv_examples = outputs [ 1 ] In [26]: adv_predicted = adv_prob . argmax ( 1 ) adv_accuracy = np . mean ( adv_predicted == mn_y_test ) print ( \"Adversarial accuracy: %.5f \" % adv_accuracy ) Adversarial accuracy: 0.32230 In [27]: n_classes = 10 f , ax = plt . subplots ( 2 , 5 , figsize = ( 10 , 5 )) ax = ax . flatten () for i in range ( n_classes ): ax [ i ] . imshow ( adv_examples [ i ] . reshape ( 28 , 28 )) ax [ i ] . set_title ( \"Adv: %d , Label: %d \" % ( adv_predicted [ i ], mn_y_test [ i ])) plt . show () From the examples above, we can see that many of the examples are misclassified from the true labels. Since the changes are non-targetted, the adversarial labels do not seem to show significant trends but are clearly not the numbers in the picture. JSMA The JSMA method is slightly more complicated than FGSM and full explanations can be found in the following paper: https://arxiv.org/abs/1511.07528 . One of the main differences is that this method is that the method generates targeted examples. For example, given a 4, we could perturb the image to register as any digit we desire between 0 and 9. In [18]: x = tf . placeholder ( tf . float32 , shape = ( None , 784 )) y = tf . placeholder ( tf . float32 , shape = ( None , 10 )) results = np . zeros (( 10 , 10000 )) perturbations = np . zeros (( 10 , 10000 )) grid_shape = ( 10 , 10 , 28 , 28 , 1 ) grid_data = np . zeros ( grid_shape ) from cleverhans.attacks import SaliencyMapMethod jsma = SaliencyMapMethod ( wrap , sess = session ) jsma_params = { 'theta' : 1. , 'gamma' : 0.1 , 'clip_min' : 0. , 'clip_max' : 1. , 'y_target' : None } In [19]: from cleverhans.utils import other_classes , grid_visual for index in range ( int ( len ( mn_x_test ) / 100 )): sample = test_images_1d [ index : index + 1 ] current = mn_y_test [ index ] target_classes = other_classes ( 10 , current ) grid_data [ current , current , :, :, :] = np . reshape ( sample , ( 28 , 28 , 1 )) for target in target_classes : one_hot_target = np . zeros (( 1 , 10 )) one_hot_target [ 0 , target ] = 1 jsma_params [ 'y_target' ] = one_hot_target adv_x = jsma . generate_np ( sample , ** jsma_params ) grid_data [ target , current , :, :, :] = np . reshape ( adv_x , ( 28 , 28 , 1 )) if index % 10 == 0 : print ( index ) print ( sample . shape ) print ( one_hot_target ) print ( adv_x . shape ) 0 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 10 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 20 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]] (1, 784) 30 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 40 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 50 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 60 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 70 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 80 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) 90 (1, 784) [[ 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]] (1, 784) In [22]: plt . figure ( figsize = ( 80 , 80 )) _ = grid_visual ( grid_data ) Each row in the above plot shows an example for a particular starting class / digit. Using JSMA, we were able to generate examples that adversarially were designed to be predicted as $0, 1, \\dots$ where each column represents the adversarial target class. CIFAR10 Below, you can repeat the attack mehtods described above for a neural network on CIFAR10. This library is decently larger and requires a more complex CNN to train properly. In [23]: import numpy as np from keras.datasets import mnist from keras.datasets import cifar10 import matplotlib.pyplot as plt import tensorflow as tf import keras session = tf . Session () keras . backend . set_session ( session ) ( c10_x_train , c10_y_train ), ( c10_x_test , c10_y_test ) = cifar10 . load_data () As a refresher, CIFAR10 is a dataset for small color images which should be classifying into classes based on the object the image such as an airplane or boat. Each image is 32 x 32 x 3, for a size of 3072 for each input. In [24]: print ( \"Training Examples: %d \" % len ( c10_x_train )) print ( \"Test Examples: %d \" % len ( c10_x_test )) Training Examples: 50000 Test Examples: 10000 In [25]: n_classes = 10 inds = np . array ([ c10_y_train == i for i in range ( n_classes )]) f , ax = plt . subplots ( 2 , 5 , figsize = ( 10 , 5 )) ax = ax . flatten () for i in range ( n_classes ): ax [ i ] . imshow ( c10_x_train [ np . argmax ( inds [ i ])] . reshape ( 32 , 32 , 3 )) ax [ i ] . set_title ( str ( i )) plt . show () if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"Lecture","url":"lecture/lab21/AdversarialNN/"},{"title":"Advanced Section 8: Generative Adversarial Networks","text":"Slides PDF Code Notebook","tags":"A-sections","url":"a-sections/a-section8/"},{"title":"Lecture 20: GANS","text":"Slides Lecture 20 PDF Lecture 20 PPTX Associated Materials Labs Lab11 Notebook Lab11 GAN with solutions Advanced Sections A-sec 8 Slides A-sec 8 Code","tags":"pages","url":"pages/lecture20/"},{"title":"Lecture 21: GANS","text":"Slides Lecture 21 PDF Lecture 21 PPTX Associated Materials Examples Adversarial Example Code Labs Lab11 Notebook Lab11 GAN with solutions Advanced Sections A-sec 8 Slides A-sec 8 Code","tags":"pages","url":"pages/lecture21/"},{"title":"Lab 10: Variational Autoencoders","text":"Notebooks Lab 10 notebook Lab 10 notebook with solutions","tags":"labs","url":"labs/lab10/"},{"title":"Lab 10: Autoencoders and Variational Autoencoders","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 10 - Autoencoders and Variational Autoencoders Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas In [1]: # !pip install imgaug In [2]: ## load the libraries import sys import warnings import os import glob warnings . filterwarnings ( \"ignore\" ) import numpy as np import pandas as pd import cv2 from sklearn.model_selection import train_test_split from keras.layers import * from keras.callbacks import EarlyStopping from keras.utils import to_categorical from keras.models import Model , Sequential from keras.metrics import * from keras.optimizers import Adam , RMSprop from scipy.stats import norm from keras.preprocessing import image from keras import backend as K from imgaug import augmenters import matplotlib.pyplot as plt plt . gray () Using TensorFlow backend. Part 1: Data Reading data Download the data given at the following link: . Use pandas and numpy to read in the data as a matrix In [3]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_x , val_x = train_test_split ( train_x , test_size = 0.15 ) ## create train and validation datasets train_x , val_x = train_test_split ( train_x , test_size = 0.15 ) In [4]: ## normalize and reshape train_x = train_x / 255. val_x = val_x / 255. train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) val_x = val_x . reshape ( - 1 , 28 , 28 , 1 ) In [5]: train_x . shape Out[5]: (43350, 28, 28, 1) Visualizing Samples Visualize 10 images from dataset In [6]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i in range ( 5 , 10 ): ax [ i - 5 ] . imshow ( train_x [ i , :, :, 0 ] . reshape ( 28 , 28 )) Part 2: Denoise Images using AEs Understanding AEs Add Noise to Images Check out imgaug docs for more info and other ways to add noise. In [7]: # Lets add sample noise - Salt and Pepper noise = augmenters . SaltAndPepper ( 0.1 ) seq_object = augmenters . Sequential ([ noise ]) train_x_n = seq_object . augment_images ( train_x * 255 ) / 255 val_x_n = seq_object . augment_images ( val_x * 255 ) / 255 In [8]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i in range ( 5 , 10 ): ax [ i - 5 ] . imshow ( train_x_n [ i , :, :, 0 ] . reshape ( 28 , 28 )) Setup Encoder Neural Network Try different number of hidden layers, nodes? In [9]: # input layer input_layer = Input ( shape = ( 28 , 28 , 1 )) # encoding architecture encoded_layer1 = Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( input_layer ) encoded_layer1 = MaxPool2D ( ( 2 , 2 ), padding = 'same' )( encoded_layer1 ) encoded_layer2 = Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( encoded_layer1 ) encoded_layer2 = MaxPool2D ( ( 2 , 2 ), padding = 'same' )( encoded_layer2 ) encoded_layer3 = Conv2D ( 16 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( encoded_layer2 ) latent_view = MaxPool2D ( ( 2 , 2 ), padding = 'same' )( encoded_layer3 ) Setup Decoder Neural Network Try different number of hidden layers, nodes? In [10]: # decoding architecture decoded_layer1 = Conv2D ( 16 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( latent_view ) decoded_layer1 = UpSampling2D (( 2 , 2 ))( decoded_layer1 ) decoded_layer2 = Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( decoded_layer1 ) decoded_layer2 = UpSampling2D (( 2 , 2 ))( decoded_layer2 ) decoded_layer3 = Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )( decoded_layer2 ) decoded_layer3 = UpSampling2D (( 2 , 2 ))( decoded_layer3 ) output_layer = Conv2D ( 1 , ( 3 , 3 ), padding = 'same' )( decoded_layer3 ) Train AE In [11]: # compile the model model = Model ( input_layer , output_layer ) model . compile ( optimizer = 'adam' , loss = 'mse' ) In [12]: model . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 64) 640 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 14, 14, 32) 18464 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 7, 7, 16) 4624 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16) 0 _________________________________________________________________ conv2d_4 (Conv2D) (None, 4, 4, 16) 2320 _________________________________________________________________ up_sampling2d_1 (UpSampling2 (None, 8, 8, 16) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 8, 8, 32) 4640 _________________________________________________________________ up_sampling2d_2 (UpSampling2 (None, 16, 16, 32) 0 _________________________________________________________________ conv2d_6 (Conv2D) (None, 14, 14, 64) 18496 _________________________________________________________________ up_sampling2d_3 (UpSampling2 (None, 28, 28, 64) 0 _________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 1) 577 ================================================================= Total params: 49,761 Trainable params: 49,761 Non-trainable params: 0 _________________________________________________________________ In [13]: early_stopping = EarlyStopping ( monitor = 'val_loss' , min_delta = 0 , patience = 10 , verbose = 5 , mode = 'auto' ) history = model . fit ( train_x_n , train_x , epochs = 20 , batch_size = 2048 , validation_data = ( val_x_n , val_x ), callbacks = [ early_stopping ]) Train on 43350 samples, validate on 7650 samples Epoch 1/20 43350/43350 [==============================] - 7s 160us/step - loss: 0.0945 - val_loss: 0.0563 Epoch 2/20 43350/43350 [==============================] - 2s 46us/step - loss: 0.0481 - val_loss: 0.0403 Epoch 3/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0365 - val_loss: 0.0327 Epoch 4/20 43350/43350 [==============================] - 2s 46us/step - loss: 0.0306 - val_loss: 0.0283 Epoch 5/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0270 - val_loss: 0.0253 Epoch 6/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0248 - val_loss: 0.0237 Epoch 7/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0233 - val_loss: 0.0224 Epoch 8/20 43350/43350 [==============================] - 2s 46us/step - loss: 0.0223 - val_loss: 0.0216 Epoch 9/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0216 - val_loss: 0.0209 Epoch 10/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0208 - val_loss: 0.0205 Epoch 11/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0205 - val_loss: 0.0200 Epoch 12/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0199 - val_loss: 0.0194 Epoch 13/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0201 - val_loss: 0.0197 Epoch 14/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0193 - val_loss: 0.0187 Epoch 15/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0188 - val_loss: 0.0184 Epoch 16/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0184 - val_loss: 0.0181 Epoch 17/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0182 - val_loss: 0.0178 Epoch 18/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0181 - val_loss: 0.0176 Epoch 19/20 43350/43350 [==============================] - 2s 46us/step - loss: 0.0178 - val_loss: 0.0175 Epoch 20/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0175 - val_loss: 0.0171 Visualize Intermediate Layers of AE Visualize intermediate layers In [14]: # compile the model model_2 = Model ( input_layer , latent_view ) model_2 . compile ( optimizer = 'adam' , loss = 'mse' ) In [15]: n = np . random . randint ( 0 , len ( val_x ) - 5 ) f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( val_x_n [ a , :, :, 0 ] . reshape ( 28 , 28 )) plt . show () In [16]: preds = model_2 . predict ( val_x_n [ n : n + 5 ]) preds . shape Out[16]: (5, 4, 4, 16) In [17]: f , ax = plt . subplots ( 16 , 5 ) ax = ax . ravel () f . set_size_inches ( 20 , 40 ) for j in range ( 16 ): for i , a in enumerate ( range ( n , n + 5 )): ax [ j * 5 + i ] . imshow ( preds [ i , :, :, j ]) plt . show () Visualize Samples reconstructed by AE In [18]: n = np . random . randint ( 0 , len ( val_x ) - 5 ) In [19]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( val_x [ a , :, :, 0 ] . reshape ( 28 , 28 )) In [20]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( val_x_n [ a , :, :, 0 ] . reshape ( 28 , 28 )) In [21]: preds = model . predict ( val_x_n [ n : n + 5 ]) f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( preds [ i ] . reshape ( 28 , 28 )) plt . show () Part 3: Exercise: Denoising noisy documents In [22]: TRAIN_IMAGES = glob . glob ( 'data/train/*.png' ) CLEAN_IMAGES = glob . glob ( 'data/train_cleaned/*.png' ) TEST_IMAGES = glob . glob ( 'data/test/*.png' ) In [23]: plt . figure ( figsize = ( 20 , 8 )) img = cv2 . imread ( 'data/train/101.png' , 0 ) plt . imshow ( img , cmap = 'gray' ) print ( img . shape ) (420, 540) In [24]: def load_image ( path ): image_list = np . zeros (( len ( path ), 258 , 540 , 1 )) for i , fig in enumerate ( path ): img = image . load_img ( fig , grayscale = True , target_size = ( 258 , 540 )) x = image . img_to_array ( img ) . astype ( 'float32' ) x = x / 255.0 image_list [ i ] = x return image_list x_train = load_image ( TRAIN_IMAGES ) y_train = load_image ( CLEAN_IMAGES ) x_test = load_image ( TEST_IMAGES ) print ( x_train . shape , x_test . shape ) (144, 258, 540, 1) (72, 258, 540, 1) In [1]: #Todo: Split your dataset into train and val In [2]: #Todo: Visualize your train set In [3]: input_layer = Input ( shape = ( 258 , 540 , 1 )) #Todo: Setup encoder #Hint: Conv2D - > MaxPooling #Todo: Setup decoder #Hint: Conv2D - > Upsampling output_layer = Conv2D ( 1 , ( 3 , 3 ), activation = 'sigmoid' , padding = 'same' )( decoder ) ae = Model ( input_layer , output_layer ) In [4]: #Todo: Compile and summarize your auto encoder In [5]: #Todo: Train your autoencoder In [32]: preds = ae . predict ( x_test ) In [6]: # n = 25 # preds_0 = preds[n] * 255.0 # preds_0 = preds_0.reshape(258, 540) # x_test_0 = x_test[n] * 255.0 # x_test_0 = x_test_0.reshape(258, 540) # plt.imshow(x_test_0, cmap='gray') In [7]: # plt.imshow(preds_0, cmap='gray') Part 4: Generating New Fashion using VAEs Understanding VAEs Reset data In [35]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_x , val_x = train_test_split ( train_x , test_size = 0.2 ) ## create train and validation datasets train_x , val_x = train_test_split ( train_x , test_size = 0.2 ) In [36]: ## normalize and reshape train_x = train_x / 255. val_x = val_x / 255. train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) val_x = val_x . reshape ( - 1 , 28 , 28 , 1 ) Setup Encoder Neural Network Try different number of hidden layers, nodes? In [37]: import keras.backend as K In [38]: batch_size = 16 latent_dim = 2 # Number of latent dimension parameters input_img = Input ( shape = ( 784 ,), name = \"input\" ) x = Dense ( 512 , activation = 'relu' , name = \"intermediate_encoder\" )( input_img ) x = Dense ( 2 , activation = 'relu' , name = \"latent_encoder\" )( x ) z_mu = Dense ( latent_dim )( x ) z_log_sigma = Dense ( latent_dim )( x ) In [39]: # sampling function def sampling ( args ): z_mu , z_log_sigma = args epsilon = K . random_normal ( shape = ( K . shape ( z_mu )[ 0 ], latent_dim ), mean = 0. , stddev = 1. ) return z_mu + K . exp ( z_log_sigma ) * epsilon # sample vector from the latent distribution z = Lambda ( sampling )([ z_mu , z_log_sigma ]) In [40]: # decoder takes the latent distribution sample as input decoder_input = Input (( 2 ,), name = \"input_decoder\" ) x = Dense ( 512 , activation = 'relu' , name = \"intermediate_decoder\" , input_shape = ( 2 ,))( decoder_input ) # Expand to 784 total pixels x = Dense ( 784 , activation = 'sigmoid' , name = \"original_decoder\" )( x ) # decoder model statement decoder = Model ( decoder_input , x ) # apply the decoder to the sample from the latent distribution z_decoded = decoder ( z ) In [41]: decoder . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_decoder (InputLayer) (None, 2) 0 _________________________________________________________________ intermediate_decoder (Dense) (None, 512) 1536 _________________________________________________________________ original_decoder (Dense) (None, 784) 402192 ================================================================= Total params: 403,728 Trainable params: 403,728 Non-trainable params: 0 _________________________________________________________________ In [42]: # construct a custom layer to calculate the loss class CustomVariationalLayer ( Layer ): def vae_loss ( self , x , z_decoded ): x = K . flatten ( x ) z_decoded = K . flatten ( z_decoded ) # Reconstruction loss xent_loss = binary_crossentropy ( x , z_decoded ) return xent_loss # adds the custom loss to the class def call ( self , inputs ): x = inputs [ 0 ] z_decoded = inputs [ 1 ] loss = self . vae_loss ( x , z_decoded ) self . add_loss ( loss , inputs = inputs ) return x # apply the custom loss to the input images and the decoded latent distribution sample y = CustomVariationalLayer ()([ input_img , z_decoded ]) In [43]: z_decoded Out[43]: In [44]: # VAE model statement vae = Model ( input_img , y ) vae . compile ( optimizer = 'rmsprop' , loss = None ) In [45]: vae . summary () __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input (InputLayer) (None, 784) 0 __________________________________________________________________________________________________ intermediate_encoder (Dense) (None, 512) 401920 input[0][0] __________________________________________________________________________________________________ latent_encoder (Dense) (None, 2) 1026 intermediate_encoder[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 2) 6 latent_encoder[0][0] __________________________________________________________________________________________________ dense_2 (Dense) (None, 2) 6 latent_encoder[0][0] __________________________________________________________________________________________________ lambda_1 (Lambda) (None, 2) 0 dense_1[0][0] dense_2[0][0] __________________________________________________________________________________________________ model_4 (Model) (None, 784) 403728 lambda_1[0][0] __________________________________________________________________________________________________ custom_variational_layer_1 (Cus [(None, 784), (None, 0 input[0][0] model_4[1][0] ================================================================================================== Total params: 806,686 Trainable params: 806,686 Non-trainable params: 0 __________________________________________________________________________________________________ In [46]: train_x . shape Out[46]: (38400, 28, 28, 1) In [47]: train_x = train_x . reshape ( - 1 , 784 ) val_x = val_x . reshape ( - 1 , 784 ) In [48]: vae . fit ( x = train_x , y = None , shuffle = True , epochs = 20 , batch_size = batch_size , validation_data = ( val_x , None )) Train on 38400 samples, validate on 9600 samples Epoch 1/20 38400/38400 [==============================] - 10s 256us/step - loss: 0.4055 - val_loss: 0.3847 Epoch 2/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3805 - val_loss: 0.3773 Epoch 3/20 38400/38400 [==============================] - 9s 243us/step - loss: 0.3594 - val_loss: 0.3461 Epoch 4/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3448 - val_loss: 0.3408 Epoch 5/20 38400/38400 [==============================] - 9s 241us/step - loss: 0.3403 - val_loss: 0.3371 Epoch 6/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3378 - val_loss: 0.3378 Epoch 7/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3363 - val_loss: 0.3334 Epoch 8/20 38400/38400 [==============================] - 9s 241us/step - loss: 0.3351 - val_loss: 0.3337 Epoch 9/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3340 - val_loss: 0.3343 Epoch 10/20 38400/38400 [==============================] - 9s 243us/step - loss: 0.3329 - val_loss: 0.3347 Epoch 11/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3323 - val_loss: 0.3310 Epoch 12/20 38400/38400 [==============================] - 9s 243us/step - loss: 0.3318 - val_loss: 0.3324 Epoch 13/20 38400/38400 [==============================] - 9s 246us/step - loss: 0.3313 - val_loss: 0.3304 Epoch 14/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3310 - val_loss: 0.3312 Epoch 15/20 38400/38400 [==============================] - 9s 241us/step - loss: 0.3307 - val_loss: 0.3344 Epoch 16/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3305 - val_loss: 0.3299 Epoch 17/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3301 - val_loss: 0.3291 Epoch 18/20 38400/38400 [==============================] - 9s 241us/step - loss: 0.3298 - val_loss: 0.3300 Epoch 19/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3297 - val_loss: 0.3290 Epoch 20/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3294 - val_loss: 0.3296 Out[48]: In [49]: # Display a 2D manifold of the samples n = 20 # figure with 20x20 samples digit_size = 28 figure = np . zeros (( digit_size * n , digit_size * n )) # Construct grid of latent variable values - can change values here to generate different things grid_x = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) grid_y = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) # decode for each square in the grid for i , yi in enumerate ( grid_x ): for j , xi in enumerate ( grid_y ): z_sample = np . array ([[ xi , yi ]]) z_sample = np . tile ( z_sample , batch_size ) . reshape ( batch_size , 2 ) x_decoded = decoder . predict ( z_sample , batch_size = batch_size ) digit = x_decoded [ 0 ] . reshape ( digit_size , digit_size ) figure [ i * digit_size : ( i + 1 ) * digit_size , j * digit_size : ( j + 1 ) * digit_size ] = digit plt . figure ( figsize = ( 20 , 20 )) plt . imshow ( figure ) plt . show () In [50]: ### read dataset train = pd . read_csv ( \"fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_y = train [ list ( train . columns )[ 0 ]] . values train_x = train_x / 255. # train_x = train_x.reshape(-1, 28, 28, 1) # Translate into the latent space encoder = Model ( input_img , z_mu ) x_valid_noTest_encoded = encoder . predict ( train_x , batch_size = batch_size ) plt . figure ( figsize = ( 10 , 10 )) plt . scatter ( x_valid_noTest_encoded [:, 0 ], x_valid_noTest_encoded [:, 1 ], c = train_y , cmap = 'brg' ) plt . colorbar () plt . show () Part 5: Exercise: Generating New Fashion using VAEs: Adding CNNs and KL Divergence Loss In [8]: batch_size = 16 latent_dim = 2 # Number of latent dimension parameters # Hint: Encoder architecture: Input -> Conv2D*4 -> Flatten -> Dense input_img = Input ( shape = ( 28 , 28 , 1 )) #Todo: Setup encoder network shape_before_flattening = K . int_shape ( x ) x = Flatten ()( x ) x = Dense ( 32 , activation = 'relu' )( x ) # Two outputs, latent mean and (log)variance z_mu = Dense ( latent_dim )( x ) z_log_sigma = Dense ( latent_dim )( x ) Set up sampling function In [52]: # sampling function def sampling ( args ): z_mu , z_log_sigma = args epsilon = K . random_normal ( shape = ( K . shape ( z_mu )[ 0 ], latent_dim ), mean = 0. , stddev = 1. ) return z_mu + K . exp ( z_log_sigma ) * epsilon # sample vector from the latent distribution z = Lambda ( sampling )([ z_mu , z_log_sigma ]) Setup Decoder Neural Network Try different number of hidden layers, nodes? In [9]: # decoder takes the latent distribution sample as input decoder_input = Input ( K . int_shape ( z )[ 1 :]) #Todo: Setup decoder network #Hint Expand to 784 pixels -> reshape -> Conv2Dtranspose -> conv2D # decoder model statement decoder = Model ( decoder_input , x ) # apply the decoder to the sample from the latent distribution z_decoded = decoder ( z ) Set up loss functions In [54]: # construct a custom layer to calculate the loss class CustomVariationalLayer ( Layer ): def vae_loss ( self , x , z_decoded ): x = K . flatten ( x ) z_decoded = K . flatten ( z_decoded ) # Reconstruction loss xent_loss = binary_crossentropy ( x , z_decoded ) # KL divergence kl_loss = - 5e-4 * K . mean ( 1 + z_log_sigma - K . square ( z_mu ) - K . exp ( z_log_sigma ), axis =- 1 ) return K . mean ( xent_loss + kl_loss ) # adds the custom loss to the class def call ( self , inputs ): x = inputs [ 0 ] z_decoded = inputs [ 1 ] loss = self . vae_loss ( x , z_decoded ) self . add_loss ( loss , inputs = inputs ) return x # apply the custom loss to the input images and the decoded latent distribution sample y = CustomVariationalLayer ()([ input_img , z_decoded ]) Train VAE In [55]: # VAE model statement vae = Model ( input_img , y ) vae . compile ( optimizer = 'rmsprop' , loss = None ) In [10]: vae . summary () In [57]: train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) val_x = val_x . reshape ( - 1 , 28 , 28 , 1 ) In [11]: vae . fit ( x = train_x , y = None , shuffle = True , epochs = 20 , batch_size = batch_size , validation_data = ( val_x , None )) Visualize Samples reconstructed by VAE In [12]: # Display a 2D manifold of the samples n = 20 # figure with 20x20 samples digit_size = 28 figure = np . zeros (( digit_size * n , digit_size * n )) # Construct grid of latent variable values - can change values here to generate different things grid_x = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) grid_y = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) # decode for each square in the grid for i , yi in enumerate ( grid_x ): for j , xi in enumerate ( grid_y ): z_sample = np . array ([[ xi , yi ]]) z_sample = np . tile ( z_sample , batch_size ) . reshape ( batch_size , 2 ) x_decoded = decoder . predict ( z_sample , batch_size = batch_size ) digit = x_decoded [ 0 ] . reshape ( digit_size , digit_size ) figure [ i * digit_size : ( i + 1 ) * digit_size , j * digit_size : ( j + 1 ) * digit_size ] = digit plt . figure ( figsize = ( 20 , 20 )) plt . imshow ( figure ) plt . show () Exercise: Visualize latent space In [60]: train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) In [61]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_y = train [ list ( train . columns )[ 0 ]] . values train_x = train_x / 255. train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) In [13]: # Translate into the latent space encoder = Model ( input_img , z_mu ) x_valid_noTest_encoded = encoder . predict ( train_x , batch_size = batch_size ) plt . figure ( figsize = ( 10 , 10 )) plt . scatter ( x_valid_noTest_encoded [:, 0 ], x_valid_noTest_encoded [:, 1 ], c = train_y , cmap = 'brg' ) plt . colorbar () plt . show () if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab10/VAE/"},{"title":"Lab 10: Autoencoders and Variational Autoencoders","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 10 - Autoencoders and Variational Autoencoders Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas In [1]: # !pip install imgaug In [2]: ## load the libraries import sys import warnings import os import glob warnings . filterwarnings ( \"ignore\" ) import numpy as np import pandas as pd import cv2 from sklearn.model_selection import train_test_split from keras.layers import * from keras.callbacks import EarlyStopping from keras.utils import to_categorical from keras.models import Model , Sequential from keras.metrics import * from keras.optimizers import Adam , RMSprop from scipy.stats import norm from keras.preprocessing import image from keras import backend as K from imgaug import augmenters import matplotlib.pyplot as plt plt . gray () Using TensorFlow backend. Part 1: Data Reading data Download the data given at the following link: . Use pandas and numpy to read in the data as a matrix In [3]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_x , val_x = train_test_split ( train_x , test_size = 0.15 ) ## create train and validation datasets train_x , val_x = train_test_split ( train_x , test_size = 0.15 ) In [4]: ## normalize and reshape train_x = train_x / 255. val_x = val_x / 255. train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) val_x = val_x . reshape ( - 1 , 28 , 28 , 1 ) In [5]: train_x . shape Out[5]: (43350, 28, 28, 1) Visualizing Samples Visualize 10 images from dataset In [6]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i in range ( 5 , 10 ): ax [ i - 5 ] . imshow ( train_x [ i , :, :, 0 ] . reshape ( 28 , 28 )) Part 2: Denoise Images using AEs Understanding AEs Add Noise to Images Check out imgaug docs for more info and other ways to add noise. In [7]: # Lets add sample noise - Salt and Pepper noise = augmenters . SaltAndPepper ( 0.1 ) seq_object = augmenters . Sequential ([ noise ]) train_x_n = seq_object . augment_images ( train_x * 255 ) / 255 val_x_n = seq_object . augment_images ( val_x * 255 ) / 255 In [8]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i in range ( 5 , 10 ): ax [ i - 5 ] . imshow ( train_x_n [ i , :, :, 0 ] . reshape ( 28 , 28 )) Setup Encoder Neural Network Try different number of hidden layers, nodes? In [9]: # input layer input_layer = Input ( shape = ( 28 , 28 , 1 )) # encoding architecture encoded_layer1 = Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( input_layer ) encoded_layer1 = MaxPool2D ( ( 2 , 2 ), padding = 'same' )( encoded_layer1 ) encoded_layer2 = Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( encoded_layer1 ) encoded_layer2 = MaxPool2D ( ( 2 , 2 ), padding = 'same' )( encoded_layer2 ) encoded_layer3 = Conv2D ( 16 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( encoded_layer2 ) latent_view = MaxPool2D ( ( 2 , 2 ), padding = 'same' )( encoded_layer3 ) Setup Decoder Neural Network Try different number of hidden layers, nodes? In [10]: # decoding architecture decoded_layer1 = Conv2D ( 16 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( latent_view ) decoded_layer1 = UpSampling2D (( 2 , 2 ))( decoded_layer1 ) decoded_layer2 = Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( decoded_layer1 ) decoded_layer2 = UpSampling2D (( 2 , 2 ))( decoded_layer2 ) decoded_layer3 = Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )( decoded_layer2 ) decoded_layer3 = UpSampling2D (( 2 , 2 ))( decoded_layer3 ) output_layer = Conv2D ( 1 , ( 3 , 3 ), padding = 'same' )( decoded_layer3 ) Train AE In [11]: # compile the model model = Model ( input_layer , output_layer ) model . compile ( optimizer = 'adam' , loss = 'mse' ) In [12]: model . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_1 (InputLayer) (None, 28, 28, 1) 0 _________________________________________________________________ conv2d_1 (Conv2D) (None, 28, 28, 64) 640 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 14, 14, 32) 18464 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 7, 7, 16) 4624 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 4, 4, 16) 0 _________________________________________________________________ conv2d_4 (Conv2D) (None, 4, 4, 16) 2320 _________________________________________________________________ up_sampling2d_1 (UpSampling2 (None, 8, 8, 16) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 8, 8, 32) 4640 _________________________________________________________________ up_sampling2d_2 (UpSampling2 (None, 16, 16, 32) 0 _________________________________________________________________ conv2d_6 (Conv2D) (None, 14, 14, 64) 18496 _________________________________________________________________ up_sampling2d_3 (UpSampling2 (None, 28, 28, 64) 0 _________________________________________________________________ conv2d_7 (Conv2D) (None, 28, 28, 1) 577 ================================================================= Total params: 49,761 Trainable params: 49,761 Non-trainable params: 0 _________________________________________________________________ In [13]: early_stopping = EarlyStopping ( monitor = 'val_loss' , min_delta = 0 , patience = 10 , verbose = 5 , mode = 'auto' ) history = model . fit ( train_x_n , train_x , epochs = 20 , batch_size = 2048 , validation_data = ( val_x_n , val_x ), callbacks = [ early_stopping ]) Train on 43350 samples, validate on 7650 samples Epoch 1/20 43350/43350 [==============================] - 7s 154us/step - loss: 0.1083 - val_loss: 0.0654 Epoch 2/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0480 - val_loss: 0.0390 Epoch 3/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0356 - val_loss: 0.0326 Epoch 4/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0303 - val_loss: 0.0281 Epoch 5/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0264 - val_loss: 0.0248 Epoch 6/20 43350/43350 [==============================] - 2s 46us/step - loss: 0.0238 - val_loss: 0.0230 Epoch 7/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0223 - val_loss: 0.0217 Epoch 8/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0213 - val_loss: 0.0208 Epoch 9/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0205 - val_loss: 0.0201 Epoch 10/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0199 - val_loss: 0.0197 Epoch 11/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0193 - val_loss: 0.0191 Epoch 12/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0189 - val_loss: 0.0187 Epoch 13/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0184 - val_loss: 0.0182 Epoch 14/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0182 - val_loss: 0.0184 Epoch 15/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0179 - val_loss: 0.0176 Epoch 16/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0175 - val_loss: 0.0174 Epoch 17/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0174 - val_loss: 0.0172 Epoch 18/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0171 - val_loss: 0.0170 Epoch 19/20 43350/43350 [==============================] - 2s 48us/step - loss: 0.0169 - val_loss: 0.0167 Epoch 20/20 43350/43350 [==============================] - 2s 47us/step - loss: 0.0167 - val_loss: 0.0166 Visualize Intermediate Layers of AE Visualize intermediate layers In [14]: # compile the model model_2 = Model ( input_layer , latent_view ) model_2 . compile ( optimizer = 'adam' , loss = 'mse' ) In [15]: n = np . random . randint ( 0 , len ( val_x ) - 5 ) f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( val_x_n [ a , :, :, 0 ] . reshape ( 28 , 28 )) plt . show () In [16]: preds = model_2 . predict ( val_x_n [ n : n + 5 ]) preds . shape Out[16]: (5, 4, 4, 16) In [17]: f , ax = plt . subplots ( 16 , 5 ) ax = ax . ravel () f . set_size_inches ( 20 , 40 ) for j in range ( 16 ): for i , a in enumerate ( range ( n , n + 5 )): ax [ j * 5 + i ] . imshow ( preds [ i , :, :, j ]) plt . show () Visualize Samples reconstructed by AE In [18]: n = np . random . randint ( 0 , len ( val_x ) - 5 ) In [19]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( val_x [ a , :, :, 0 ] . reshape ( 28 , 28 )) In [20]: f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( val_x_n [ a , :, :, 0 ] . reshape ( 28 , 28 )) In [21]: preds = model . predict ( val_x_n [ n : n + 5 ]) f , ax = plt . subplots ( 1 , 5 ) f . set_size_inches ( 80 , 40 ) for i , a in enumerate ( range ( n , n + 5 )): ax [ i ] . imshow ( preds [ i ] . reshape ( 28 , 28 )) plt . show () Part 3: Exercise: Denoising noisy documents In [22]: TRAIN_IMAGES = glob . glob ( 'data/train/*.png' ) CLEAN_IMAGES = glob . glob ( 'data/train_cleaned/*.png' ) TEST_IMAGES = glob . glob ( 'data/test/*.png' ) In [23]: plt . figure ( figsize = ( 20 , 8 )) img = cv2 . imread ( 'data/train/101.png' , 0 ) plt . imshow ( img , cmap = 'gray' ) print ( img . shape ) (420, 540) In [24]: def load_image ( path ): image_list = np . zeros (( len ( path ), 258 , 540 , 1 )) for i , fig in enumerate ( path ): img = image . load_img ( fig , grayscale = True , target_size = ( 258 , 540 )) x = image . img_to_array ( img ) . astype ( 'float32' ) x = x / 255.0 image_list [ i ] = x return image_list x_train = load_image ( TRAIN_IMAGES ) y_train = load_image ( CLEAN_IMAGES ) x_test = load_image ( TEST_IMAGES ) print ( x_train . shape , x_test . shape ) (144, 258, 540, 1) (72, 258, 540, 1) In [25]: x_train . shape Out[25]: (144, 258, 540, 1) In [26]: x_train , x_val , y_train , y_val = train_test_split ( x_train , y_train , test_size = 0.15 ) print ( x_train . shape , x_val . shape ) (122, 258, 540, 1) (22, 258, 540, 1) In [27]: plt . imshow ( x_train [ 0 , :, :, 0 ]) Out[27]: In [28]: plt . imshow ( y_train [ 0 , :, :, 0 ]) Out[28]: In [29]: input_layer = Input ( shape = ( 258 , 540 , 1 )) # encoder encoder = Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( input_layer ) encoder = MaxPooling2D (( 2 , 2 ), padding = 'same' )( encoder ) # decoder decoder = Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' , padding = 'same' )( encoder ) decoder = UpSampling2D (( 2 , 2 ))( decoder ) output_layer = Conv2D ( 1 , ( 3 , 3 ), activation = 'sigmoid' , padding = 'same' )( decoder ) ae = Model ( input_layer , output_layer ) In [30]: ae . compile ( loss = 'mse' , optimizer = Adam ( lr = 0.001 )) ae . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) (None, 258, 540, 1) 0 _________________________________________________________________ conv2d_8 (Conv2D) (None, 258, 540, 64) 640 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 129, 270, 64) 0 _________________________________________________________________ conv2d_9 (Conv2D) (None, 129, 270, 64) 36928 _________________________________________________________________ up_sampling2d_4 (UpSampling2 (None, 258, 540, 64) 0 _________________________________________________________________ conv2d_10 (Conv2D) (None, 258, 540, 1) 577 ================================================================= Total params: 38,145 Trainable params: 38,145 Non-trainable params: 0 _________________________________________________________________ In [31]: batch_size = 16 epochs = 200 early_stopping = EarlyStopping ( monitor = 'val_loss' , min_delta = 0 , patience = 5 , verbose = 1 , mode = 'auto' ) history = ae . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , validation_data = ( x_val , y_val ), callbacks = [ early_stopping ]) Train on 122 samples, validate on 22 samples Epoch 1/200 122/122 [==============================] - 2s 17ms/step - loss: 0.1448 - val_loss: 0.0700 Epoch 2/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0729 - val_loss: 0.0763 Epoch 3/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0772 - val_loss: 0.0742 Epoch 4/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0700 - val_loss: 0.0643 Epoch 5/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0624 - val_loss: 0.0576 Epoch 6/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0546 - val_loss: 0.0491 Epoch 7/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0453 - val_loss: 0.0395 Epoch 8/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0374 - val_loss: 0.0331 Epoch 9/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0323 - val_loss: 0.0290 Epoch 10/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0288 - val_loss: 0.0260 Epoch 11/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0262 - val_loss: 0.0238 Epoch 12/200 122/122 [==============================] - 1s 9ms/step - loss: 0.0241 - val_loss: 0.0218 Epoch 13/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0222 - val_loss: 0.0201 Epoch 14/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0205 - val_loss: 0.0184 Epoch 15/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0189 - val_loss: 0.0171 Epoch 16/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0178 - val_loss: 0.0158 Epoch 17/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0165 - val_loss: 0.0148 Epoch 18/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0156 - val_loss: 0.0140 Epoch 19/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0146 - val_loss: 0.0134 Epoch 20/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0139 - val_loss: 0.0125 Epoch 21/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0131 - val_loss: 0.0116 Epoch 22/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0124 - val_loss: 0.0111 Epoch 23/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0119 - val_loss: 0.0106 Epoch 24/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0114 - val_loss: 0.0101 Epoch 25/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0108 - val_loss: 0.0097 Epoch 26/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0104 - val_loss: 0.0094 Epoch 27/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0101 - val_loss: 0.0091 Epoch 28/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0099 - val_loss: 0.0086 Epoch 29/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0095 - val_loss: 0.0084 Epoch 30/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0092 - val_loss: 0.0081 Epoch 31/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0089 - val_loss: 0.0079 Epoch 32/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0087 - val_loss: 0.0077 Epoch 33/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0085 - val_loss: 0.0075 Epoch 34/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0082 - val_loss: 0.0073 Epoch 35/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0080 - val_loss: 0.0072 Epoch 36/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0071 Epoch 37/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0079 - val_loss: 0.0070 Epoch 38/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0077 - val_loss: 0.0070 Epoch 39/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0076 - val_loss: 0.0066 Epoch 40/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0073 - val_loss: 0.0064 Epoch 41/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0071 - val_loss: 0.0064 Epoch 42/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0064 Epoch 43/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0070 - val_loss: 0.0062 Epoch 44/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0060 Epoch 45/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0068 - val_loss: 0.0060 Epoch 46/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0067 - val_loss: 0.0059 Epoch 47/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0065 - val_loss: 0.0057 Epoch 48/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0057 Epoch 49/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0056 Epoch 50/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0063 - val_loss: 0.0055 Epoch 51/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0064 - val_loss: 0.0059 Epoch 52/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0062 - val_loss: 0.0055 Epoch 53/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0060 - val_loss: 0.0053 Epoch 54/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0059 - val_loss: 0.0052 Epoch 55/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0058 - val_loss: 0.0052 Epoch 56/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0051 Epoch 57/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0057 - val_loss: 0.0050 Epoch 58/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0050 Epoch 59/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0056 - val_loss: 0.0050 Epoch 60/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0055 - val_loss: 0.0050 Epoch 61/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0054 - val_loss: 0.0048 Epoch 62/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0047 Epoch 63/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0053 - val_loss: 0.0048 Epoch 64/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0052 - val_loss: 0.0046 Epoch 65/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0046 Epoch 66/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0051 - val_loss: 0.0045 Epoch 67/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0045 Epoch 68/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0050 - val_loss: 0.0044 Epoch 69/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0044 Epoch 70/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0049 - val_loss: 0.0043 Epoch 71/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0044 Epoch 72/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0048 - val_loss: 0.0044 Epoch 73/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0047 - val_loss: 0.0042 Epoch 74/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0041 Epoch 75/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0046 - val_loss: 0.0041 Epoch 76/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0041 Epoch 77/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0040 Epoch 78/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0041 Epoch 79/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0045 - val_loss: 0.0039 Epoch 80/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0041 Epoch 81/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0044 - val_loss: 0.0039 Epoch 82/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0043 - val_loss: 0.0038 Epoch 83/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0038 Epoch 84/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0038 Epoch 85/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0042 - val_loss: 0.0037 Epoch 86/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0037 Epoch 87/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0037 Epoch 88/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0041 - val_loss: 0.0037 Epoch 89/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0036 Epoch 90/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0036 Epoch 91/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0035 Epoch 92/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0039 - val_loss: 0.0035 Epoch 93/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0035 Epoch 94/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0034 Epoch 95/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0038 - val_loss: 0.0034 Epoch 96/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0034 Epoch 97/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0033 Epoch 98/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0037 - val_loss: 0.0033 Epoch 99/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0033 Epoch 100/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0033 Epoch 101/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0033 Epoch 102/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0032 Epoch 103/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0032 Epoch 104/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0031 Epoch 105/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0033 Epoch 106/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0035 - val_loss: 0.0031 Epoch 107/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0031 Epoch 108/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0032 Epoch 109/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0034 - val_loss: 0.0030 Epoch 110/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0031 Epoch 111/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0030 Epoch 112/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0030 Epoch 113/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0031 Epoch 114/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0033 - val_loss: 0.0029 Epoch 115/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 116/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 117/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 118/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 119/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 120/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 121/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0032 - val_loss: 0.0029 Epoch 122/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0028 Epoch 123/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0028 Epoch 124/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0028 Epoch 125/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0031 - val_loss: 0.0029 Epoch 126/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 Epoch 127/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 Epoch 128/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0027 Epoch 129/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 Epoch 130/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0027 Epoch 131/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0028 Epoch 132/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0029 Epoch 133/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0027 Epoch 134/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0028 Epoch 135/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0030 - val_loss: 0.0027 Epoch 136/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0026 Epoch 137/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0026 Epoch 138/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0029 - val_loss: 0.0026 Epoch 139/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 140/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 141/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 142/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 143/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 144/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0025 Epoch 145/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 146/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0025 Epoch 147/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0026 Epoch 148/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0028 - val_loss: 0.0025 Epoch 149/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 150/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 151/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 152/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 153/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 154/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 155/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0024 Epoch 156/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0025 Epoch 157/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0024 Epoch 158/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0025 Epoch 159/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024 Epoch 160/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0027 - val_loss: 0.0024 Epoch 161/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0025 Epoch 162/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024 Epoch 163/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0026 - val_loss: 0.0024 Epoch 164/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 165/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 166/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 167/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 168/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 169/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 170/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 171/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0024 Epoch 172/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 173/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 174/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 175/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0023 Epoch 176/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 177/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 178/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0024 Epoch 179/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 180/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 181/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 182/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 183/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 184/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 185/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 186/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 187/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 188/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 189/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0022 Epoch 190/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0023 Epoch 191/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0022 Epoch 192/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0025 - val_loss: 0.0021 Epoch 193/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0022 Epoch 194/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0022 Epoch 195/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021 Epoch 196/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0023 Epoch 197/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0023 Epoch 198/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0024 - val_loss: 0.0021 Epoch 199/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021 Epoch 200/200 122/122 [==============================] - 1s 8ms/step - loss: 0.0023 - val_loss: 0.0021 Epoch 00200: early stopping In [32]: preds = ae . predict ( x_test ) In [33]: n = 25 preds_0 = preds [ n ] * 255.0 preds_0 = preds_0 . reshape ( 258 , 540 ) x_test_0 = x_test [ n ] * 255.0 x_test_0 = x_test_0 . reshape ( 258 , 540 ) plt . imshow ( x_test_0 , cmap = 'gray' ) Out[33]: In [34]: plt . imshow ( preds_0 , cmap = 'gray' ) Out[34]: Part 4: Generating New Fashion using VAEs Understanding VAEs Reset data In [35]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_x , val_x = train_test_split ( train_x , test_size = 0.2 ) ## create train and validation datasets train_x , val_x = train_test_split ( train_x , test_size = 0.2 ) In [36]: ## normalize and reshape train_x = train_x / 255. val_x = val_x / 255. train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) val_x = val_x . reshape ( - 1 , 28 , 28 , 1 ) Setup Encoder Neural Network Try different number of hidden layers, nodes? In [37]: import keras.backend as K In [38]: batch_size = 16 latent_dim = 2 # Number of latent dimension parameters input_img = Input ( shape = ( 784 ,), name = \"input\" ) x = Dense ( 512 , activation = 'relu' , name = \"intermediate_encoder\" )( input_img ) x = Dense ( 2 , activation = 'relu' , name = \"latent_encoder\" )( x ) z_mu = Dense ( latent_dim )( x ) z_log_sigma = Dense ( latent_dim )( x ) In [39]: # sampling function def sampling ( args ): z_mu , z_log_sigma = args epsilon = K . random_normal ( shape = ( K . shape ( z_mu )[ 0 ], latent_dim ), mean = 0. , stddev = 1. ) return z_mu + K . exp ( z_log_sigma ) * epsilon # sample vector from the latent distribution z = Lambda ( sampling )([ z_mu , z_log_sigma ]) In [40]: # decoder takes the latent distribution sample as input decoder_input = Input (( 2 ,), name = \"input_decoder\" ) x = Dense ( 512 , activation = 'relu' , name = \"intermediate_decoder\" , input_shape = ( 2 ,))( decoder_input ) # Expand to 784 total pixels x = Dense ( 784 , activation = 'sigmoid' , name = \"original_decoder\" )( x ) # decoder model statement decoder = Model ( decoder_input , x ) # apply the decoder to the sample from the latent distribution z_decoded = decoder ( z ) In [41]: decoder . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_decoder (InputLayer) (None, 2) 0 _________________________________________________________________ intermediate_decoder (Dense) (None, 512) 1536 _________________________________________________________________ original_decoder (Dense) (None, 784) 402192 ================================================================= Total params: 403,728 Trainable params: 403,728 Non-trainable params: 0 _________________________________________________________________ In [42]: # construct a custom layer to calculate the loss class CustomVariationalLayer ( Layer ): def vae_loss ( self , x , z_decoded ): x = K . flatten ( x ) z_decoded = K . flatten ( z_decoded ) # Reconstruction loss xent_loss = binary_crossentropy ( x , z_decoded ) return xent_loss # adds the custom loss to the class def call ( self , inputs ): x = inputs [ 0 ] z_decoded = inputs [ 1 ] loss = self . vae_loss ( x , z_decoded ) self . add_loss ( loss , inputs = inputs ) return x # apply the custom loss to the input images and the decoded latent distribution sample y = CustomVariationalLayer ()([ input_img , z_decoded ]) In [43]: z_decoded Out[43]: In [44]: # VAE model statement vae = Model ( input_img , y ) vae . compile ( optimizer = 'rmsprop' , loss = None ) In [45]: vae . summary () __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input (InputLayer) (None, 784) 0 __________________________________________________________________________________________________ intermediate_encoder (Dense) (None, 512) 401920 input[0][0] __________________________________________________________________________________________________ latent_encoder (Dense) (None, 2) 1026 intermediate_encoder[0][0] __________________________________________________________________________________________________ dense_1 (Dense) (None, 2) 6 latent_encoder[0][0] __________________________________________________________________________________________________ dense_2 (Dense) (None, 2) 6 latent_encoder[0][0] __________________________________________________________________________________________________ lambda_1 (Lambda) (None, 2) 0 dense_1[0][0] dense_2[0][0] __________________________________________________________________________________________________ model_4 (Model) (None, 784) 403728 lambda_1[0][0] __________________________________________________________________________________________________ custom_variational_layer_1 (Cus [(None, 784), (None, 0 input[0][0] model_4[1][0] ================================================================================================== Total params: 806,686 Trainable params: 806,686 Non-trainable params: 0 __________________________________________________________________________________________________ In [46]: train_x . shape Out[46]: (38400, 28, 28, 1) In [47]: train_x = train_x . reshape ( - 1 , 784 ) val_x = val_x . reshape ( - 1 , 784 ) In [48]: vae . fit ( x = train_x , y = None , shuffle = True , epochs = 20 , batch_size = batch_size , validation_data = ( val_x , None )) Train on 38400 samples, validate on 9600 samples Epoch 1/20 38400/38400 [==============================] - 10s 258us/step - loss: 0.3728 - val_loss: 0.3446 Epoch 2/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3423 - val_loss: 0.3378 Epoch 3/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3369 - val_loss: 0.3380 Epoch 4/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3345 - val_loss: 0.3418 Epoch 5/20 38400/38400 [==============================] - 9s 243us/step - loss: 0.3329 - val_loss: 0.3353 Epoch 6/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3318 - val_loss: 0.3318 Epoch 7/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3309 - val_loss: 0.3307 Epoch 8/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3302 - val_loss: 0.3301 Epoch 9/20 38400/38400 [==============================] - 9s 241us/step - loss: 0.3297 - val_loss: 0.3297 Epoch 10/20 38400/38400 [==============================] - 9s 241us/step - loss: 0.3293 - val_loss: 0.3298 Epoch 11/20 38400/38400 [==============================] - 9s 242us/step - loss: 0.3289 - val_loss: 0.3312 Epoch 12/20 38400/38400 [==============================] - 9s 246us/step - loss: 0.3285 - val_loss: 0.3290 Epoch 13/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3283 - val_loss: 0.3284 Epoch 14/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3279 - val_loss: 0.3311 Epoch 15/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3277 - val_loss: 0.3298 Epoch 16/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3276 - val_loss: 0.3276 Epoch 17/20 38400/38400 [==============================] - 9s 243us/step - loss: 0.3274 - val_loss: 0.3285 Epoch 18/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3273 - val_loss: 0.3287 Epoch 19/20 38400/38400 [==============================] - 9s 245us/step - loss: 0.3271 - val_loss: 0.3292 Epoch 20/20 38400/38400 [==============================] - 9s 244us/step - loss: 0.3269 - val_loss: 0.3278 Out[48]: In [49]: # Display a 2D manifold of the samples n = 20 # figure with 20x20 samples digit_size = 28 figure = np . zeros (( digit_size * n , digit_size * n )) # Construct grid of latent variable values - can change values here to generate different things grid_x = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) grid_y = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) # decode for each square in the grid for i , yi in enumerate ( grid_x ): for j , xi in enumerate ( grid_y ): z_sample = np . array ([[ xi , yi ]]) z_sample = np . tile ( z_sample , batch_size ) . reshape ( batch_size , 2 ) x_decoded = decoder . predict ( z_sample , batch_size = batch_size ) digit = x_decoded [ 0 ] . reshape ( digit_size , digit_size ) figure [ i * digit_size : ( i + 1 ) * digit_size , j * digit_size : ( j + 1 ) * digit_size ] = digit plt . figure ( figsize = ( 20 , 20 )) plt . imshow ( figure ) plt . show () In [50]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_y = train [ list ( train . columns )[ 0 ]] . values train_x = train_x / 255. # train_x = train_x.reshape(-1, 28, 28, 1) # Translate into the latent space encoder = Model ( input_img , z_mu ) x_valid_noTest_encoded = encoder . predict ( train_x , batch_size = batch_size ) plt . figure ( figsize = ( 10 , 10 )) plt . scatter ( x_valid_noTest_encoded [:, 0 ], x_valid_noTest_encoded [:, 1 ], c = train_y , cmap = 'brg' ) plt . colorbar () plt . show () Part 5: Exercise: Generating New Fashion using VAEs: Adding CNNs and KL Divergence Loss In [51]: batch_size = 16 latent_dim = 2 # Number of latent dimension parameters # Encoder architecture: Input -> Conv2D*4 -> Flatten -> Dense input_img = Input ( shape = ( 28 , 28 , 1 )) x = Conv2D ( 32 , 3 , padding = 'same' , activation = 'relu' )( input_img ) x = Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' , strides = ( 2 , 2 ))( x ) x = Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' )( x ) x = Conv2D ( 64 , 3 , padding = 'same' , activation = 'relu' )( x ) # need to know the shape of the network here for the decoder shape_before_flattening = K . int_shape ( x ) x = Flatten ()( x ) x = Dense ( 32 , activation = 'relu' )( x ) # Two outputs, latent mean and (log)variance z_mu = Dense ( latent_dim )( x ) z_log_sigma = Dense ( latent_dim )( x ) Set up sampling function In [52]: # sampling function def sampling ( args ): z_mu , z_log_sigma = args epsilon = K . random_normal ( shape = ( K . shape ( z_mu )[ 0 ], latent_dim ), mean = 0. , stddev = 1. ) return z_mu + K . exp ( z_log_sigma ) * epsilon # sample vector from the latent distribution z = Lambda ( sampling )([ z_mu , z_log_sigma ]) Setup Decoder Neural Network Try different number of hidden layers, nodes? In [53]: # decoder takes the latent distribution sample as input decoder_input = Input ( K . int_shape ( z )[ 1 :]) # Expand to 784 total pixels x = Dense ( np . prod ( shape_before_flattening [ 1 :]), activation = 'relu' )( decoder_input ) # reshape x = Reshape ( shape_before_flattening [ 1 :])( x ) # use Conv2DTranspose to reverse the conv layers from the encoder x = Conv2DTranspose ( 32 , 3 , padding = 'same' , activation = 'relu' , strides = ( 2 , 2 ))( x ) x = Conv2D ( 1 , 3 , padding = 'same' , activation = 'sigmoid' )( x ) # decoder model statement decoder = Model ( decoder_input , x ) # apply the decoder to the sample from the latent distribution z_decoded = decoder ( z ) Set up loss functions In [54]: # construct a custom layer to calculate the loss class CustomVariationalLayer ( Layer ): def vae_loss ( self , x , z_decoded ): x = K . flatten ( x ) z_decoded = K . flatten ( z_decoded ) # Reconstruction loss xent_loss = binary_crossentropy ( x , z_decoded ) # KL divergence kl_loss = - 5e-4 * K . mean ( 1 + z_log_sigma - K . square ( z_mu ) - K . exp ( z_log_sigma ), axis =- 1 ) return K . mean ( xent_loss + kl_loss ) # adds the custom loss to the class def call ( self , inputs ): x = inputs [ 0 ] z_decoded = inputs [ 1 ] loss = self . vae_loss ( x , z_decoded ) self . add_loss ( loss , inputs = inputs ) return x # apply the custom loss to the input images and the decoded latent distribution sample y = CustomVariationalLayer ()([ input_img , z_decoded ]) Train VAE In [55]: # VAE model statement vae = Model ( input_img , y ) vae . compile ( optimizer = 'rmsprop' , loss = None ) In [56]: vae . summary () __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_3 (InputLayer) (None, 28, 28, 1) 0 __________________________________________________________________________________________________ conv2d_11 (Conv2D) (None, 28, 28, 32) 320 input_3[0][0] __________________________________________________________________________________________________ conv2d_12 (Conv2D) (None, 14, 14, 64) 18496 conv2d_11[0][0] __________________________________________________________________________________________________ conv2d_13 (Conv2D) (None, 14, 14, 64) 36928 conv2d_12[0][0] __________________________________________________________________________________________________ conv2d_14 (Conv2D) (None, 14, 14, 64) 36928 conv2d_13[0][0] __________________________________________________________________________________________________ flatten_1 (Flatten) (None, 12544) 0 conv2d_14[0][0] __________________________________________________________________________________________________ dense_3 (Dense) (None, 32) 401440 flatten_1[0][0] __________________________________________________________________________________________________ dense_4 (Dense) (None, 2) 66 dense_3[0][0] __________________________________________________________________________________________________ dense_5 (Dense) (None, 2) 66 dense_3[0][0] __________________________________________________________________________________________________ lambda_2 (Lambda) (None, 2) 0 dense_4[0][0] dense_5[0][0] __________________________________________________________________________________________________ model_7 (Model) (None, 28, 28, 1) 56385 lambda_2[0][0] __________________________________________________________________________________________________ custom_variational_layer_2 (Cus [(None, 28, 28, 1), 0 input_3[0][0] model_7[1][0] ================================================================================================== Total params: 550,629 Trainable params: 550,629 Non-trainable params: 0 __________________________________________________________________________________________________ In [57]: train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) val_x = val_x . reshape ( - 1 , 28 , 28 , 1 ) In [58]: vae . fit ( x = train_x , y = None , shuffle = True , epochs = 20 , batch_size = batch_size , validation_data = ( val_x , None )) Train on 60000 samples, validate on 9600 samples Epoch 1/20 60000/60000 [==============================] - 30s 500us/step - loss: 0.3938 - val_loss: 0.3383 Epoch 2/20 60000/60000 [==============================] - 29s 486us/step - loss: 0.3371 - val_loss: 0.3379 Epoch 3/20 60000/60000 [==============================] - 29s 490us/step - loss: 0.3337 - val_loss: 0.3315 Epoch 4/20 60000/60000 [==============================] - 29s 485us/step - loss: 0.3315 - val_loss: 0.3306 Epoch 5/20 60000/60000 [==============================] - 29s 489us/step - loss: 0.3305 - val_loss: 0.3335 Epoch 6/20 60000/60000 [==============================] - 29s 484us/step - loss: 0.3289 - val_loss: 0.3291 Epoch 7/20 60000/60000 [==============================] - 29s 491us/step - loss: 0.3283 - val_loss: 0.3299 Epoch 8/20 60000/60000 [==============================] - 29s 489us/step - loss: 0.3282 - val_loss: 0.3322 Epoch 9/20 60000/60000 [==============================] - 29s 488us/step - loss: 0.3286 - val_loss: 0.3276 Epoch 10/20 60000/60000 [==============================] - 29s 489us/step - loss: 0.3271 - val_loss: 0.3295 Epoch 11/20 60000/60000 [==============================] - 29s 487us/step - loss: 0.3261 - val_loss: 0.3267 Epoch 12/20 60000/60000 [==============================] - 29s 484us/step - loss: 0.3254 - val_loss: 0.3260 Epoch 13/20 60000/60000 [==============================] - 29s 486us/step - loss: 0.3249 - val_loss: 0.3311 Epoch 14/20 60000/60000 [==============================] - 29s 489us/step - loss: 0.3244 - val_loss: 0.3244 Epoch 15/20 60000/60000 [==============================] - 29s 491us/step - loss: 0.3240 - val_loss: 0.3251 Epoch 16/20 60000/60000 [==============================] - 29s 487us/step - loss: 0.3237 - val_loss: 0.3240 Epoch 17/20 60000/60000 [==============================] - 29s 491us/step - loss: 0.3234 - val_loss: 0.3231 Epoch 18/20 60000/60000 [==============================] - 29s 489us/step - loss: 0.3232 - val_loss: 0.3233 Epoch 19/20 60000/60000 [==============================] - 29s 488us/step - loss: 0.3230 - val_loss: 0.3236 Epoch 20/20 60000/60000 [==============================] - 29s 489us/step - loss: 0.3227 - val_loss: 0.3231 Out[58]: Visualize Samples reconstructed by VAE In [59]: # Display a 2D manifold of the samples n = 20 # figure with 20x20 samples digit_size = 28 figure = np . zeros (( digit_size * n , digit_size * n )) # Construct grid of latent variable values - can change values here to generate different things grid_x = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) grid_y = norm . ppf ( np . linspace ( 0.05 , 0.95 , n )) # decode for each square in the grid for i , yi in enumerate ( grid_x ): for j , xi in enumerate ( grid_y ): z_sample = np . array ([[ xi , yi ]]) z_sample = np . tile ( z_sample , batch_size ) . reshape ( batch_size , 2 ) x_decoded = decoder . predict ( z_sample , batch_size = batch_size ) digit = x_decoded [ 0 ] . reshape ( digit_size , digit_size ) figure [ i * digit_size : ( i + 1 ) * digit_size , j * digit_size : ( j + 1 ) * digit_size ] = digit plt . figure ( figsize = ( 20 , 20 )) plt . imshow ( figure ) plt . show () TODO: VAE: Visualize latent space In [60]: train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) In [61]: ### read dataset train = pd . read_csv ( \"data/fashion-mnist_train.csv\" ) train_x = train [ list ( train . columns )[ 1 :]] . values train_y = train [ list ( train . columns )[ 0 ]] . values train_x = train_x / 255. train_x = train_x . reshape ( - 1 , 28 , 28 , 1 ) In [62]: # Translate into the latent space encoder = Model ( input_img , z_mu ) x_valid_noTest_encoded = encoder . predict ( train_x , batch_size = batch_size ) plt . figure ( figsize = ( 10 , 10 )) plt . scatter ( x_valid_noTest_encoded [:, 0 ], x_valid_noTest_encoded [:, 1 ], c = train_y , cmap = 'brg' ) plt . colorbar () plt . show () if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab10/VAE-solutions/"},{"title":"Advanced Section 7: VAE","text":"Slides PDF Notes Notes","tags":"A-sections","url":"a-sections/a-section7/"},{"title":"Lecture 19: Variational Autoencoders","text":"Slides Lecture 19 PDF Lecture 19 PPTX","tags":"pages","url":"pages/lecture19/"},{"title":"Lecture 18: Autoencoders","text":"Slides Lecture 18 PDF Lecture 18 PPTX","tags":"pages","url":"pages/lecture18/"},{"title":"Lecture 18 Notebook","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lecture 18: Autoencoders Example Harvard University Spring 2019 Instructors: Pavlos Protopapas and Mark Glickman Code and ideas taken/borrowed/adapted from Deep Learning From Basics to Practice, by Andrew Glassner, https://dlbasics.com , http://glassner.com , Python utilities for saving and loading files, mostly images and Keras model weights In [11]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[11]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [12]: from keras.datasets import mnist from keras.models import Sequential , Model from keras.layers import Dense import numpy as np #import h5py #from pathlib import Path import matplotlib.pyplot as plt from keras import backend as keras_backend keras_backend . set_image_data_format ( 'channels_last' ) In [13]: # I will be saving everything so I can re-use them save_files = True import os , sys , inspect current_dir = os . path . dirname ( os . path . abspath ( inspect . getfile ( inspect . currentframe ()))) sys . path . insert ( 0 , os . path . dirname ( current_dir )) # path to parent dir from DLBasics_Utilities import File_Helper file_helper = File_Helper ( save_files ) In [14]: random_seed = 52 np . random . seed ( random_seed ) # Read MNIST data. Of course we will not be using y_train and y_test ( X_train , y_train ), ( X_test , y_test ) = mnist . load_data () # Full size of the image 28x28 N_pixels = X_train . shape [ 1 ] * X_train . shape [ 2 ] # Convert to floats X_train = keras_backend . cast_to_floatx ( X_train ) X_test = keras_backend . cast_to_floatx ( X_test ) # Normalize the range from [0,255] to [0,1] X_train /= 255. X_test /= 255. # Reshape the data into a grid with one row per sample, each row 784 (28*28) pixels X_train = X_train . reshape (( len ( X_train ), N_pixels )) X_test = X_test . reshape (( len ( X_test ), N_pixels )) print ( \"X_train.shape = \" , X_train . shape , \" X_test.shape = \" , X_test . shape ) X_train.shape = (60000, 784) X_test.shape = (10000, 784) In [15]: def draw_predictions_set ( predictions , filename = None ): plt . figure ( figsize = ( 8 , 4 )) for i in range ( 5 ): plt . subplot ( 2 , 5 , i + 1 ) plt . imshow ( X_test [ i ] . reshape ( 28 , 28 ), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . subplot ( 2 , 5 , i + 6 ) plt . imshow ( predictions [ i ] . reshape ( 28 , 28 ), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . tight_layout () file_helper . save_figure ( filename + '-predictions' ) plt . show () In [18]: # Build and train our first autoencoder num_latent_vars = 20 modelAE1 = Sequential () modelAE1 . add ( Dense ( num_latent_vars , input_dim = N_pixels , activation = 'relu' )) modelAE1 . add ( Dense ( N_pixels , activation = 'linear' )) modelAE1 . compile ( optimizer = 'adadelta' , loss = 'mse' ) weights_filename = \"modelAE1-weights\" np . random . seed ( 52 ) if not file_helper . load_model_weights ( modelAE1 , weights_filename ): modelAE1 . fit ( X_train , X_train , epochs = 20 , batch_size = 128 , shuffle = True , verbose = 2 , validation_data = ( X_test , X_test )) file_helper . save_model_weights ( modelAE1 , weights_filename ) Train on 60000 samples, validate on 10000 samples Epoch 1/20 - 2s - loss: 0.0309 - val_loss: 0.0305 Epoch 2/20 - 2s - loss: 0.0308 - val_loss: 0.0304 Epoch 3/20 - 2s - loss: 0.0308 - val_loss: 0.0304 Epoch 4/20 - 2s - loss: 0.0307 - val_loss: 0.0303 Epoch 5/20 - 2s - loss: 0.0307 - val_loss: 0.0303 Epoch 6/20 - 2s - loss: 0.0307 - val_loss: 0.0303 Epoch 7/20 - 2s - loss: 0.0307 - val_loss: 0.0303 Epoch 8/20 - 2s - loss: 0.0307 - val_loss: 0.0303 Epoch 9/20 - 2s - loss: 0.0306 - val_loss: 0.0303 Epoch 10/20 - 2s - loss: 0.0306 - val_loss: 0.0303 Epoch 11/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 12/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 13/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 14/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 15/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 16/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 17/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 18/20 - 2s - loss: 0.0306 - val_loss: 0.0302 Epoch 19/20 - 3s - loss: 0.0306 - val_loss: 0.0302 Epoch 20/20 - 2s - loss: 0.0306 - val_loss: 0.0302 In [19]: predictions1 = modelAE1 . predict ( X_test ) draw_predictions_set ( predictions1 , 'FCC1' ) In [8]: # Build and train our first autoencoder num_latent_vars = 20 modelAE1_s = Sequential () modelAE1_s . add ( Dense ( num_latent_vars , input_dim = N_pixels , activation = 'relu' )) modelAE1_s . add ( Dense ( N_pixels , activation = 'sigmoid' )) modelAE1_s . compile ( optimizer = 'adadelta' , loss = 'binary_crossentropy' ) weights_filename = \"modelAE1-weights-sigmoid\" np . random . seed ( 52 ) if not file_helper . load_model_weights ( modelAE1_s , weights_filename ): modelAE1_s . fit ( X_train , X_train , epochs = 20 , batch_size = 128 , shuffle = True , verbose = 2 , validation_data = ( X_test , X_test )) file_helper . save_model_weights ( modelAE1_s , weights_filename ) In [9]: predictions1 = modelAE1_s . predict ( X_test ) draw_predictions_set ( predictions1 , 'FCC1-s' ) In [10]: from PIL import Image filepath = file_helper . get_input_file_path ( \"pavlos-gray-28-28.png\" ) im = Image . open ( filepath ) pix = im . load () pavlos = np . zeros (( 1 , 784 )) for y in range ( 28 ): for x in range ( 28 ): pavlos [ 0 ,( y * 28 ) + x ] = pix [ x , y ][ 0 ] / 255. predicted_pavlos = modelAE1_s . predict ( pavlos ) plt . subplot ( 1 , 2 , 1 ) plt . imshow ( np . reshape ( pavlos , ( 28 , 28 )), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . subplot ( 1 , 2 , 2 ) plt . imshow ( np . reshape ( predicted_pavlos , ( 28 , 28 )), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . tight_layout () file_helper . save_figure ( 'Model-FCC-pavlos-pair' ) plt . show () --------------------------------------------------------------------------- FileNotFoundError Traceback (most recent call last) in () 2 3 filepath = file_helper . get_input_file_path ( \"pavlos-gray-28-28.png\" ) ----> 4 im = Image . open ( filepath ) 5 pix = im . load ( ) 6 pavlos = np . zeros ( ( 1 , 784 ) ) ~/anaconda3/lib/python3.6/site-packages/PIL/Image.py in open (fp, mode) 2475 2476 if filename : -> 2477 fp = builtins . open ( filename , \"rb\" ) 2478 exclusive_fp = True 2479 FileNotFoundError : [Errno 2] No such file or directory: '../data/pavlos-gray-28-28.png' In [ ]: # rebuild model with the Functional API so we can play with the decoder alone from keras.layers import Input num_latent_vars = 20 model_encoder_input = Input ( shape = ( 784 ,)) model_encoder_512 = Dense ( 512 , activation = 'relu' ) model_encoder_256 = Dense ( 256 , activation = 'relu' ) model_encoder_latent = Dense ( num_latent_vars , activation = 'relu' ) model_decoder_256 = Dense ( 256 , activation = 'relu' ) model_decoder_512 = Dense ( 512 , activation = 'relu' ) model_decoder_out = Dense ( 784 , activation = 'sigmoid' ) model_encoder_step_1 = model_encoder_512 ( model_encoder_input ) model_encoder_step_2 = model_encoder_256 ( model_encoder_step_1 ) model_encoder_output = model_encoder_latent ( model_encoder_step_2 ) model_decoder_step_1 = model_decoder_256 ( model_encoder_output ) model_decoder_step_2 = model_decoder_512 ( model_decoder_step_1 ) model_decoder_output = model_decoder_out ( model_decoder_step_2 ) model_AE_F = Model ( model_encoder_input , model_decoder_output ) model_encoder_only_model = Model ( model_encoder_input , model_encoder_output ) model_decoder_only_input = Input ( shape = ( num_latent_vars ,)) model_decoder_only_step_1 = model_decoder_256 ( model_decoder_only_input ) model_decoder_only_step_2 = model_decoder_512 ( model_decoder_only_step_1 ) model_decoder_only_output = model_decoder_out ( model_decoder_only_step_2 ) model_decoder_only_model = Model ( model_decoder_only_input , model_decoder_only_output ) In [ ]: model_AE_F . compile ( optimizer = 'adadelta' , loss = 'binary_crossentropy' ) weights_filename = \"model-AE-F-weights\" np . random . seed ( 52 ) if not file_helper . load_model_weights ( model_AE_F , weights_filename ): model_AE_F . fit ( X_train , X_train , epochs = 20 , batch_size = 128 , shuffle = True , verbose = 2 , validation_data = ( X_test , X_test )) file_helper . save_model_weights ( model_AE_F , weights_filename ) In [ ]: # show the input data, its latent values, and the corresponding predicted images np . random . seed ( random_seed ) encoder_predictions = model_encoder_only_model . predict ( X_test ) plt . figure ( figsize = ( 8 , 5 )) latent_min = np . min ( encoder_predictions [ 0 : 5 ]) latent_max = np . max ( encoder_predictions [ 0 : 5 ]) for i in range ( 5 ): plt . subplot ( 3 , 5 , i + 1 ) plt . imshow ( X_test [ i ] . reshape ( 28 , 28 ), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . subplot ( 3 , 5 , i + 6 ) plt . bar ( np . arange ( len ( encoder_predictions [ i ])), encoder_predictions [ i ]) plt . xticks ([], []) plt . ylim ( latent_min , latent_max ) plt . subplot ( 3 , 5 , i + 11 ) decoder_model_input = np . resize ( encoder_predictions [ i ], ( 1 , len ( encoder_predictions [ i ]))) decoder_prediction = model_decoder_only_model . predict ( decoder_model_input ) plt . imshow ( decoder_prediction . reshape ( 28 , 28 ), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . tight_layout () file_helper . save_figure ( \"model-F-latents-and-output\" ) plt . show () In [ ]: # show the latent values and the corresponding predicted images # this makes big vertical spaces between the def show_latents_and_predictions ( predictions , filename = None ): plt . figure ( figsize = ( 8 , 4 )) latent_min = np . min ( predictions [ 0 : 5 ]) latent_max = np . max ( predictions [ 0 : 5 ]) for i in range ( 5 ): plt . subplot ( 2 , 5 , i + 1 ) plt . bar ( np . arange ( len ( predictions [ i ])), predictions [ i ]) plt . xticks ([], []) plt . ylim ( latent_min , latent_max ) plt . subplot ( 2 , 5 , i + 6 ) decoder_model_input = np . resize ( predictions [ i ], ( 1 , len ( predictions [ i ]))) decoder_prediction = model_decoder_only_model . predict ( decoder_model_input ) plt . imshow ( decoder_prediction . reshape ( 28 , 28 ), vmin = 0 , vmax = 1 , cmap = \"gray\" ) ax = plt . gca () ax . get_xaxis () . set_visible ( False ) ax . get_yaxis () . set_visible ( False ) plt . tight_layout () file_helper . save_figure ( filename ) plt . show () In [ ]: # add [-noise to all values encoder_predictions = np . array ( model_encoder_only_model . predict ( X_test )) np . random . seed ( random_seed ) noise = 10 for i in range ( encoder_predictions . shape [ 0 ]): for j in range ( len ( encoder_predictions [ i ])): encoder_predictions [ i ][ j ] += np . random . uniform ( low =- noise , high = noise ) show_latents_and_predictions ( encoder_predictions , 'NB2-MLP-AE5-prediction-latent-values-with-noise-1' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"lectures","url":"lectures/lecture18/notebook/"},{"title":"Lecture 16:  Bayesian 2/3","text":"Slides This lecture is only available to registered students Lecture 15-17 PDF Associated Material","tags":"pages","url":"pages/lecture16/"},{"title":"Lecture 17:  Bayesian 3/3","text":"Slides This lecture is only available to registered students Lecture 15-17 PDF Associated Material","tags":"pages","url":"pages/lecture17/"},{"title":"Advanced Section 6: Deep Reinforcement Learning","text":"Slides PDF","tags":"A-sections","url":"a-sections/a-section6/"},{"title":"Lab 8: Bayesian Analysis using pyjags (+ Reinforcement Learning with gym)","text":"Slides PDF Notebooks Lab 8 Notebook","tags":"labs","url":"labs/lab8/"},{"title":"Lab 8: Bayesian Analysis using pyjags (+Reinforcement Learning using gym)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 8 - Bayesian Analysis, Part 1 - JAGS (+RL setup) Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas Note that this lab has been tested with pandas version 0.22.0 rpy2 version 2.9.4 The latest libraries may have changed somewhat since these versions; if you are having problems, try using these versions. In this lab, we are working with JAGS, so make sure that it is installed on your system. In [ ]: import os os . environ [ 'R_HOME' ] = \"/usr/share/anaconda3/lib/R\" In [ ]: import pyjags import numpy as np import matplotlib.pyplot as plt % matplotlib inline import pandas as pd import rpy2 from rpy2.robjects.packages import importr #If there are errors about missing R packages, run the code below: # r_utils = importr(\"utils\") # r_utils.install_packages('coda') r_coda = importr ( \"coda\" ) from rpy2.robjects import pandas2ri pandas2ri . activate () Example 1: A Bayesian Coin Flip The idea here is to use JAGS to estimate how fair a coin is, based on 100 coin flips. In [ ]: coinflip_code = ''' model { for (i in 1:N){ x[i] ~ dbern(theta) } theta ~ dunif(0,1) } ''' In [ ]: #generate some data for our coin coinflip_N = 100 true_theta = 0.6 coinflip_x = np . random . binomial ( 1 , true_theta , coinflip_N ) In [ ]: init_theta = 0.5 #prior is that coin is fair n_chains = 3 coinflip_model = pyjags . Model ( coinflip_code , data = dict ( x = coinflip_x , N = coinflip_N ), init = dict ( theta = init_theta ), chains = n_chains ) In [ ]: coinflip_burnin = coinflip_model . sample ( 500 , vars = [ 'theta' ]) #warmup/burn-in coinflip_samples = coinflip_model . sample ( 2500 , vars = [ 'theta' ]) In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), coinflip_burnin [ 'theta' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), coinflip_burnin [ 'theta' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), coinflip_burnin [ 'theta' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"theta\" ) _ = plt . title ( \"Traceplot for coinflip data: theta\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), coinflip_samples [ 'theta' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), coinflip_samples [ 'theta' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), coinflip_samples [ 'theta' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"theta\" ) _ = plt . title ( \"Traceplot for coinflip data: theta\" ) _ = plt . legend () In [ ]: #chain 1 coinflip_chain1 = coinflip_samples [ 'theta' ][ 0 ][:, 0 ] coinflip_chain1_df = pd . DataFrame ({ 'theta' : coinflip_chain1 }) coinflip_chain1_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( coinflip_chain1_df )) #chain 2 coinflip_chain2 = coinflip_samples [ 'theta' ][ 0 ][:, 1 ] coinflip_chain2_df = pd . DataFrame ({ 'theta' : coinflip_chain2 }) coinflip_chain2_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( coinflip_chain2_df )) #chain 3 coinflip_chain3 = coinflip_samples [ 'theta' ][ 0 ][:, 2 ] coinflip_chain3_df = pd . DataFrame ({ 'theta' : coinflip_chain3 }) coinflip_chain3_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( coinflip_chain3_df )) #convert to mcmc_list object coinflip_chains = r_coda . mcmc_list ( coinflip_chain1_mcmc , coinflip_chain2_mcmc , coinflip_chain3_mcmc ) #get n_eff and Rhat coinflip_n_eff = np . round ( np . array ( r_coda . effectiveSize ( coinflip_chains ))) #round because must be an integer coinflip_rhat = np . array ( r_coda . gelman_diag ( coinflip_chains ) . rx2 ( \"psrf\" )) coinflip_rhat = coinflip_rhat [ 0 ][ 0 ] #extract point estimates #calculate summary coinflip_theta_summary = [ np . mean ( coinflip_samples [ 'theta' ]), np . std ( coinflip_samples [ 'theta' ])] for i in [ 0.025 , 0.25 , 0.5 , 0.75 , 0.975 ]: coinflip_theta_summary . append ( np . quantile ( coinflip_samples [ 'theta' ], i )) coinflip_theta_summary . append ( coinflip_n_eff [ 0 ]) coinflip_theta_summary . append ( coinflip_rhat ) coinflip_summary = pd . DataFrame ([ coinflip_theta_summary ], columns = [ \"mean\" , \"sd\" , \"2.5%\" , \"25%\" , \"50%\" , \"75%\" , \"97.5%\" , \"n_eff\" , \"Rhat\" ], index = [ \"theta\" ]) coinflip_summary . round ( 3 ) Exercise: Try running the analysis above with different values of $p$ (the probability of the coin), as well as with different values for N (number of coin flips in the data). What do you observe? In [ ]: #try it here Example 2: Mean and Standard Deviation of the Normal Given samples from a normal distribution, we want to estimate its mean and standard deviation. In [ ]: normal_code = ''' model { for (i in 1:N){ x[i] ~ dnorm(mu, tau) } mu ~ dnorm(0,.0001) tau = pow(sigma, -2) sigma ~ dunif(0,100) } ''' In [ ]: #generate some data for our normal distribution normal_N = 1000 true_mu = - 5 true_sigma = 5 normal_x = np . random . normal ( true_mu , true_sigma , 1000 ) #true data: mean = -5, standard deviation = 5 #prior is that this is a standard normal init_mu = 0 init_sigma = 1 In [ ]: normal_model = pyjags . Model ( normal_code , data = dict ( x = normal_x , N = normal_N ), init = dict ( mu = init_mu , sigma = init_sigma ), chains = 3 ) normal_burnin = normal_model . sample ( 500 , vars = [ 'mu' , 'sigma' ]) #warmup/burn-in normal_samples = normal_model . sample ( 2500 , vars = [ 'mu' , 'sigma' ]) In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), normal_burnin [ 'mu' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'mu' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'mu' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"mu\" ) _ = plt . title ( \"Traceplot for normal data: mu\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'mu' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'mu' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'mu' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"mu\" ) _ = plt . title ( \"Traceplot for normal data: mu\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), normal_burnin [ 'sigma' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'sigma' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), normal_burnin [ 'sigma' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"sigma\" ) _ = plt . title ( \"Traceplot for normal data: sigma\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'sigma' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'sigma' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), normal_samples [ 'sigma' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"sigma\" ) _ = plt . title ( \"Traceplot for normal data: sigma\" ) _ = plt . legend () In [ ]: #chain 1 normal_chain1 = np . column_stack (( normal_samples [ 'mu' ][ 0 ][:, 0 ], normal_samples [ 'sigma' ][ 0 ][:, 0 ])) normal_chain1_df = pd . DataFrame ({ 'mu' : normal_chain1 [:, 0 ], 'sigma' : normal_chain1 [:, 1 ]}) normal_chain1_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( normal_chain1_df )) #chain 2 normal_chain2 = np . column_stack (( normal_samples [ 'mu' ][ 0 ][:, 1 ], normal_samples [ 'sigma' ][ 0 ][:, 1 ])) normal_chain2_df = pd . DataFrame ({ 'mu' : normal_chain2 [:, 0 ], 'sigma' : normal_chain2 [:, 1 ]}) normal_chain2_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( normal_chain2_df )) #chain 3 normal_chain3 = np . column_stack (( normal_samples [ 'mu' ][ 0 ][:, 2 ], normal_samples [ 'sigma' ][ 0 ][:, 2 ])) normal_chain3_df = pd . DataFrame ({ 'mu' : normal_chain3 [:, 0 ], 'sigma' : normal_chain3 [:, 1 ]}) normal_chain3_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( normal_chain3_df )) #convert to mcmc_list object normal_chains = r_coda . mcmc_list ( normal_chain1_mcmc , normal_chain2_mcmc , normal_chain3_mcmc ) #get n_eff and Rhat normal_n_eff = np . round ( np . array ( r_coda . effectiveSize ( normal_chains ))) #round because must be an integer normal_rhat = np . array ( r_coda . gelman_diag ( normal_chains ) . rx2 ( \"psrf\" )) normal_rhat = np . array ([ normal_rhat [ 0 ][ 0 ], normal_rhat [ 1 ][ 0 ]]) #extract point estimates #calculate summary normal_mu_summary = [ np . mean ( normal_samples [ 'mu' ]), np . std ( normal_samples [ 'mu' ])] normal_sigma_summary = [ np . mean ( normal_samples [ 'sigma' ]), np . std ( normal_samples [ 'sigma' ])] for i in [ 0.025 , 0.25 , 0.5 , 0.75 , 0.975 ]: normal_mu_summary . append ( np . quantile ( normal_samples [ 'mu' ], i )) normal_sigma_summary . append ( np . quantile ( normal_samples [ 'sigma' ], i )) normal_mu_summary . append ( normal_n_eff [ 0 ]) normal_mu_summary . append ( normal_rhat [ 0 ]) normal_sigma_summary . append ( normal_n_eff [ 1 ]) normal_sigma_summary . append ( normal_rhat [ 1 ]) normal_summary = pd . DataFrame ([ normal_mu_summary , normal_sigma_summary ], columns = [ \"mean\" , \"sd\" , \"2.5%\" , \"25%\" , \"50%\" , \"75%\" , \"97.5%\" , \"n_eff\" , \"Rhat\" ], index = [ \"mu\" , \"sigma\" ]) normal_summary . round ( 3 ) Exercise: Try varying the length of the burn-in period and number of iterations in the chains. What do you observe? In [ ]: #try it here Example 3: Linear Regression We will run a simple linear regression using JAGS. In [ ]: regression_code = ''' model { for (i in 1:N){ y[i] ~ dnorm(mu[i], tau) mu[i] = a + b * x[i] } a ~ dnorm(0, .0001) b ~ dnorm(0, .0001) tau = pow(sigma, -2) sigma ~ dunif(0, 100) } ''' In [ ]: regression_N = 1000 true_b = 5 true_a = 70 regression_x = np . arange ( 1 , 1001 ) regression_epsilon = np . random . normal ( true_a , 100 , 1000 ) regression_y = true_b * regression_x + regression_epsilon #prior is that y = x (i.e., a = 0, b = 1) prior_a = 0 prior_b = 1 In [ ]: regression_model = pyjags . Model ( regression_code , data = dict ( x = regression_x , y = regression_y , N = regression_N ), init = dict ( a = prior_a , b = prior_b ), chains = 3 ) regression_burnin = regression_model . sample ( 500 , vars = [ 'a' , 'b' ]) #warmup/burn-in regression_samples = regression_model . sample ( 2500 , vars = [ 'a' , 'b' ]) In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), regression_burnin [ 'a' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'a' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'a' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"a\" ) _ = plt . title ( \"Traceplot for regression data: a\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'a' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'a' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'a' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"a\" ) _ = plt . title ( \"Traceplot for regression data: a\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 500 ), regression_burnin [ 'b' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'b' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 500 ), regression_burnin [ 'b' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"b\" ) _ = plt . title ( \"Traceplot for regression data: b\" ) _ = plt . legend () In [ ]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'b' ][ 0 ,:, 0 ], color = \"red\" , label = \"Chain 1\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'b' ][ 0 ,:, 1 ], color = \"blue\" , label = \"Chain 2\" ) _ = plt . plot ( range ( 501 , 3001 ), regression_samples [ 'b' ][ 0 ,:, 2 ], color = \"cyan\" , label = \"Chain 3\" ) _ = plt . xlabel ( \"iteration\" ) _ = plt . ylabel ( \"b\" ) _ = plt . title ( \"Traceplot for regression data: b\" ) _ = plt . legend () In [ ]: #chain 1 regression_chain1 = np . column_stack (( regression_samples [ 'a' ][ 0 ][:, 0 ], regression_samples [ 'b' ][ 0 ][:, 0 ])) regression_chain1_df = pd . DataFrame ({ 'a' : regression_chain1 [:, 0 ], 'b' : regression_chain1 [:, 1 ]}) regression_chain1_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( regression_chain1_df )) #chain 2 regression_chain2 = np . column_stack (( regression_samples [ 'a' ][ 0 ][:, 1 ], regression_samples [ 'b' ][ 0 ][:, 1 ])) regression_chain2_df = pd . DataFrame ({ 'a' : regression_chain2 [:, 0 ], 'b' : regression_chain2 [:, 1 ]}) regression_chain2_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( regression_chain2_df )) #chain 3 regression_chain3 = np . column_stack (( regression_samples [ 'a' ][ 0 ][:, 2 ], regression_samples [ 'b' ][ 0 ][:, 2 ])) regression_chain3_df = pd . DataFrame ({ 'a' : regression_chain3 [:, 0 ], 'b' : regression_chain3 [:, 1 ]}) regression_chain3_mcmc = r_coda . mcmc ( pandas2ri . py2ri ( regression_chain3_df )) #convert to mcmc_list object regression_chains = r_coda . mcmc_list ( regression_chain1_mcmc , regression_chain2_mcmc , regression_chain3_mcmc ) #get n_eff and Rhat regression_n_eff = np . round ( np . array ( r_coda . effectiveSize ( regression_chains ))) #round because must be an integer regression_rhat = np . array ( r_coda . gelman_diag ( regression_chains ) . rx2 ( \"psrf\" )) regression_rhat = np . array ([ regression_rhat [ 0 ][ 0 ], regression_rhat [ 1 ][ 0 ]]) #extract point estimates #calculate summary regression_a_summary = [ np . mean ( regression_samples [ 'a' ]), np . std ( regression_samples [ 'a' ])] regression_b_summary = [ np . mean ( regression_samples [ 'b' ]), np . std ( regression_samples [ 'b' ])] for i in [ 0.025 , 0.25 , 0.5 , 0.75 , 0.975 ]: regression_a_summary . append ( np . quantile ( regression_samples [ 'a' ], i )) regression_b_summary . append ( np . quantile ( regression_samples [ 'b' ], i )) regression_a_summary . append ( regression_n_eff [ 0 ]) regression_a_summary . append ( regression_rhat [ 0 ]) regression_b_summary . append ( regression_n_eff [ 1 ]) regression_b_summary . append ( regression_rhat [ 1 ]) regression_summary = pd . DataFrame ([ regression_a_summary , regression_b_summary ], columns = [ \"mean\" , \"sd\" , \"2.5%\" , \"25%\" , \"50%\" , \"75%\" , \"97.5%\" , \"n_eff\" , \"Rhat\" ], index = [ \"a\" , \"b\" ]) regression_summary . round ( 3 ) Exercise: Compare the results of performing a linear regression with this method and a non-Bayesian approach (say, using the sklearn LinearRegression function). What do you observe? In [ ]: #try it here Example 4: Reinforcement Learning with Open AI Gym In this lab we are going to work with OpenAIgym's FrozenLake environment. The details of the environment can be found in the link https://gym.openai.com/envs/FrozenLake-v0/ . Winter is here. You and your friends were tossing around a frisbee at the park when you made a wild throw that left the frisbee out in the middle of the lake. The water is mostly frozen, but there are a few holes where the ice has melted. If you step into one of those holes, you'll fall into the freezing water. At this time, there's an international frisbee shortage, so it's absolutely imperative that you navigate across the lake and retrieve the disc. The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile. The surface is described using a grid like the following: [PP: WOULD IT BETTER TO INCLUDE A DIAGRAM] S: starting point, safe F: frozen surface, safe H: hole, fall to your doom G: goal, where the frisbee is located SFFF FHFH FFFH HFFG Expected actions are Left(0), Right(1), Down(2), Up(3). The episode ends when you reach the goal or fall in a hole. You receive a reward of 1 if you reach the goal, and zero otherwise. In [ ]: import gym from gym.envs.registration import register register ( id = 'FrozenLakeNotSlippery-v0' , entry_point = 'gym.envs.toy_text:FrozenLakeEnv' , kwargs = { 'map_name' : '4x4' , 'is_slippery' : False }, max_episode_steps = 100 , reward_threshold = 0.8196 , # optimum = .8196 ) In [ ]: from gym.envs.registration import register register ( id = 'FrozenLake8x8NotSlippery-v0' , entry_point = 'gym.envs.toy_text:FrozenLakeEnv' , kwargs = { 'map_name' : '8x8' , 'is_slippery' : False }, max_episode_steps = 100 , reward_threshold = 0.8196 , # optimum = .8196 ) hint: If you receive an error message while registering the above env the second time you run this cell again, ignore the error message or restart the kernel. Throughout the assignment, use only the environments we registered in the previous cells: FrozenLake8x8NotSlippery-v0 FrozenLakeNotSlippery-v0 Even though the original problem description has slippery environment, we are working in a non-slippery environment. In our environment, if you go right, you only go right whereas in the original environment, if you intend to go right, you can go right, up or down with 1/3 probability. In [ ]: import gym import numpy as np #Change environment to FrozenLake8x8 to see grid. env = gym . make ( 'FrozenLake-v0' ) # env = gym.make('FrozenLake8x8NotSlippery-v0') print ( env . observation_space . n ) #Both the grids look like as follows. ''' \"4x4\": [ \"SFFF\", \"FHFH\", \"FFFH\", \"HFFG\" ], \"8x8\": [ \"SFFFFFFF\", \"FFFFFFFF\", \"FFFHFFFF\", \"FFFFFHFF\", \"FFFHFFFF\", \"FHHFFFHF\", \"FHFFHFHF\", \"FFFHFFFG\" ]''' #env.render() prints the frozenlake with an indicator showing where the agent is. You can use it for debugging. env . render () In [ ]: print ( env . observation_space . n ) print ( env . action_space . n ) In [ ]: Q = np . zeros ([ env . observation_space . n , env . action_space . n ]) def choose_action ( state ): return np . random . choice ( np . array ([ 0 , 1 , 2 , 3 ])) def learn ( s , s1 , r , a ): return In [ ]: # Set learning parameters ################ # num_episodes = 2000 # epsilon = 0.0 # max_steps = 100 # lr_rate = 0.0 # gamma = 0.0 # rList = [] num_episodes = 10 max_iter_per_episode = 20 for i in range ( num_episodes ): iter = 0 #Reset environment and get an initial state - should be done at start of each episode. s = env . reset () rAll = 0 d = False j = 0 while iter < max_iter_per_episode : iter += 1 #Choose an action a = choose_action ( s ) # env.step() gives you next state, reward, done(whether the episode is over) # s1 - new state, r-reward, d-whether you are done or not s1 , r , d , _ = env . step ( a ) print ( 'State : ' , s , ' Action : ' , a , ' State 1 : ' , s1 , ' Reward : ' , r , 'Done : ' , d ) learn ( s , s1 , r , a ) if d : print ( 'Episode Over' ) if r != 1 : print ( 'Fell into hole with reward ' , r ) break s = s1 if r == 1 : print ( i ) break if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab8/Bayes/"},{"title":"Lab 9: Latent Dirichlet Allocation (LDA)","text":"Notebooks Lab 8 Notebook","tags":"labs","url":"labs/lab9/"},{"title":"Lab 9: Latent Dirichlet Allocation (LDA)","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 9 - Bayes, Part 2 - LDA Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas In [1]: import pandas as pd import numpy as np % matplotlib inline import matplotlib.pyplot as plt from matplotlib import gridspec import re import scipy.stats import pyjags In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Schools Data and Bayesian Modeling Once upon a time, eight different schools each implemented a particular SAT prep program. At the end of the year, students from each school's program took the SATs and we've recorded the students' average performance relative to a control group that got no treatment. We've also recorded the standard error for each school's estimated increase, a measure of how accurate the estimated increase is. (Standard Error factors in the number of students who took the program and how variable their scores were). In [3]: school_data = pd . read_csv ( \"data/gelman_schools.csv\" ) school_data Out[3]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } School Estimated Score Increase Standard error of the estimate 0 A 28 15 1 B 8 10 2 C -3 16 3 D 7 11 4 E -1 9 5 F 1 11 6 G 18 10 7 H 12 18 The measurements look something like this: In [4]: x_vals = np . linspace ( - 50 , 80 , 1000 ) for cur_school_id in range ( 8 ): name = school_data [ \"School\" ][ cur_school_id ] mean = school_data [ \"Estimated Score Increase\" ][ cur_school_id ] sd = school_data [ \"Standard error of the estimate\" ][ cur_school_id ] norm_obj = scipy . stats . norm ( mean , sd ) plt . plot ( x_vals , norm_obj . pdf ( x_vals ), label = name ) plt . xlabel ( \"School's Performance\" ) plt . ylabel ( \"Probability Density\" ) plt . legend () plt . show () Discussion How effective is the program? Does it increase scores? By how much? A Hierarchical Model for the Schools Gelman (or maybe Rubin?) proposed the following model to explain the data and understand the effect of the program on SAT scores. As in class, the point of the model is that it neither takes each school's result at face value, nor ignores variation from school to school. $$\\sigma_j\\ given$$ $$\\mu \\sim Uniform(-20,20)$$ $$\\tau \\sim Uniform(0,10)$$ $$\\theta_j \\sim Normal(Mean=\\mu,\\ SD=\\tau)$$ $$y_j \\sim Normal(Mean=\\theta_j,\\ SD=\\sigma_j)$$ $y_j$ are the observed SAT increase at each school $\\sigma_j$ are the observed standard errors at each school $\\theta_j$ is the 'true' effect of each school's program $\\mu$ and $\\tau$ govern the distribution of possible true effects. Bayesian models (and others) are often presented like this. Actually, they're usually presented even less clearly (e.g. missing the definition of each symbol). Let's learn how to make sense of this jumble. First pass: Understanding the parameters This pass is typically easiest from bottom to top, starting with the observed parameters that you know how to interpret. It often also requires reading about the context of the data or what the modeler is trying to encode with each parameter. $$y_j \\sim Normal(Mean=\\theta_j,\\ SD=\\sigma_j)$$ First, the observed data (one value per school) are 1) normally distributed 2) each centered at a different value, one per school. The 8 $\\theta_j$ parameters are the 'true average effect' of the program in school j, separate from the (noisy) effect we actually observe. $$\\theta_j \\sim Normal(Mean=\\mu,\\ SD=\\tau)$$ Where do the 'true average effects' in each school come from? Line 2, above, says that they're all draws from a normal distribution with a particular mean and center. Okay, so they're all form the same family, that's fine for now. Moving on, $$\\sigma_j\\ given$$ $$\\mu \\sim Uniform(-20,20)$$ $$\\tau \\sim Uniform(0,10)$$ Finally, the parameters defining what 'true average effects' we might see come from specific uniform distributions. In particular, the author encodes that the center of the 'true average effect' distribution is strictly between -20 and 20, and the spread of the 'true average effect' distribution is somewhere betweeen 0 and 10. Seconnd Pass: Summarizing : The author's story is that when someone goes to implement this cirriculum in a given school, the actual (long term?) effectiveness of that program is secretly picked from a normal distribution. Then the actual observed effect is a noisy version of that actual effectiveness, with the noise set by that school's standard error. (The school's standard error is set by the number of students who were in the program and the variability in how well those students did, but this model takes that as given for each school). Third pass: Critiquing the story Discussion Does the author's overall story make sense? Do you believe in a 'true' effectiveness in each school, distinct from the observed effectiveness? Do you believe that schools' 'true' effectiveness all come from some distribution? Or do you think they're all the same? Or all unrelated? What does it mean, in context, for the author to say $\\mu$ is definitely between -20 and 20? Does that seem reasonable to you? What does it mean, in context, for the author to say $\\tau$ is definitely between 0 and 10? Does that seem reasonable to you? As a class, come up with a prior for $\\mu$ and $\\tau$ Coding the Model To work in JAGS, we need to write out the model in a specific code-like format. That format is designed to be a mix of the equation description of the model above and R syntax. The tricky parts are: Writing a loop for any varibles with indices, and double loops if the variable has two indices Looking up the abreviation for each ditribution (usualy the letter d and a short-ish version of the distribution name) Looking up the parameters the distributions want (does it ask for mean, sd, or precision?) Looking up how to do functions like $x&#94;2$ in R Compare: There are J schools $$\\sigma_j\\ given$$ $$\\mu \\sim Uniform(-20,20)$$ $$\\tau \\sim Uniform(0,10)$$ $$\\theta_j \\sim Normal(Mean=\\mu,\\ SD=\\tau)$$ $$y_j \\sim Normal(Mean=\\theta_j,\\ SD=\\sigma_j)$$ To: In [5]: schools_model_code = ''' model { mu ~ dunif(-20,20) tau ~ dunif(0,10) for (j in 1:J){ theta[j] ~ dnorm(mu, 1/pow(tau,2)) } for (j in 1:J){ y[j] ~ dnorm(theta[j], 1/pow(sigma[j],2)) } } ''' Running the model To run the model, you need to pass in a dictionary of the observed data. Pyjags is pretty good about giving useful error messages, but definitely turn on line numbers in Jupyter! We run 500 samples of burn-in (MCMC needs some undefined amount of steps before it produces samples from the target distribution). We then collect 2500 actual samples from each of 4 chains. In [6]: observed_vals = { 'y' : school_data [ \"Estimated Score Increase\" ], 'sigma' : school_data [ \"Standard error of the estimate\" ], 'J' : school_data . shape [ 0 ]} num_chains = 4 school_model = pyjags . Model ( schools_model_code , data = observed_vals , chains = num_chains ) burnin = school_model . sample ( 500 ) #warmup/burn-in samples = school_model . sample ( 2500 ) #cf 7500 adapting: iterations 4000 of 4000, elapsed 0:00:00, remaining 0:00:00 sampling: iterations 2000 of 2000, elapsed 0:00:00, remaining 0:00:00 sampling: iterations 10000 of 10000, elapsed 0:00:00, remaining 0:00:00 Checking Convergence MCMC is only guaranteed to work if you run it for infinite time. It can give good samples after finite, or even short time, but it's worth checking whether it looks like it did return good samples. The first thing to check is whether the sampler got stuck in one place for a bit by looking for flat/thin regions in the trace. Luckily, we have a lot to show you In [7]: def plot_trace ( samples , varname , entry = 0 ): plt . plot () sample_array = samples [ varname ] vec_len , num_samples , num_chains = sample_array . shape for cur_chain in range ( num_chains ): cur_label = \"Chain {} \" . format ( cur_chain ) plt . plot ( range ( num_samples ), sample_array [ entry ,:, cur_chain ], label = cur_label ) plt . legend () plt . show () We check the $\\mu$ and $\\tau$ parameters In [8]: plt . xlabel ( \"Iteration\" ) plt . ylabel ( \"Value of Mu\" ) plot_trace ( samples , 'mu' ) plt . xlabel ( \"Iteration\" ) plt . ylabel ( \"Value of Tau\" ) plot_trace ( samples , 'tau' ) and the 8 different $\\theta_j$ In [9]: for cur_school in range ( 8 ): print ( \"Theta for School {} \" . format ( cur_school )) plt . xlabel ( \"Iteration\" ) plt . ylabel ( \"Value of Theta_ {} \" . format ( cur_school )) plot_trace ( samples , 'theta' , entry = cur_school ) print ( \"------\" ) Theta for School 0 ------ Theta for School 1 ------ Theta for School 2 ------ Theta for School 3 ------ Theta for School 4 ------ Theta for School 5 ------ Theta for School 6 ------ Theta for School 7 ------ Overall, we see pretty rough traces- lots of places with limited variation. Fixing these defects is tough . Simply running more samples gives you better odds that you've got stuck for an even amount of time in each trap, though it's more 'hope' than 'strategy'. Changing the priors or even how the model is written can help ease the issues. More advanced samplers (e.g. Hamiltonian Monte Carlo implemented in pymc3 or Stan) can help, too. There are other measures of whether the traces look reasonable- effective sample size, R-hat, and Geweke. In real life, you should carefully vet your traces and adjust the model/sampler until they look good . See AM207 for lots more on this topic. Here, we're just going to press on as if the traces and samples are legitimate Exploring The Posterior The samples produced are basically a big data frame where each row is a sample and each column is one of the prameters of the model. This is everything we know about the posterior. Conceptually, from here forward all we do is describe this data frame- means or histograms or the columns, correlations, etc. (The samples aren't actually stored as a data frame, but conversion code is provided below) In [10]: samples Out[10]: {'J': array([[[8., 8., 8., 8.], [8., 8., 8., 8.], [8., 8., 8., 8.], ..., [8., 8., 8., 8.], [8., 8., 8., 8.], [8., 8., 8., 8.]]]), 'mu': array([[[11.44200703, -5.2483797 , 3.67912647, 0.0738187 ], [12.26069247, -5.48494222, 3.61115491, 4.95019625], [10.73895563, -5.085733 , 3.18646544, 4.80098972], ..., [11.17434202, 8.62852242, 8.57332894, 3.38636574], [11.32547262, 3.60811946, 7.74219932, 6.88329731], [11.64152507, 3.81368591, 9.61093627, 7.36313944]]]), 'sigma': array([[[15., 15., 15., 15.], [15., 15., 15., 15.], [15., 15., 15., 15.], ..., [15., 15., 15., 15.], [15., 15., 15., 15.], [15., 15., 15., 15.]], [[10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.], ..., [10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.]], [[16., 16., 16., 16.], [16., 16., 16., 16.], [16., 16., 16., 16.], ..., [16., 16., 16., 16.], [16., 16., 16., 16.], [16., 16., 16., 16.]], ..., [[11., 11., 11., 11.], [11., 11., 11., 11.], [11., 11., 11., 11.], ..., [11., 11., 11., 11.], [11., 11., 11., 11.], [11., 11., 11., 11.]], [[10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.], ..., [10., 10., 10., 10.], [10., 10., 10., 10.], [10., 10., 10., 10.]], [[18., 18., 18., 18.], [18., 18., 18., 18.], [18., 18., 18., 18.], ..., [18., 18., 18., 18.], [18., 18., 18., 18.], [18., 18., 18., 18.]]]), 'tau': array([[[5.22944064, 0.51424254, 0.57377092, 7.70896573], [4.12126626, 0.62418476, 0.55211472, 5.65434903], [5.02714961, 1.34672645, 0.55877668, 7.79227361], ..., [1.74828205, 5.63677814, 8.53923862, 7.55739259], [1.74222428, 5.65749486, 8.58125167, 8.09525945], [2.69541102, 4.94712847, 7.39562856, 7.32618989]]]), 'theta': array([[[16.61972838, -5.56344442, 3.49366297, 13.04717757], [ 7.77682071, -5.49960964, 3.53405496, 6.83151556], [16.46103894, -5.75185783, 2.86776548, 3.62641676], ..., [16.8258211 , 10.39344698, -1.57631373, 18.03982207], [ 8.72831671, 8.30629003, 13.73868418, 17.59792133], [12.05765791, -2.24196389, 27.22559778, 25.53386541]], [[19.56954737, -5.42537957, 4.05026727, 1.03910367], [11.59722917, -5.74709919, 4.54484246, 5.87960291], [ 6.367036 , -6.01464545, 3.39471538, 4.42970772], ..., [ 8.57546221, 10.32027721, 12.7106045 , 1.31254366], [ 8.38944263, 6.24801873, 7.44531707, 5.27553666], [10.90258801, 3.43412943, 10.33769674, 9.0311747 ]], [[ 5.88837309, -4.81366293, 3.15127896, -6.05951826], [14.78128587, -5.73556426, 3.71896808, 2.57675358], [12.54597606, -5.0653308 , 3.18413593, 0.49493214], ..., [11.98891272, 14.48338533, 13.87393438, 0.28335609], [10.9354531 , 8.07284582, -3.44999072, 9.18619352], [11.64331293, 10.64072935, 0.95014784, -0.21079075]], ..., [[ 1.22263673, -4.68733117, 3.31083688, 0.25609424], [18.55268161, -6.09756273, 4.05988122, 12.64476468], [ 6.71437458, -4.61057384, 3.52748741, -9.89316271], ..., [12.20384369, 4.68861594, 6.5070424 , 3.57409133], [ 8.62450786, 8.8124001 , 4.52069646, 0.46528057], [10.86269654, 6.22219415, 4.76471052, 6.61856667]], [[14.92735666, -5.68611841, 3.78224308, 9.02318814], [14.07864705, -4.10942606, 3.2962622 , 14.81264762], [16.15917815, -5.94679351, 3.74045733, 5.33112382], ..., [13.46168853, 8.76175389, 8.48475549, 3.892842 ], [ 9.52856636, 7.49486197, 15.59616436, 2.57200075], [12.38932389, 10.33383833, 1.72877462, 7.3614203 ]], [[10.48061998, -5.45665423, 3.91330464, 0.06519383], [16.33537128, -5.73639233, 4.15078261, 13.75552883], [10.26217066, -6.05283819, 3.24939955, 11.2550645 ], ..., [ 8.85214681, 4.31514814, 5.14246541, 8.71776731], [13.72143201, 9.21182701, 10.58598474, -1.14178797], [12.69258184, 6.78170005, 14.78258857, -1.19588779]]]), 'y': array([[[28., 28., 28., 28.], [28., 28., 28., 28.], [28., 28., 28., 28.], ..., [28., 28., 28., 28.], [28., 28., 28., 28.], [28., 28., 28., 28.]], [[ 8., 8., 8., 8.], [ 8., 8., 8., 8.], [ 8., 8., 8., 8.], ..., [ 8., 8., 8., 8.], [ 8., 8., 8., 8.], [ 8., 8., 8., 8.]], [[-3., -3., -3., -3.], [-3., -3., -3., -3.], [-3., -3., -3., -3.], ..., [-3., -3., -3., -3.], [-3., -3., -3., -3.], [-3., -3., -3., -3.]], ..., [[ 1., 1., 1., 1.], [ 1., 1., 1., 1.], [ 1., 1., 1., 1.], ..., [ 1., 1., 1., 1.], [ 1., 1., 1., 1.], [ 1., 1., 1., 1.]], [[18., 18., 18., 18.], [18., 18., 18., 18.], [18., 18., 18., 18.], ..., [18., 18., 18., 18.], [18., 18., 18., 18.], [18., 18., 18., 18.]], [[12., 12., 12., 12.], [12., 12., 12., 12.], [12., 12., 12., 12.], ..., [12., 12., 12., 12.], [12., 12., 12., 12.], [12., 12., 12., 12.]]])} In [11]: display ( samples [ 'theta' ] . shape ) display ( samples [ 'mu' ] . shape ) (8, 2500, 4) (1, 2500, 4) The raw samples from pyjags are a dictionary of parameeter names -> 3d arrays Discussion Why are the sample object's arrays shaped like this? We can equivalently organize the samples as a data frame (one per chain). The code below will handle this for you In [12]: def convert_to_dfs ( samples , parameter_names , num_chains ): \"\"\"Converts a pyjags sampling result to a list of data frames, one per chain\"\"\" big_list = [] for cur_chain_num in range ( num_chains ): df_list = [] for k in parameter_names : v = samples [ k ] chain1_data = v [:,:, cur_chain_num ] cur_df = pd . DataFrame ( chain1_data . T ) if cur_df . shape [ 1 ] == 1 : cur_df = cur_df . rename ({ 0 : k }, axis = 1 ) else : cur_df = cur_df . add_prefix ( k ) df_list . append ( cur_df ) chain1_samples_df = pd . concat ( df_list , axis = 1 ) big_list . append ( chain1_samples_df ) return big_list chain_df_list = convert_to_dfs ( samples ,[ \"J\" , \"mu\" , \"tau\" , \"theta\" , \"sigma\" ], num_chains ) chain_df_list [ 0 ] . head ( 15 ) Out[12]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } J mu tau theta0 theta1 theta2 theta3 theta4 theta5 theta6 theta7 sigma0 sigma1 sigma2 sigma3 sigma4 sigma5 sigma6 sigma7 0 8.0 11.442007 5.229441 16.619728 19.569547 5.888373 11.555302 14.000452 1.222637 14.927357 10.480620 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 1 8.0 12.260692 4.121266 7.776821 11.597229 14.781286 8.849931 11.661383 18.552682 14.078647 16.335371 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 2 8.0 10.738956 5.027150 16.461039 6.367036 12.545976 8.353043 13.858865 6.714375 16.159178 10.262171 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 3 8.0 10.516138 4.554490 7.474957 6.259871 11.719390 10.502339 4.189236 11.253609 16.150101 5.926606 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 4 8.0 10.960373 4.869065 18.473639 12.840373 10.860589 14.785369 3.523220 2.416270 12.767866 10.243774 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 5 8.0 11.096228 3.164246 14.732883 13.481348 5.766054 10.089107 6.318225 15.063753 13.295595 9.481372 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 6 8.0 11.823150 4.010776 12.051695 15.428234 5.185046 13.173989 10.775218 13.420324 7.560915 14.283472 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 7 8.0 11.970236 8.292315 20.341468 10.596276 14.109678 21.072512 8.798100 5.908609 15.986449 15.522908 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 8 8.0 8.504100 7.625681 20.081649 11.187542 -7.337301 4.319860 16.882968 -7.501047 14.923680 23.086732 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 9 8.0 6.782231 6.401574 21.331827 -7.331606 8.548878 7.238340 -1.487119 -7.016653 11.106292 9.737838 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 10 8.0 6.687746 7.104521 12.442858 12.048259 2.113918 9.093249 6.816101 3.553985 13.849016 11.038066 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 11 8.0 6.814846 8.586887 13.693062 7.003443 -1.932552 -5.210427 1.169831 0.766485 15.865447 12.148062 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 12 8.0 5.745068 6.131445 12.496375 15.859827 3.879309 13.467793 4.079493 4.300865 6.819747 -3.968503 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 13 8.0 4.639780 8.804461 18.416387 6.921307 14.155640 -2.364373 8.944646 -2.533777 11.618003 7.952452 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 14 8.0 5.674181 9.300716 20.937233 -0.637050 3.997101 11.917414 11.382043 7.458958 17.209642 19.006517 15.0 10.0 16.0 11.0 9.0 11.0 10.0 18.0 Learn About the Parameters Once we have the posterior dataset, we can analyze it like we'd analyze any other dataset ( with the warning that the rows are correlated, not IID ) In [13]: for cur_chain in range ( num_chains ): plt . hist ( chain_df_list [ cur_chain ][ 'mu' ], bins = 100 , histtype = 'step' , density = True , label = \"Chain {} \" . format ( cur_chain )); plt . xlabel ( \"Value of mu\" ) plt . ylabel ( \"Approx. Posterior Probability\" ) plt . legend () plt . show () Above, we see that (assuming this model+priors and factoring in all data) $\\mu$ seems to range from about -2.5 to about 20, and its most likely value is between 5 and 10. Example : What's the probability that $\\mu$ is above 5? What does this mean in context? Answer : In [14]: count_above_5 = np . sum ( chain_df_list [ 0 ][ 'mu' ] > 15 ) total = len ( chain_df_list [ 0 ][ 'mu' ]) count_above_5 / total Out[14]: 0.0468 (Using just chain 0), there's a roughly 2-8% chance (changes from run to run) that $\\mu$ is above 15. In context, this means that a there's very little chance the program, on average, increases student scores by 15 or more. Practically, we might decide that the program isn't worth it; maybe we only feel increases of less than 50 SAT points aren't worth paying for. Discussion Is it more apropriate to use one chain, or combine all four? Repeating that plot for $\\tau$ In [15]: for cur_chain in range ( num_chains ): plt . hist ( chain_df_list [ cur_chain ][ 'tau' ], bins = 100 , histtype = 'step' , density = True , label = \"Chain {} \" . format ( cur_chain )); plt . xlabel ( \"Value of tau\" ) plt . ylabel ( \"Approx. Posterior Probability\" ) plt . legend () plt . show () Exercise 1 What can you conclude from the plot above? Answer : Exploring effect in each school Investigating the $\\theta_j$ is a touch more complex becuase there is one per school. Overall, it looks like each school's theta is about the same-- the model is suggesting pooling all the schools' data together. We can also see some issues from the sampler manifesting; different chains get stuck in and create bumps in different places. In [17]: fig , ax = plt . subplots ( 1 , num_chains , figsize = ( 20 , 5 ), sharex = True , sharey = True ) for cur_chain in range ( num_chains ): ax [ cur_chain ] . set_xlabel ( \"Thetas from Chain {} \" . format ( cur_chain )) ax [ cur_chain ] . set_ylabel ( \"Approx. Posterior Probability\" . format ( cur_chain )) for i in range ( 8 ): cur_name = 'theta' + str ( i ) all_theta_n = samples [ 'theta' ][ i ,:,:] ax [ cur_chain ] . hist ( chain_df_list [ cur_chain ][ cur_name ], bins = 100 , histtype = 'step' , label = \"School {} \" . format ( school_data [ \"School\" ][ i ]), density = True ) plt . legend () plt . show () Exercise 2 Interrogate the results Summarize the effect of school A's program- how many SAT points do students seem to gain on average? What's the probability that the program, on average, actually lowers scores? What's the probability that a particular school would end up with a program that lowers student scores? Can you make the MCMC converge better? Better priors? Longer sampling run? Answers : Discussion Overall, what does a Bayesian analysis buy you? What is the price of entry? Harry Potter and the Latent Dirichlet Analysis Before we do anything else, let's talk about the Dirichlet distribution The Dirichlet distribution takes in N parameters and spits out a probability vector of length N. The above graphs show which probability vectors are likely for different parameter settings, but it's easiest just to see for yourself: In [50]: length = 3 for rep in range ( 5 ): vec = np . random . dirichlet ([ . 1 ] * length ) print ( np . round ( vec , 3 )) [0.036 0.034 0.931] [0. 0.034 0.966] [0. 1. 0.] [0.344 0.656 0. ] [0. 1. 0.] (above) Values less than 1 make a few entries of the output vector large, and most entries small In [51]: for rep in range ( 5 ): vec = np . random . dirichlet ([ 1 ] * length ) print ( np . round ( vec , 3 )) [0.559 0.329 0.112] [0.263 0.038 0.699] [0.716 0.133 0.151] [0.408 0.086 0.506] [0.657 0.272 0.071] (above) Values of 1 make all possible probability vectors equally likely, in some sense Exercise 3 What happens when the inputs to Dirichlet are all large (above 1)? What happens if you make one entry substantially bigger than the others? Answer : The LDA Model (as code) Prof Glickman did a good job in lecture covering LDA from lots of different viewpoints. The one thing we haven't seen is actual code to produce a document via the LDA framework. I honestly think this is the clearest way to tell LDA's story. In [54]: np . random . seed ( 7 ) # scalar givens num_docs = 5 num_topics = 3 vocab = [ \"yes\" , \"no\" , \"harry\" , \"hermione\" , \"ron\" , \"dumbledore\" ] vocab_len = len ( vocab ) # vector givens: alphas and betas are given (or found when we solve the model) alphas = . 8 * np . ones ( num_topics ) betas = . 3 * np . ones ( vocab_len ) # each document has a probability of talking about each topic thetas = np . zeros (( num_docs , num_topics )) for cur_doc in range ( num_docs ): thetas [ cur_doc ,:] = np . random . dirichlet ( alphas ) # each topic has a probability of talking about each word phis = np . zeros (( num_topics , vocab_len )) for cur_topic in range ( num_topics ): phis [ cur_topic ,:] = np . random . dirichlet ( betas ) ## # write document 1 for 20 words, as an example ## cur_doc = 1 doc_words = [] # get the document's probability of talking about each topic topic_probs = thetas [ cur_doc ,:] # for each word in the document's length: for cur_word in range ( 20 ): # Using the document's topic probabilities, randomly decide the topic this word belongs to cur_topic_vec = np . random . multinomial ( 1 , topic_probs ) cur_topic_int = np . argmax ( cur_topic_vec ) # Using the topic's word probabilites, randomly decide which word will appear word_probs = phis [ cur_topic ,:] cur_word_vec = np . random . multinomial ( 1 , word_probs ) cur_word_int = np . argmax ( cur_word_vec ) # store the word doc_words . append ( vocab [ cur_word_int ]) print ( \"Dpcument 1's Topics\" ) print ( thetas [ 0 ,:]) print ( \"Document 1's Words\" ) print ( doc_words ) Dpcument 1's Topics [0.008885 0.08921879 0.90189621] Document 1's Words ['ron', 'ron', 'dumbledore', 'ron', 'ron', 'ron', 'dumbledore', 'ron', 'no', 'no', 'no', 'no', 'ron', 'ron', 'ron', 'yes', 'no', 'ron', 'ron', 'ron'] Exercise 2 Interpret the $\\theta$ and $\\phi$ matrices, below Why do \"no\", \"dumbledor\" and \"ron\" show up so much in document 1? In [55]: display ( np . round ( thetas , 2 )) display ( np . round ( phis , 2 )) array([[0.01, 0.09, 0.9 ], [0.31, 0.12, 0.57], [0.47, 0.32, 0.21], [0.22, 0.05, 0.73], [0.35, 0.56, 0.09]]) array([[0.04, 0.04, 0.44, 0.16, 0.07, 0.25], [0.18, 0.13, 0.01, 0.14, 0.54, 0. ], [0.02, 0.38, 0. , 0.03, 0.45, 0.12]]) Answer : Answer : The LDA model (as equations) There are T topics, D documents, V words in the corpus $$\\alpha_t,\\ given \\text{ for t=1,2,...T}$$ $$\\beta_w,\\ given \\text{ for w=1,2,...V}$$ $$ \\theta_{d,:} \\sim Dirichlet\\left(\\alpha_1,\\alpha_2, ...,\\alpha_T\\right) \\text{ for d=1,2,...D}$$ $$ \\phi_{t,:} \\sim Dirichlet\\left(\\beta_1,\\beta_2, ...,\\beta_W\\right) \\text{ for t=1,2,...T}$$ $$z_{d,i} \\sim Multinomial\\left(\\theta_{d,1},\\theta_{d,2},...\\theta_{d,T}\\right) \\text{ for each d,i}$$ $$w_{d,i} \\sim Multinomial\\left(\\phi_{z_{d,i},1},\\phi_{z_{d,i},2},...\\phi_{z_{d,i},V}\\right) \\text{ for each d,i}$$ $w_{d,i}$ is the $i$th word in the $d$th document $z_{d,i}$ is the topic of the $i$th word in the $d$th document $\\phi_{t,i}$ is the probability of word $i$ appearing when the topic is $t$ $\\theta_{d,t}$ is the probability of document $d$ talking about topic $t$ The $\\beta_w$ determine how likely overall each word is, and how many words typically occur in the same topic The $\\alpha_t$ determine how likely overall each topic is, and how many topics typically occur in the same document Fitting LDA In [73]: import nltk nltk . download ( 'stopwords' ) from nltk.corpus import stopwords from nltk.tokenize import RegexpTokenizer from gensim.corpora import Dictionary from gensim.models.ldamodel import LdaModel from gensim.models import CoherenceModel [nltk_data] Downloading package stopwords to [nltk_data] /home/40960295/nltk_data... [nltk_data] Package stopwords is already up-to-date! Below is the code used to clean the Harry Potter books. Because we're not about to host the full text on a public GitHub, these cells will produce errors. If you see someone ask about it on Piazza, please cheekily refer them to this sentence. First, we define what counts as a word for us. The regular expression below translates to \"any number of letters, digits, numbers, and apostrophes\". Note that we'll include \"Ron\" and \"Ron's\" as different words, and \"fast-acting\" is two words. In [74]: tokenizer = RegexpTokenizer ( r '[\\w \\' ]+' ) # \\w means any letter or digit. #Overall, \"words\" in the corpus are any number of letters, digits, and apostrophes. No hyphens or other fancyness. Often, any very-common words are dropped from the text before extracting topics from it. NLTK provides a list of common words in different languages, which we augment with Potter-specfic words. In [75]: stop_words = set ( stopwords . words ( 'english' )) stop_words . update ([ 'harry' , 'hermione' , 'ron' ]) #add stop words for three main characters stop_words . update ([ 'said' , 'got' , 'get' , 'would' , 'could' ]) #empirically find these words very common You can see the cleaning process below. For each book, we split it into chapters by hunting for the phrase \"Chapter\" or \"Epilogue\", lowercase the chapter, split it into a list of individual words, and purge the common words. In [112]: hp_text_array = [ 0 ] * 7 for booknum in range ( 7 ): print ( booknum ) with open ( \"data/harrypotter_book\" + str ( booknum + 1 ) + \".txt\" , \"r\" , encoding = \"UTF-8\" ) as book : book_text = book . read () chapter_text_list = re . split ( r 'Chapter\\s?\\d*|Epilogue' , book_text ) hp_text_array [ booknum ] = chapter_text_list for cur_chapter_id , cur_chapter_text in enumerate ( chapter_text_list ): #make everything lower case cur_chapter_text = cur_chapter_text . lower () #tokenize chapter_word_list = tokenizer . tokenize ( cur_chapter_text ) #remove stop words purged_word_list = [ cur_word for cur_word in chapter_word_list if cur_word not in stop_words ] #store: [book][chapter]->list of words hp_text_array [ booknum ][ cur_chapter_id ] = purged_word_list 0 1 2 3 4 5 6 In [116]: import pickle with open ( \"data/HP_words.pkl\" , \"wb\" ) as outfile : pickle . dump ( hp_text_array , outfile ) This is the cell that will load the processesed data so you can continue with lab. An example of the structure we're working with is below In [117]: with open ( \"data/HP_words.pkl\" , \"rb\" ) as infile : hp_text_array = pickle . load ( infile ) In [118]: hp_text_array [ 0 ][ 11 ] #all (non-trivial) words in book 1, chapter 11 (yes 11- there's a preamble) Out[118]: ['quidditch', 'entered', 'november', 'weather', 'turned', 'cold', 'mountains', 'around', 'school', 'became', 'icy', 'gray', 'lake', 'like', 'chilled', 'steel', 'every', 'morning', 'ground', 'covered', 'frost', 'hagrid', 'seen', 'upstairs', 'windows', 'defrost', 'ing', 'broomsticks', 'quidditch', 'field', 'bundled', 'long', 'moleskin', 'overcoat', 'rabbit', 'fur', 'gloves', 'enormous', 'beaverskin', 'boots', 'quidditch', 'season', 'begun', 'saturday', 'playing', 'first', 'match', 'weeks', 'training', 'gryffindor', 'versus', 'slytherin', 'gryffindor', 'move', 'second', 'place', 'house', 'championship', 'hardly', 'anyone', 'seen', 'play', 'wood', 'decided', 'secret', 'weapon', 'kept', 'well', 'secret', 'news', 'playing', 'seeker', 'leaked', 'somehow', 'know', 'worse', 'people', 'telling', 'brilliant', 'people', 'telling', 'running', 'around', 'neath', 'holding', 'mattress', 'really', 'lucky', 'friend', 'know', 'gotten', 'homework', 'last', 'minute', 'quidditch', 'practice', 'wood', 'making', 'also', 'lent', 'quidditch', 'ages', 'turned', 'interesting', 'read', 'learned', 'seven', 'hundred', 'ways', 'commit', 'ting', 'quidditch', 'foul', 'happened', 'world', 'cup', 'match', '1473', 'seekers', 'usually', 'smallest', 'fastest', 'players', 'serious', 'quidditch', 'accidents', 'seemed', 'happen', 'although', 'people', 'rarely', 'died', 'play', 'ing', 'quidditch', 'referees', 'known', 'vanish', 'turn', 'months', 'later', 'sahara', 'desert', 'become', 'bit', 'relaxed', 'breaking', 'rules', 'since', 'saved', 'mountain', 'troll', 'much', 'nicer', 'day', 'first', 'quidditch', 'match', 'three', 'freezing', 'courtyard', 'break', 'conjured', 'bright', 'blue', 'fire', 'carried', 'around', 'jam', 'jar', 'standing', 'backs', 'getting', 'warm', 'snape', 'crossed', 'yard', 'noticed', 'snape', 'limping', 'moved', 'closer', 'together', 'block', 'fire', 'view', 'sure', 'allowed', 'unfortunately', 'something', 'guilty', 'faces', 'caught', 'snape', 'eye', 'limped', 'seen', 'fire', 'seemed', 'looking', 'reason', 'tell', 'anyway', 'potter', 'quidditch', 'ages', 'showed', 'library', 'books', 'taken', 'outside', 'school', 'snape', 'give', 'five', 'points', 'gryffindor', 'made', 'rule', 'muttered', 'angrily', 'snape', 'limped', 'away', 'wonder', 'wrong', 'leg', 'dunno', 'hope', 'really', 'hurting', 'bitterly', 'gryffindor', 'common', 'room', 'noisy', 'evening', 'sat', 'together', 'next', 'window', 'checking', 'charms', 'homework', 'never', 'let', 'copy', 'learn', 'asking', 'read', 'right', 'answers', 'anyway', 'felt', 'restless', 'wanted', 'quidditch', 'ages', 'back', 'take', 'mind', 'nerves', 'tomorrow', 'afraid', 'snape', 'getting', 'told', 'go', 'ing', 'ask', 'snape', 'better', 'together', 'idea', 'snape', 'refuse', 'teachers', 'listening', 'made', 'way', 'staffroom', 'knocked', 'answer', 'knocked', 'nothing', 'perhaps', 'snape', 'left', 'book', 'worth', 'try', 'pushed', 'door', 'ajar', 'peered', 'inside', 'horrible', 'scene', 'met', 'eyes', 'snape', 'filch', 'inside', 'alone', 'snape', 'holding', 'robes', 'knees', 'one', 'legs', 'bloody', 'mangled', 'filch', 'handing', 'snape', 'bandages', 'blasted', 'thing', 'snape', 'saying', 'supposed', 'keep', 'eyes', 'three', 'heads', 'tried', 'shut', 'door', 'quietly', 'potter', 'snape', 'face', 'twisted', 'fury', 'dropped', 'robes', 'quickly', 'hide', 'leg', 'gulped', 'wondered', 'book', 'back', 'left', 'snape', 'take', 'points', 'gryffindor', 'sprinted', 'back', 'upstairs', 'asked', 'joined', 'matter', 'low', 'whisper', 'told', 'seen', 'know', 'means', 'finished', 'breathlessly', 'tried', 'past', 'three', 'headed', 'dog', 'halloween', 'going', 'saw', 'whatever', 'guarding', 'bet', 'broomstick', 'let', 'troll', 'make', 'diversion', 'eyes', 'wide', 'know', 'nice', 'try', 'steal', 'something', 'dumbledore', 'keeping', 'safe', 'honestly', 'think', 'teachers', 'saints', 'thing', 'snapped', 'put', 'anything', 'past', 'snape', 'dog', 'guarding', 'went', 'bed', 'head', 'buzzing', 'ques', 'tion', 'neville', 'snoring', 'loudly', 'sleep', 'tried', 'empty', 'mind', 'needed', 'sleep', 'first', 'quidditch', 'match', 'hours', 'expression', 'snape', 'face', 'seen', 'leg', 'easy', 'forget', 'next', 'morning', 'dawned', 'bright', 'cold', 'great', 'hall', 'full', 'delicious', 'smell', 'fried', 'sausages', 'cheerful', 'chatter', 'everyone', 'looking', 'forward', 'good', 'quidditch', 'match', 'eat', 'breakfast', 'want', 'anything', 'bit', 'toast', 'wheedled', 'hungry', 'felt', 'terrible', 'hour', 'time', 'walking', 'onto', 'field', 'need', 'strength', 'seamus', 'finnigan', 'seek', 'ers', 'always', 'ones', 'clobbered', 'team', 'thanks', 'seamus', 'watching', 'seamus', 'pile', 'ketchup', 'sausages', 'eleven', 'clock', 'whole', 'school', 'seemed', 'stands', 'around', 'quidditch', 'pitch', 'many', 'students', 'binoculars', 'seats', 'might', 'raised', 'high', 'air', 'still', 'difficult', 'see', 'going', 'sometimes', 'joined', 'neville', 'seamus', 'dean', 'west', 'ham', 'fan', 'top', 'row', 'surprise', 'painted', 'large', 'banner', 'one', 'sheets', 'scabbers', 'ruined', 'potter', 'president', 'dean', 'good', 'drawing', 'done', 'large', 'gryffindor', 'lion', 'underneath', 'performed', 'tricky', 'little', 'charm', 'paint', 'flashed', 'different', 'colors', 'meanwhile', 'locker', 'room', 'rest', 'team', 'changing', 'scarlet', 'quidditch', 'robes', 'slytherin', 'playing', 'green', 'wood', 'cleared', 'throat', 'silence', 'okay', 'men', 'women', 'chaser', 'angelina', 'johnson', 'women', 'wood', 'agreed', 'big', 'one', 'fred', 'weasley', 'one', 'waiting', 'george', 'know', 'oliver', 'speech', 'heart', 'fred', 'told', 'team', 'last', 'year', 'shut', 'two', 'wood', 'best', 'team', 'gryf', 'findor', 'years', 'going', 'win', 'know', 'glared', 'say', 'else', 'right', 'time', 'good', 'luck', 'followed', 'fred', 'george', 'locker', 'room', 'hoping', 'knees', 'going', 'give', 'way', 'walked', 'onto', 'field', 'loud', 'cheers', 'madam', 'hooch', 'refereeing', 'stood', 'middle', 'field', 'waiting', 'two', 'teams', 'broom', 'hand', 'want', 'nice', 'fair', 'game', 'gathered', 'around', 'noticed', 'seemed', 'speaking', 'particularly', 'slytherin', 'captain', 'marcus', 'flint', 'fifth', 'year', 'thought', 'flint', 'looked', 'troll', 'blood', 'corner', 'eye', 'saw', 'fluttering', 'banner', 'high', 'flashing', 'potter', 'president', 'crowd', 'heart', 'skipped', 'felt', 'braver', 'mount', 'brooms', 'please', 'clambered', 'onto', 'nimbus', 'two', 'thousand', 'madam', 'hooch', 'gave', 'loud', 'blast', 'silver', 'whistle', 'fifteen', 'brooms', 'rose', 'high', 'high', 'air', 'quaffle', 'taken', 'immediately', 'angelina', 'johnson', 'gryffindor', 'excellent', 'chaser', 'girl', 'rather', 'tractive', 'jordan', 'sorry', 'professor', 'weasley', 'twins', 'friend', 'lee', 'jordan', 'commen', 'tary', 'match', 'closely', 'watched', 'professor', 'mcgonagall', 'really', 'belting', 'along', 'neat', 'pass', 'alicia', 'spinnet', 'good', 'find', 'oliver', 'wood', 'last', 'year', 'reserve', 'back', 'johnson', 'slytherins', 'taken', 'quaffle', 'slytherin', 'captain', 'marcus', 'flint', 'gains', 'quaffle', 'goes', 'flint', 'flying', 'like', 'eagle', 'going', 'sc', 'stopped', 'excellent', 'move', 'gryffindor', 'keeper', 'wood', 'gryffindors', 'take', 'quaffle', 'chaser', 'katie', 'bell', 'gryffindor', 'nice', 'dive', 'around', 'flint', 'field', 'ouch', 'must', 'hurt', 'hit', 'back', 'head', 'bludger', 'quaffle', 'taken', 'slytherins', 'adrian', 'pucey', 'speeding', 'toward', 'goal', 'posts', 'blocked', 'second', 'bludger', 'sent', 'way', 'fred', 'george', 'weasley', 'tell', 'nice', 'play', 'gryffindor', 'beater', 'anyway', 'johnson', 'back', 'possession', 'quaffle', 'clear', 'field', 'ahead', 'goes', 'really', 'flying', 'dodges', 'speeding', 'bludger', 'goal', 'posts', 'ahead', 'come', 'angelina', 'keeper', 'bletch', 'ley', 'dives', 'misses', 'gryffindors', 'score', 'gryffindor', 'cheers', 'filled', 'cold', 'air', 'howls', 'moans', 'slytherins', 'budge', 'move', 'along', 'hagrid', 'squeezed', 'together', 'give', 'hagrid', 'enough', 'space', 'join', 'bin', 'watchin', 'hut', 'hagrid', 'patting', 'large', 'pair', 'binoculars', 'around', 'neck', 'bein', 'crowd', 'sign', 'snitch', 'yet', 'eh', 'nope', 'much', 'yet', 'kept', 'outta', 'trouble', 'though', 'somethin', 'hagrid', 'rais', 'ing', 'binoculars', 'peering', 'skyward', 'speck', 'way', 'gliding', 'game', 'squinting', 'sign', 'snitch', 'part', 'wood', 'game', 'plan', 'keep', 'way', 'catch', 'sight', 'snitch', 'wood', 'want', 'attacked', 'angelina', 'scored', 'done', 'couple', 'loop', 'loops', 'let', 'feelings', 'back', 'staring', 'around', 'snitch', 'caught', 'sight', 'flash', 'gold', 'reflection', 'one', 'weasleys', 'wristwatches', 'bludger', 'decided', 'come', 'pelting', 'way', 'like', 'cannonball', 'anything', 'dodged', 'fred', 'weasley', 'came', 'chas', 'ing', 'right', 'time', 'yell', 'beat', 'bludger', 'furiously', 'toward', 'marcus', 'flint', 'slytherin', 'possession', 'lee', 'jordan', 'saying', 'chaser', 'pucey', 'ducks', 'two', 'bludgers', 'two', 'weasleys', 'chaser', 'bell', 'speeds', 'toward', 'wait', 'moment', 'snitch', 'murmur', 'ran', 'crowd', 'adrian', 'pucey', 'dropped', 'quaffle', 'busy', 'looking', 'shoulder', 'flash', 'gold', 'passed', 'left', 'ear', 'saw', 'great', 'rush', 'excitement', 'dived', 'downward', 'streak', 'gold', 'slytherin', 'seeker', 'terence', 'higgs', 'seen', 'neck', 'neck', 'hurtled', 'toward', 'snitch', 'chasers', 'seemed', 'forgotten', 'supposed', 'hung', 'midair', 'watch', 'faster', 'higgs', 'see', 'little', 'round', 'ball', 'wings', 'fluttering', 'darting', 'ahead', 'put', 'extra', 'spurt', 'speed', 'wham', 'roar', 'rage', 'echoed', 'gryffindors', 'marcus', 'flint', 'blocked', 'purpose', ...] Exploring Let's see if books 1 and 7 differ in their most common words. Python's Counter object is really good at, well, counting. In [119]: from collections import Counter counts = Counter ( hp_text_array [ 0 ][ 11 ]) #count which words are in Book 1, Chapter 11 counts . most_common ( 15 ) Out[119]: [('snape', 31), ('hagrid', 19), ('gryffindor', 17), ('quidditch', 15), ('broom', 15), ('flint', 14), ('back', 12), ('know', 11), ('one', 11), ('wood', 10), ('quaffle', 9), ('around', 8), ('snitch', 8), ('ing', 7), ('field', 7)] You can add counter objects together. Let's check out the top words in Book 1 versus Book 7. Does Book 7 seem darker? In [120]: book1_counter = Counter () for cur_chapter_words in hp_text_array [ 0 ]: chapter_word_count = Counter ( cur_chapter_words ) book1_counter += chapter_word_count book1_counter . most_common ( 10 ) Out[120]: [('hagrid', 357), ('back', 261), ('one', 258), ('know', 215), ('like', 192), ('see', 180), ('snape', 171), ('professor', 170), ('looked', 169), ('dumbledore', 152)] In [121]: book7_counter = Counter () for cur_chapter_words in hp_text_array [ 6 ]: chapter_word_count = Counter ( cur_chapter_words ) book7_counter += chapter_word_count book7_counter . most_common ( 10 ) Out[121]: [('wand', 596), ('dumbledore', 591), ('back', 544), ('know', 542), ('like', 458), ('one', 449), ('voldemort', 446), ('looked', 432), ('around', 363), ('still', 352)] Hmmm, there's a lot of overlap (\"back\",\"know\",\"like\",\"looked\"), but book 1 has a lot more Hagrid, and book 7 has a lot more Voldemort. Exercise 2 Find the 20 most common words across all the books Answer : Fitting LDA LDA wants to operate on a list of all documents. (Here, we're treating each chapter as its own document). We need to restructure our data In [123]: list_of_docs = [] for book_id in range ( 7 ): for chapter in hp_text_array [ book_id ]: list_of_docs . append ( chapter ) We build a gensim Dictionary on all the documents -- this tracks and numbers all words used in any of the documents. In [124]: masterdictionary = Dictionary ( list_of_docs ) We use the doc2bow to convert each document to a numerical format In [125]: mastercorpus = [ masterdictionary . doc2bow ( doc ) for doc in list_of_docs ] In [126]: mastercorpus [ 11 ][: 20 ] #20 words and their counts from book 1, chapter 11 Out[126]: [(32, 1), (54, 3), (57, 2), (58, 2), (59, 1), (70, 1), (76, 1), (82, 11), (86, 1), (90, 4), (111, 3), (113, 1), (130, 1), (133, 1), (138, 1), (139, 1), (145, 1), (148, 6), (151, 1), (152, 2)] Invoking the dictionary, we can translate to see that book 1, chapter 11 used the word 'hogwarts' once and the word 'one' eleven times. In [127]: masterdictionary [ 59 ], masterdictionary [ 82 ] Out[127]: ('hogwarts', 'one') Now, we're ready to actually fit a model In [128]: seven_book_model = LdaModel ( mastercorpus , num_topics = 7 , id2word = masterdictionary , passes = 10 ) We can investigate any particular topic In [129]: seven_book_model . show_topic ( 2 , topn = 20 ) Out[129]: [('weasley', 0.009971628), ('mr', 0.0061152214), ('back', 0.0056994683), ('know', 0.00521109), ('one', 0.003969954), ('like', 0.003714172), ('car', 0.0036524823), ('fred', 0.0035978646), ('mrs', 0.0035469406), ('around', 0.0033618358), ('looked', 0.0031710735), ('lupin', 0.0030880375), ('george', 0.003071988), ('time', 0.0030347034), ('door', 0.0030331232), ('see', 0.0030115694), ('right', 0.00298992), ('go', 0.0029416424), ('think', 0.0027970911), ('hogwarts', 0.0027610017)] It's nicer to plot the heavy-hitting words in each topic, though In [130]: top_words = [[ word for word , _ in seven_book_model . show_topic ( topicno , topn = 50 )] for topicno in range ( seven_book_model . num_topics )] top_betas = [[ beta for _ , beta in seven_book_model . show_topic ( topicno , topn = 50 )] for topicno in range ( seven_book_model . num_topics )] top_words [ 0 ][: 5 ] top_betas [ 0 ][: 5 ] gs = gridspec . GridSpec ( 3 , 3 ) gs . update ( wspace = 0.5 , hspace = 0.5 ) plt . figure ( figsize = ( 11 , 8.5 )) for i in range ( 7 ): #new subplot ax = plt . subplot ( gs [ i ]) plt . barh ( range ( 5 ), top_betas [ i ][: 5 ], align = 'center' , color = 'blue' , ecolor = 'black' ) ax . invert_yaxis () ax . set_yticks ( range ( 5 )) ax . set_yticklabels ( top_words [ i ][: 5 ]) plt . title ( \"Topic \" + str ( i )) In [131]: #finding optimal number of topics for book 1 via coherence measure u_mass coherence_vals = [] for ntop in range ( 1 , 12 ): mod = LdaModel ( mastercorpus , num_topics = ntop , id2word = masterdictionary , passes = 10 ) cmod = CoherenceModel ( model = mod , corpus = mastercorpus , dictionary = masterdictionary , coherence = 'u_mass' ) cval = cmod . get_coherence () print ( ntop , cval ) coherence_vals . append ( cval ) 1 -0.06658074296200506 2 -0.09209196248981996 3 -0.12238222054387032 4 -0.12166218708149992 5 -0.17002467133413787 6 -0.890047503574987 7 -0.2968548788467019 8 -0.6939044922084053 9 -0.5234586594541473 10 -0.19845307086804698 11 -0.3880701368848243 In [132]: _ = plt . figure ( figsize = ( 11 , 8.5 )) _ = plt . plot ( range ( 1 , 12 ), coherence_vals ) _ = plt . xlabel ( \"Number of Topics\" ) _ = plt . ylabel ( \"Coherence Score\" ) Discussion Overall, is LDA more like KNN or K-means? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab9/LDA/"},{"title":"Lecture 15:  Bayesian 1/3","text":"Slides This lecture is only available to registered students Lecture 15-17 PDF Associated Material","tags":"pages","url":"pages/lecture15/"},{"title":"Lecture 14: Reinforcement Learning","text":"Slides Lecture 14 PDF Lecture 14 PPTX","tags":"lectures","url":"lectures/lecture14/"},{"title":"Advanced Section 5: Neural Style Transfer","text":"Slides PDF Lecture Notes PDF DeepDream Blog DeepDream Generator","tags":"A-sections","url":"a-sections/a-section5/"},{"title":"Lab 7: Clustering","text":"Notebooks Lab7 Clustering Lab7 Clustering with solutions","tags":"pages","url":"pages/lab7/"},{"title":"Lecture 13: Unsupervised Learning, Cluster Analysis","text":"Slides This lecture is only available to registered students Lecture 12-13 PDF Associated Material Lab 7 Lab 7 solutions","tags":"pages","url":"pages/lecture13/"},{"title":"Lecture 12: Unsupervised Learning, Cluster Analysis","text":"Slides This lecture is only available to registered students Lecture 12-13 PDF Associated Material Lab 7 Lab 7 solutions","tags":"pages","url":"pages/lecture12/"},{"title":"Lab 6: Recurrent Neural Networks","text":"Notebooks Lab6 RNNs Lab6 RNNs with solutions Installation Instructions OpenAIgym","tags":"pages","url":"pages/lab6/"},{"title":"Installation instructions","text":"Please install the OpenAIgym package on JupyterHub (similar to what you did with viz package last lab). You will need for the HW next week. pip install gym https://gym.openai.com/docs/","tags":"lab","url":"lab/lab6/inst/"},{"title":"Lab 6: Recurrent Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Advanced Data Science Lab 6: Recurrent Neural Networks Harvard University Spring 2019 Lab instructor: Srivatsan Srinivasan Instructors: Pavlos Protopapas and Mark Glickman Authors: Srivatsan Srinivasan, Pavlos Protopapas In [ ]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Learning Goals In this lab we will look at Recurrent Neural Networks (RNNs), LSTMs and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in RNNs and its variants (GRU, LSTM) in keras with an example. have a good undertanding on how sequences - any dataset that has some temporal semantics (time series, natural language, images etc.) fit into and benefit from a recurrent architecture be familiar with preprocessing text, dynamic embeddings be familiar with gradient issues on RNNs processing longer sentence lengths understand different kinds of LSTM architectures - classifier, sequence to sequence models and their far-reaching applications 1. IMDB Review Classification Battlefield - Contestants : Feedforward, CNN, RNN, LSTM In this task, we are going to do sentiment classification on a movie review dataset. We are going to build a feedforward net, a convolutional neural net, a recurrent net and combine one or more of them to understand performance of each of them. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. There are also semantic connections backwards in a sentence, in an ideal case (in which we use RNNs from both directions and combine their outputs). But for the purpose of this tutorial, we are going to restrict ourselves to only uni-directional RNNs. In [ ]: import numpy from keras.datasets import imdb from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM , SimpleRNN from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np # fix random seed for reproducibility numpy . random . seed ( 1 ) In [ ]: # We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small vocabulary_size = 10000 #We also want to have a finite length of reviews and not have to process really long sentences. max_review_length = 500 TOKENIZATION For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example. Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary. i have books - [1, 4, 7] interesting books are useful [10,2,9,8] i have computers [1,4,6] computers are interesting and useful [6,9,11,10,8] books and computers are both valuable. [2,10,2,9,13,12] Bye Bye [7,7] Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens I-1, books-2, computers-3, have-4, are-5, computers-6,bye-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13 Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form. Load data In [ ]: ( X_train , y_train ), ( X_test , y_test ) = imdb . load_data ( num_words = vocabulary_size ) print ( 'Number of reviews' , len ( X_train )) print ( 'Length of first and fifth review before padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) print ( 'First review' , X_train [ 0 ]) print ( 'First label' , y_train [ 0 ]) Preprocess data Pad sequences in order to ensure that all inputs have same sentence length and dimensions. In [ ]: X_train = sequence . pad_sequences ( X_train , maxlen = max_review_length ) X_test = sequence . pad_sequences ( X_test , maxlen = max_review_length ) print ( 'Length of first and fifth review after padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS Let us build a single layer feedforward net with 250 nodes. Each input would be a 500-dim vector of tokens since we padded all our sequences to size 500. EXERCISE : Calculate the number of parameters involved in this network and implement a feedforward net to do classification without looking at cells below. In [ ]: model = Sequential () model . add ( Dense ( 250 , activation = 'relu' , input_dim = max_review_length )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) Discussion : Why was the performance bad ? What was wrong with tokenization ? MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS What is an embedding layer ? An embedding is a linear projection from one vector space to another. We usually use embeddings to project the one-hot encodings of words on to a lower-dimensional continuous space so that the input surface is dense and possibly smooth. According to the model, an embedding layer is just a transformation from $\\mathbb{R}&#94;{inp}$ to $\\mathbb{R}&#94;{emb}$ In [ ]: embedding_dim = 100 In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) #inputs will be converted from batch_size * sentence_length to batch_size*sentence_length*embedding _dim model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) In [ ]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) MODEL 2 : CONVOLUTIONAL NEURAL NETWORKS Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog. http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/ Fit a 1D convolution with 200 filters, kernel size 3 followed by a feedforward layer of 250 nodes and ReLU, sigmoid activations as appropriate. In [ ]: # create the model model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( Conv1D ( filters = 200 , kernel_size = 3 , padding = 'same' , activation = 'relu' )) model . add ( MaxPooling1D ( pool_size = 2 )) model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) MODEL 3 : SIMPLE RNN Two of the best blogs that help understand the workings of a RNN and LSTM are http://karpathy.github.io/2015/05/21/rnn-effectiveness/ http://colah.github.io/posts/2015-08-Understanding-LSTMs/ Mathematically speaking, a simple RNN does the following. It constructs a set of hidden states using the state variable from the previous timestep and the input at current time. Mathematically, a simpleRNN can be defined by the following relation. $h_t = \\sigma(W([h_{t-1},x_{t}])+b)$ If we extend this recurrence relation to the length of sequences we have in hand, we have our RNN network constructed. In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( SimpleRNN ( 100 )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) model . fit ( X_train , y_train , epochs = 3 , batch_size = 64 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) RNNs and vanishing/exploding gradients Let us use sigmoid activations as example. Derivative of a sigmoid can be written as $\\sigma'(x) = \\sigma(x) \\cdot \\sigma(1-x)$. Remember RNN is a \"really deep\" feedforward network (when unrolled in time). Hence, backpropagation happens from $h_t$ all the way to $h_1$. Also realize that sigmoid gradients are multiplicatively dependent on the value of sigmoid. Hence, if the non-activated output of any layer $h_l$ is < 0, then $\\sigma$ tends to 0, effectively \"vanishing\" gradient. Any layer that the current layer backprops to $H_{1:L-1}$ do not learn anything useful out of the gradients. LSTMs and GRU LSTM and GRU are two sophisticated implementations of RNN which essentially are built on what we call as gates. A gate is a probability number between 0 and 1. For instance, LSTM is built on these state updates Note : L is just a linear transformation L(x) = W*x + b. $f_t = \\sigma(L([h_{t-1},x_t))$ $i_t = \\sigma(L([h_{t-1},x_t))$ $o_t = \\sigma(L([h_{t-1},x_t))$ $\\hat{C}_t = \\tanh(L([h_{t-1},x_t))$ $C_t = f_t * C_{t-1}+i_t*\\hat{C}_t$ (Using the forget gate, the neural network can learn to control how much information it has to retain or forget) $h_t = o_t * \\tanh(c_t)$ MODEL 4 : LSTM In the next step, we will implement a LSTM model to do classification. Use the same architecture as before. Try experimenting with increasing the number of nodes, stacking multiple layers, applyong dropouts etc. Check the number of parameters that this model entails. In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( LSTM ( 100 )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) model . fit ( X_train , y_train , epochs = 3 , batch_size = 64 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) MODEL 5 : CNN + LSTM CNNs are good at learning spatial features and sentences can be thought of as 1-D spatial vectors (dimension being connotated by the sequence ordering among the words in the sentence.). We apply a LSTM over the features learned by the CNN (after a maxpooling layer). This leverages the power of CNNs and LSTMs combined. We expect the CNN to be able to pick out invariant features across the 1-D spatial structure(i.e. sentence) that characterize good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer followed by a feedforward for classification. In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( Conv1D ( filters = 32 , kernel_size = 3 , padding = 'same' , activation = 'relu' )) model . add ( MaxPooling1D ( pool_size = 2 )) model . add ( LSTM ( 100 )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) model . fit ( X_train , y_train , epochs = 3 , batch_size = 64 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) CONCLUSION We saw the power of sequence models and how they are useful in text classification. They give a solid performance, low memory footprint (thanks to shared parameters) and are able to understand and leverage the temporally connected information contained in the inputs. There is still an open debate about the performance vs memory benefits of CNNs vs RNNs in the research community. 2. 231+432 = 665.... It's not ? Let's ask our LSTM In this exercise, we are going to teach addition to our model. Given two numbers (<999), the model outputs their sum (<9999). The input is provided as a string '231+432' and the model will provide its output as ' 663' (Here the empty space is the padding character). We are not going to use any external dataset and are going to construct our own dataset for this exercise. The exercise we attempt to do effectively \"translates\" a sequence of characters '231+432' to another sequence of characters ' 663' and hence, this class of models are called sequence-to-sequence models. Such architectures have profound applications in several real-life tasks such as machine translation, summarization, image captioning etc. In [ ]: from __future__ import print_function from keras.models import Sequential from keras import layers from keras.layers import Dense , RepeatVector , TimeDistributed import numpy as np from six.moves import range The less interesting data generation and preprocessing In [ ]: class CharacterTable ( object ): def __init__ ( self , chars ): self . chars = sorted ( set ( chars )) self . char_indices = dict (( c , i ) for i , c in enumerate ( self . chars )) self . indices_char = dict (( i , c ) for i , c in enumerate ( self . chars )) #One-hot encodes def encode ( self , C , num_rows ): x = np . zeros (( num_rows , len ( self . chars ))) for i , c in enumerate ( C ): x [ i , self . char_indices [ c ]] = 1 return x #Decodes a one-hot encoding def decode ( self , x , calc_argmax = True ): if calc_argmax : x = x . argmax ( axis =- 1 ) return '' . join ( self . indices_char [ x ] for x in x ) In [ ]: TRAINING_SIZE = 50000 DIGITS = 3 MAXOUTPUTLEN = DIGITS + 1 MAXLEN = DIGITS + 1 + DIGITS chars = '0123456789+ ' ctable = CharacterTable ( chars ) In [ ]: def return_random_digit (): return np . random . choice ( list ( '0123456789' )) def generate_number (): num_digits = np . random . randint ( 1 , DIGITS + 1 ) return int ( '' . join ( return_random_digit () for i in range ( num_digits ))) def data_generate ( num_examples ): questions = [] expected = [] seen = set () print ( 'Generating data...' ) while len ( questions ) < TRAINING_SIZE : a , b = generate_number (), generate_number () #Remove already seen elements key = tuple ( sorted (( a , b ))) if key in seen : continue seen . add ( key ) # Pad the data with spaces such that it is always MAXLEN. q = ' {} + {} ' . format ( a , b ) query = q + ' ' * ( MAXLEN - len ( q )) ans = str ( a + b ) # Answers can be of maximum size DIGITS + 1. ans += ' ' * ( MAXOUTPUTLEN - len ( ans )) questions . append ( query ) expected . append ( ans ) print ( 'Total addition questions:' , len ( questions )) return questions , expected def encode_examples ( questions , answers ): x = np . zeros (( len ( questions ), MAXLEN , len ( chars )), dtype = np . bool ) y = np . zeros (( len ( questions ), DIGITS + 1 , len ( chars )), dtype = np . bool ) for i , sentence in enumerate ( questions ): x [ i ] = ctable . encode ( sentence , MAXLEN ) for i , sentence in enumerate ( answers ): y [ i ] = ctable . encode ( sentence , DIGITS + 1 ) indices = np . arange ( len ( y )) np . random . shuffle ( indices ) return x [ indices ], y [ indices ] In [ ]: q , a = data_generate ( TRAINING_SIZE ) x , y = encode_examples ( q , a ) split_at = len ( x ) - len ( x ) // 10 x_train , x_val , y_train , y_val = x [: split_at ], x [ split_at :], y [: split_at ], y [ split_at :] print ( 'Training Data shape:' ) print ( 'X : ' , x_train . shape ) print ( 'Y : ' , y_train . shape ) print ( 'Sample Question(in encoded form) : ' , x_train [ 0 ], y_train [ 0 ]) print ( 'Sample Question(in decoded form) : ' , ctable . decode ( x_train [ 0 ]), 'Sample Output : ' , ctable . decode ( y_train [ 0 ])) Let's learn two wrapper functions in Keras - TimeDistributed and RepeatVector with some dummy examples. TimeDistributed is a wrapper function call that applies an input operation on all the timesteps of an input data. For instance I have a feedforward network which converts a 10-dim vector to a 5-dim vector, then wrapping this timedistributed layer on that feedforward operation would convert a batch_size * sentence_len * vector_len(=10) to batch_size * sentence_len * output_len(=5) In [ ]: model = Sequential () #Inputs to it will be batch_size*time_steps*input_vector_dim(to Dense) . Output will be batch_size*time_steps* output_vector_dim #Here dense converts a 5-dim input vector to a 8-dim vector. model . add ( TimeDistributed ( Dense ( 8 ), input_shape = ( 3 , 5 ))) input_array = np . random . randint ( 10 , size = ( 1 , 3 , 5 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( \"Shape of output : \" , output_array . shape ) RepeatVector repeats the vector a specified number of times. Dimension changes from batch_size number of elements to batch_size number of repetitions * number of elements. In [ ]: model = Sequential () #converts from 1*10 to 1 * 6 model . add ( Dense ( 6 , input_dim = 10 )) print ( model . output_shape ) #converts from 1*6 to 1*3*6 model . add ( RepeatVector ( 3 )) print ( model . output_shape ) input_array = np . random . randint ( 1000 , size = ( 1 , 10 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( \"Shape of output : \" , output_array . shape ) # note: `None` is the batch dimension print ( 'Input : ' , input_array [ 0 ]) print ( 'Output : ' , output_array [ 0 ]) MODEL ARCHITECTURE Note : Whenever you are initializing a LSTM in Keras, by the default the option return_sequences = False. This means that at the end of the step the next component will only get to see the final hidden layer's values. On the other hand, if you set return_sequences = True, the LSTM component will return the hidden layer at each time step. It means that the next component should be able to consume inputs in that form. Think how this statement is relevant in terms of this model architecture and the TimeDistributed module we just learned. Build an encoder and decoder both single layer 128 nodes and an appropriate dense layer as needed by the model. In [ ]: #Hyperaparams RNN = layers . LSTM HIDDEN_SIZE = 128 BATCH_SIZE = 128 LAYERS = 1 print ( 'Build model...' ) model = Sequential () #ENCODING model . add ( RNN ( HIDDEN_SIZE , input_shape = ( MAXLEN , len ( chars )))) model . add ( RepeatVector ( MAXOUTPUTLEN )) #DECODING for _ in range ( LAYERS ): model . add ( RNN ( HIDDEN_SIZE , return_sequences = True )) model . add ( TimeDistributed ( layers . Dense ( len ( chars ), activation = 'softmax' ))) model . compile ( loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) model . summary () Let's check how well our model trained. In [ ]: for iteration in range ( 1 , 2 ): print () model . fit ( x_train , y_train , batch_size = BATCH_SIZE , epochs = 20 , validation_data = ( x_val , y_val )) # Select 10 samples from the validation set at random so we can visualize # errors. print ( 'Finished iteration ' , iteration ) numcorrect = 0 numtotal = 20 for i in range ( numtotal ): ind = np . random . randint ( 0 , len ( x_val )) rowx , rowy = x_val [ np . array ([ ind ])], y_val [ np . array ([ ind ])] preds = model . predict_classes ( rowx , verbose = 0 ) q = ctable . decode ( rowx [ 0 ]) correct = ctable . decode ( rowy [ 0 ]) guess = ctable . decode ( preds [ 0 ], calc_argmax = False ) print ( 'Question' , q , end = ' ' ) print ( 'True' , correct , end = ' ' ) print ( 'Guess' , guess , end = ' ' ) if guess == correct : print ( 'Good job' ) numcorrect += 1 else : print ( 'Fail' ) print ( 'The model scored ' , numcorrect * 100 / numtotal , ' % i n its test.' ) EXERCISE Try changing the hyperparams, use other RNNs, more layers, check if increasing the number of epochs is useful. Try reversing the data from validation set and check if commutative property of addition is learned by the model. Try printing the hidden layer with two inputs that are commutative and check if the hidden representations it learned are same or similar. Do we expect it to be true ? If so, why ? If not why ? You can access the layer using an index with model.layers and layer.output will give the output of that layer. Try doing addition in the RNN model the same way we do by hand. Reverse the order of digits and at each time step, input two digits get an output use the hidden layer and input next two digits and so on.(units in the first time step, tens in the second time step etc.) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab6/solutions/"},{"title":"Lab 6: Recurrent Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Advanced Data Science Lab 6: Recurrent Neural Networks Harvard University Spring 2019 Lab instructor: Srivatsan Srinivasan Instructors: Pavlos Protopapas and Mark Glickman Authors: Srivatsan Srinivasan, Pavlos Protopapas In [1]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab we will look at Recurrent Neural Networks (RNNs), LSTMs and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in RNNs and its variants (GRU, LSTM) in keras with an example. have a good undertanding on how sequences - any dataset that has some temporal semantics (time series, natural language, images etc.) fit into and benefit from a recurrent architecture be familiar with preprocessing text, dynamic embeddings be familiar with gradient issues on RNNs processing longer sentence lengths understand different kinds of LSTM architectures - classifier, sequence to sequence models and their far-reaching applications 1. IMDB Review Classification Battlefield - Contestants : Feedforward, CNN, RNN, LSTM In this task, we are going to do sentiment classification on a movie review dataset. We are going to build a feedforward net, a convolutional neural net, a recurrent net and combine one or more of them to understand performance of each of them. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. There are also semantic connections backwards in a sentence, in an ideal case (in which we use RNNs from both directions and combine their outputs). But for the purpose of this tutorial, we are going to restrict ourselves to only uni-directional RNNs. In [2]: import numpy from keras.datasets import imdb from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM , SimpleRNN from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np # fix random seed for reproducibility numpy . random . seed ( 1 ) Using TensorFlow backend. In [3]: # We want to have a finite vocabulary to make sure that our word matrices are not arbitrarily small vocabulary_size = 10000 #We also want to have a finite length of reviews and not have to process really long sentences. max_review_length = 500 TOKENIZATION For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example. Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary. i have books - [1, 4, 7] interesting books are useful [10,2,9,8] i have computers [1,4,6] computers are interesting and useful [6,9,11,10,8] books and computers are both valuable. [2,10,2,9,13,12] Bye Bye [7,7] Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens I-1, books-2, computers-3, have-4, are-5, computers-6,bye-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13 Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form. Load data In [ ]: ( X_train , y_train ), ( X_test , y_test ) = imdb . load_data ( num_words = vocabulary_size ) print ( 'Number of reviews' , len ( X_train )) print ( 'Length of first and fifth review before padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) print ( 'First review' , X_train [ 0 ]) print ( 'First label' , y_train [ 0 ]) Preprocess data Pad sequences in order to ensure that all inputs have same sentence length and dimensions. In [ ]: X_train = sequence . pad_sequences ( X_train , maxlen = max_review_length ) X_test = sequence . pad_sequences ( X_test , maxlen = max_review_length ) print ( 'Length of first and fifth review after padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS Let us build a single layer feedforward net with 250 nodes. Each input would be a 500-dim vector of tokens since we padded all our sequences to size 500. EXERCISE : Calculate the number of parameters involved in this network and implement a feedforward net to do classification without looking at cells below. In [ ]: #### YOUR CODE HERE #### Discussion : Why was the performance bad ? What was wrong with tokenization ? MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS What is an embedding layer ? An embedding is a linear projection from one vector space to another. We usually use embeddings to project the one-hot encodings of words on to a lower-dimensional continuous space so that the input surface is dense and possibly smooth. According to the model, an embedding layer is just a transformation from $\\mathbb{R}&#94;{inp}$ to $\\mathbb{R}&#94;{emb}$ In [ ]: embedding_dim = 100 In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) #inputs will be converted from batch_size * sentence_length to batch_size*sentence_length*embedding _dim model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) In [ ]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) MODEL 2 : CONVOLUTIONAL NEURAL NETWORKS Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog. http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/ Fit a 1D convolution with 200 filters, kernel size 3 followed by a feedforward layer of 250 nodes and ReLU, sigmoid activations as appropriate. In [ ]: #### YOUR CODE HERE #### MODEL 3 : SIMPLE RNN Two of the best blogs that help understand the workings of a RNN and LSTM are http://karpathy.github.io/2015/05/21/rnn-effectiveness/ http://colah.github.io/posts/2015-08-Understanding-LSTMs/ Mathematically speaking, a simple RNN does the following. It constructs a set of hidden states using the state variable from the previous timestep and the input at current time. Mathematically, a simpleRNN can be defined by the following relation. $h_t = \\sigma(W([h_{t-1},x_{t}])+b)$ If we extend this recurrence relation to the length of sequences we have in hand, we have our RNN network constructed. In [ ]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( SimpleRNN ( 100 )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) RNNs and vanishing/exploding gradients Let us use sigmoid activations as example. Derivative of a sigmoid can be written as $\\sigma'(x) = \\sigma(x) \\cdot \\sigma(1-x)$. Remember RNN is a \"really deep\" feedforward network (when unrolled in time). Hence, backpropagation happens from $h_t$ all the way to $h_1$. Also realize that sigmoid gradients are multiplicatively dependent on the value of sigmoid. Hence, if the non-activated output of any layer $h_l$ is < 0, then $\\sigma$ tends to 0, effectively \"vanishing\" gradient. Any layer that the current layer backprops to $H_{1:L-1}$ do not learn anything useful out of the gradients. LSTMs and GRU LSTM and GRU are two sophisticated implementations of RNN which essentially are built on what we call as gates. A gate is a probability number between 0 and 1. For instance, LSTM is built on these state updates Note : L is just a linear transformation L(x) = W*x + b. $f_t = \\sigma(L([h_{t-1},x_t))$ $i_t = \\sigma(L([h_{t-1},x_t))$ $o_t = \\sigma(L([h_{t-1},x_t))$ $\\hat{C}_t = \\tanh(L([h_{t-1},x_t))$ $C_t = f_t * C_{t-1}+i_t*\\hat{C}_t$ (Using the forget gate, the neural network can learn to control how much information it has to retain or forget) $h_t = o_t * \\tanh(c_t)$ MODEL 4 : LSTM In the next step, we will implement a LSTM model to do classification. Use the same architecture as before. Try experimenting with increasing the number of nodes, stacking multiple layers, applyong dropouts etc. Check the number of parameters that this model entails. In [ ]: #### YOUR CODE HERE #### MODEL 5 : CNN + LSTM CNNs are good at learning spatial features and sentences can be thought of as 1-D spatial vectors (dimension being connotated by the sequence ordering among the words in the sentence.). We apply a LSTM over the features learned by the CNN (after a maxpooling layer). This leverages the power of CNNs and LSTMs combined. We expect the CNN to be able to pick out invariant features across the 1-D spatial structure(i.e. sentence) that characterize good and bad sentiment. This learned spatial features may then be learned as sequences by an LSTM layer followed by a feedforward for classification. In [ ]: #### YOUR CODE HERE #### CONCLUSION We saw the power of sequence models and how they are useful in text classification. They give a solid performance, low memory footprint (thanks to shared parameters) and are able to understand and leverage the temporally connected information contained in the inputs. There is still an open debate about the performance vs memory benefits of CNNs vs RNNs in the research community. 2. 231+432 = 665.... It's not ? Let's ask our LSTM In this exercise, we are going to teach addition to our model. Given two numbers (<999), the model outputs their sum (<9999). The input is provided as a string '231+432' and the model will provide its output as ' 663' (Here the empty space is the padding character). We are not going to use any external dataset and are going to construct our own dataset for this exercise. The exercise we attempt to do effectively \"translates\" a sequence of characters '231+432' to another sequence of characters ' 663' and hence, this class of models are called sequence-to-sequence models. Such architectures have profound applications in several real-life tasks such as machine translation, summarization, image captioning etc. In [ ]: from __future__ import print_function from keras.models import Sequential from keras import layers from keras.layers import Dense , RepeatVector , TimeDistributed import numpy as np from six.moves import range The less interesting data generation and preprocessing In [ ]: class CharacterTable ( object ): def __init__ ( self , chars ): self . chars = sorted ( set ( chars )) self . char_indices = dict (( c , i ) for i , c in enumerate ( self . chars )) self . indices_char = dict (( i , c ) for i , c in enumerate ( self . chars )) #One-hot encodes def encode ( self , C , num_rows ): x = np . zeros (( num_rows , len ( self . chars ))) for i , c in enumerate ( C ): x [ i , self . char_indices [ c ]] = 1 return x #Decodes a one-hot encoding def decode ( self , x , calc_argmax = True ): if calc_argmax : x = x . argmax ( axis =- 1 ) return '' . join ( self . indices_char [ x ] for x in x ) In [ ]: TRAINING_SIZE = 50000 DIGITS = 3 MAXOUTPUTLEN = DIGITS + 1 MAXLEN = DIGITS + 1 + DIGITS chars = '0123456789+ ' ctable = CharacterTable ( chars ) In [ ]: def return_random_digit (): return np . random . choice ( list ( '0123456789' )) def generate_number (): num_digits = np . random . randint ( 1 , DIGITS + 1 ) return int ( '' . join ( return_random_digit () for i in range ( num_digits ))) def data_generate ( num_examples ): questions = [] expected = [] seen = set () print ( 'Generating data...' ) while len ( questions ) < TRAINING_SIZE : a , b = generate_number (), generate_number () #Remove already seen elements key = tuple ( sorted (( a , b ))) if key in seen : continue seen . add ( key ) # Pad the data with spaces such that it is always MAXLEN. q = ' {} + {} ' . format ( a , b ) query = q + ' ' * ( MAXLEN - len ( q )) ans = str ( a + b ) # Answers can be of maximum size DIGITS + 1. ans += ' ' * ( MAXOUTPUTLEN - len ( ans )) questions . append ( query ) expected . append ( ans ) print ( 'Total addition questions:' , len ( questions )) return questions , expected def encode_examples ( questions , answers ): x = np . zeros (( len ( questions ), MAXLEN , len ( chars )), dtype = np . bool ) y = np . zeros (( len ( questions ), DIGITS + 1 , len ( chars )), dtype = np . bool ) for i , sentence in enumerate ( questions ): x [ i ] = ctable . encode ( sentence , MAXLEN ) for i , sentence in enumerate ( answers ): y [ i ] = ctable . encode ( sentence , DIGITS + 1 ) indices = np . arange ( len ( y )) np . random . shuffle ( indices ) return x [ indices ], y [ indices ] In [ ]: q , a = data_generate ( TRAINING_SIZE ) x , y = encode_examples ( q , a ) split_at = len ( x ) - len ( x ) // 10 x_train , x_val , y_train , y_val = x [: split_at ], x [ split_at :], y [: split_at ], y [ split_at :] print ( 'Training Data shape:' ) print ( 'X : ' , x_train . shape ) print ( 'Y : ' , y_train . shape ) print ( 'Sample Question(in encoded form) : ' , x_train [ 0 ], y_train [ 0 ]) print ( 'Sample Question(in decoded form) : ' , ctable . decode ( x_train [ 0 ]), 'Sample Output : ' , ctable . decode ( y_train [ 0 ])) Let's learn two wrapper functions in Keras - TimeDistributed and RepeatVector with some dummy examples. TimeDistributed is a wrapper function call that applies an input operation on all the timesteps of an input data. For instance I have a feedforward network which converts a 10-dim vector to a 5-dim vector, then wrapping this timedistributed layer on that feedforward operation would convert a batch_size * sentence_len * vector_len(=10) to batch_size * sentence_len * output_len(=5) In [ ]: model = Sequential () #Inputs to it will be batch_size*time_steps*input_vector_dim(to Dense) . Output will be batch_size*time_steps* output_vector_dim #Here dense converts a 5-dim input vector to a 8-dim vector. model . add ( TimeDistributed ( Dense ( 8 ), input_shape = ( 3 , 5 ))) input_array = np . random . randint ( 10 , size = ( 1 , 3 , 5 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( \"Shape of output : \" , output_array . shape ) RepeatVector repeats the vector a specified number of times. Dimension changes from batch_size number of elements to batch_size number of repetitions * number of elements. In [ ]: model = Sequential () #converts from 1*10 to 1 * 6 model . add ( Dense ( 6 , input_dim = 10 )) print ( model . output_shape ) #converts from 1*6 to 1*3*6 model . add ( RepeatVector ( 3 )) print ( model . output_shape ) input_array = np . random . randint ( 1000 , size = ( 1 , 10 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) print ( \"Shape of output : \" , output_array . shape ) # note: `None` is the batch dimension print ( 'Input : ' , input_array [ 0 ]) print ( 'Output : ' , output_array [ 0 ]) MODEL ARCHITECTURE Note : Whenever you are initializing a LSTM in Keras, by the default the option return_sequences = False. This means that at the end of the step the next component will only get to see the final hidden layer's values. On the other hand, if you set return_sequences = True, the LSTM component will return the hidden layer at each time step. It means that the next component should be able to consume inputs in that form. Think how this statement is relevant in terms of this model architecture and the TimeDistributed module we just learned. Build an encoder and decoder both single layer 128 nodes and an appropriate dense layer as needed by the model. In [ ]: #### YOUR CODE HERE #### Let's check how well our model trained. In [ ]: for iteration in range ( 1 , 2 ): print () model . fit ( x_train , y_train , batch_size = BATCH_SIZE , epochs = 20 , validation_data = ( x_val , y_val )) # Select 10 samples from the validation set at random so we can visualize # errors. print ( 'Finished iteration ' , iteration ) numcorrect = 0 numtotal = 20 for i in range ( numtotal ): ind = np . random . randint ( 0 , len ( x_val )) rowx , rowy = x_val [ np . array ([ ind ])], y_val [ np . array ([ ind ])] preds = model . predict_classes ( rowx , verbose = 0 ) q = ctable . decode ( rowx [ 0 ]) correct = ctable . decode ( rowy [ 0 ]) guess = ctable . decode ( preds [ 0 ], calc_argmax = False ) print ( 'Question' , q , end = ' ' ) print ( 'True' , correct , end = ' ' ) print ( 'Guess' , guess , end = ' ' ) if guess == correct : print ( 'Good job' ) numcorrect += 1 else : print ( 'Fail' ) print ( 'The model scored ' , numcorrect * 100 / numtotal , ' % i n its test.' ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab6/students/"},{"title":"Lab 7: Clustering","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 7 - Clustering Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler % matplotlib inline In [3]: import rpy2 import os os . environ [ 'R_HOME' ] = \"/usr/share/anaconda3/lib/R\" from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) In [4]: #If there are errors about missing R packages, run the relevant code below: #r_utils.install_packages('aplpack') # r_utils.install_packages('TeachingDemos') # r_utils.install_packages('ggplot2') # r_utils.install_packages('cluster') # r_utils.install_packages('factoextra') # r_utils.install_packages('dbscan') # # #If you need to install ggplot2 version 2.2.1, then run the following code: # r_utils.install_packages(\"devtools\") # r_remotes = importr(\"remotes\") # r_remotes.install_version(\"ggplot2\",version=\"2.2.1\") Import and plot the data We begin, as always, by importing and exploring the data. Here, we're exploring the crazy cluster data from the end of yesterday's lecture. As you know, by the end we'll have an essentially automated method for extracting the pattern in these data. Python In [5]: multishapes = pd . read_csv ( \"data/multishapes.csv\" ) scaled_df = multishapes [[ 'x' , 'y' ]] scaled_df . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y count 1100.000000 1100.000000 mean -0.081222 -0.625431 std 0.644967 1.176170 min -1.489180 -3.353462 25% -0.478839 -1.126752 50% -0.132920 -0.297040 75% 0.366072 0.250817 max 1.492208 1.253874 In [6]: scaled_df . plot . scatter ( x = 'x' , y = 'y' , c = 'Black' , title = \"Multishapes data\" , figsize = ( 11 , 8.5 )); R We'll work in parallel in R, as some later function work better in that language. In [7]: from rpy2.robjects import pandas2ri pandas2ri . activate () r_scaled_df = pandas2ri . py2ri ( scaled_df ) There is an 'automatic' function in rpy2 to convert a pnadas data frame into an R object. However, this function isn't included in the package's documentation, so use it at your own risk. The old style of building data frames will always work. In [8]: r_scaled_df = rpy2 . robjects . DataFrame ({ \"x\" : rpy2 . robjects . FloatVector ( scaled_df [ 'x' ]), \"y\" : rpy2 . robjects . FloatVector ( scaled_df [ 'y' ]) }) r_scaled_df Out[8]: R/rpy2 DataFrame (1100 x 2) x y -0.803739 -0.853053 0.852851 0.367618 0.927180 -0.274902 -0.752626 -0.511565 ... ... 0.930758 -2.366531 0.989555 -2.475225 0.979200 -2.637578 1.121931 -2.619054 Discussion Above, we named a data frame 'scaled', but didn't actually scale it! When we're clustering should we scale or not? Kmeans We kick things off with the old workhorse of clustering: KMeans. The \"who cares, it runs\" code is below, but first a small conceptual digression on how/why Kmeans does[n't] work: http://web.stanford.edu/class/ee103/visualizations/kmeans/kmeans.html Lessons: Initializations matter; run multiple times Total Squared dsitance should never get worse during an update KMeans can struggle with clusters that are close together; they can get lumped into one There's no notion of 'not part of any cluster' or 'part of two clusters' Python In [9]: from sklearn.cluster import KMeans fitted_km = KMeans ( n_clusters = 5 , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) display ( fitted_km . cluster_centers_ ) display ( fitted_km . labels_ [ 0 : 10 ]) array([[-0.35981394, -0.49384068], [-0.71581926, -2.48493748], [ 0.97688793, -2.38945886], [-0.28306103, 0.5234012 ], [ 0.58969517, -0.07953374]]) array([0, 4, 4, 0, 4, 4, 3, 0, 0, 0], dtype=int32) Above, we see two useful components of the kmeans fit: the coordinates of the 5 cluster centers, and the clusters assigned to (the first few) points of data R In R, Kmeans is part of the 'stats' library, so we first importr 'stats', then call the .kmeans function within that grouping. As always, we refer to R's documentation to figure out the name of the function and its arguments. Link to the documentation We also set R's random number generator, which allows us to get exatcly reproducible results. In [10]: r_base = importr ( 'base' ) r_base . set_seed ( 109 ) #set seed for random number generation r_stats = importr ( 'stats' ) r_km_out = r_stats . kmeans ( scaled_df , 5 , nstart = 5 ) display ( r_km_out ) display ( list ( r_km_out . names )) display ( r_km_out . rx2 ( \"size\" )) ListVector with 9 elements. cluster IntVector with 1100 elements. 4 3 3 4 ... 2 2 2 2 centers Matrix with 10 elements. -0.275288 0.976888 0.590826 -0.361774 ... -2.389459 -0.084235 -0.491818 -2.484937 totss FloatVector with 1 elements. 1977.496339 ... ... size IntVector with 5 elements. 261 60 294 275 210 iter IntVector with 1 elements. 3 ifault IntVector with 1 elements. 0 ['cluster', 'centers', 'totss', 'withinss', 'tot.withinss', 'betweenss', 'size', 'iter', 'ifault'] IntVector with 5 elements. 261 60 294 275 210 Recall that R functions typically return something between a named list and a dictionary. You can display it directly, and access particular segments via .rx2() Plotting Python As of 2019, python doesn't have many specialized plotting methods, you mostly have to do it yourself. Take note of matplotlib's c= argument to color items in a plot, and stacking two different plotting functions in the same cell. In [11]: plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = fitted_km . labels_ ); plt . scatter ( fitted_km . cluster_centers_ [:, 0 ], fitted_km . cluster_centers_ [:, 1 ], c = 'r' , marker = 'h' , s = 100 ); R As before, R is loaded with custom plotting. We're upgrading how we call R for plotting-- once you %load_ext rpy2.ipython (once per notebook, like %matplotlib inline ) use %R to run a single line of R code, or %%R to run a whole cell of R code. Transfer R objects from python to r by adding -i and the object name on the %%R line. Summary: %load_ext rpy2.ipython once %%R when you want to run multiple lines of R code Won't send outputs back into python Will display plots in the notebook Move robject variables to R via -i In [12]: % load_ext rpy2.ipython In [13]: %% R - i r_km_out - i r_scaled_df library ( factoextra ) fviz_cluster ( r_km_out , r_scaled_df , geom = \"point\" ) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Loading required package: ggplot2 warnings.warn(x, RRuntimeWarning) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Welcome! Related Books: `Practical Guide To Cluster Analysis in R` at https://goo.gl/13EFCZ warnings.warn(x, RRuntimeWarning) Selecting size: Elbow This method measures the total (squared) distance from points to their cluster's centroid. Within a given cluster, this is equivalent , up to a factor of $2n$, to the summed (squared) distance from each point to the other points in the cluster (the phrasing we use in laer methods). Look for the place(s) where distance stops decreasing as much. Python In [14]: wss = [] for i in range ( 1 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) wss . append ( fitx . inertia_ ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), wss , 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Inertia' ) plt . title ( 'The Elbow Method showing the optimal $k$' ) plt . show () R Nearly all of our plots in R today come from the handy library factoextra (and nearly all of our plots will be from the fviz_clust function). Becuase we ran library(factoextra) in R earlier, the library is still loaded and we can invoke fviz_clust directly. Also, the -i is optional: R remembers what r_scaled_df is from before, but it can be wise to always send over the latest version. Summary: R remembers things you've loaded, saved, or passed it before, just like variables persist across cells in jupyter library(factoextra) and then fviz_nbclust is your main plotting tool Remember to set nstart= above its default of 1 whenever you use Kmeans in R Documentation here In [15]: %% R - i r_scaled_df fviz_nbclust ( r_scaled_df , kmeans , method = \"wss\" , nstart = 5 ) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Selecting size: Silhouette Silhouette scores measure how close an observation is (on average) to points in its cluster, compared to the next-closest cluster's points. The range is [-1,1]; 0 indicates a point on the decision boundary (equal average closeness to points in both clusters), and negative values mean that datum might be better in a different cluster. The silhouette score plotted below is the average of the above score across all points. Python The silhouette score is a metric available in sklearn. We have to manually loop over values of K, calculate, and plot. In [16]: from sklearn.metrics import silhouette_score scores = [ 0 ] for i in range ( 2 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) score = silhouette_score ( scaled_df , fitx . labels_ ) scores . append ( score ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), np . array ( scores ), 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Average Silhouette' ) plt . title ( 'The Elbow Method showing the optimal $k$' ) plt . show () R Again, fviz_clust will do the work, we just need to pass it a different method= . In [17]: %% R - i r_scaled_df fviz_nbclust ( r_scaled_df , kmeans , method = \"silhouette\" , nstart = 5 ) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Selecting size: Gap Statistic The gap statistic compares within-cluster distances (like in silhouette), but instead of comparing against the second-best existing cluster for that point, it compares our clustering's overall average to average we'd see when data don't have clusters at all. In essence, the within-cluster distances (in the elbow plot) will go down just becuse we have more clusters. We additionally calculate how much they'd go down on non-clustered data with the same spread as our data and subtract that trend out to produce the plot below. Python Again, we'd have to code it up ourselves. Though there are some implementations online, they're not ready for immediate use. In [18]: # you'd have to implement it yourself R And again, fviz_clust will do the work, we just need to pass it a different method= . In [19]: %% R - i r_scaled_df fviz_nbclust ( r_scaled_df , kmeans , method = \"gap\" , nstart = 5 ) Clustering k = 1,2,..., K.max (= 10): .. done Bootstrapping, b = 1,2,..., B (= 100) [one \".\" per sample]: .................................................. 50 .................................................. 100 Exercise 1 Determine the optimal number of clusters Re-fit a KNN model with that number of clusters In [20]: #your code here. In [21]: better_km = KMeans ( n_clusters = 2 , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) In [22]: plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = better_km . labels_ ); plt . scatter ( better_km . cluster_centers_ [:, 0 ], better_km . cluster_centers_ [:, 1 ]); #TODO: higlight the centers Asessing Fit: Silhouette Python Below, we borrow from an SKlearn example. The second plot may be overkill. The second plot is JUST the first two dimensions in the data. It is not a PCA plot If you only need the raw silhouette scores, use the silhouette_samples function In [23]: from sklearn.metrics import silhouette_samples , silhouette_score import matplotlib.cm as cm #modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html def silplot ( X , clusterer , pointlabels = None ): cluster_labels = clusterer . labels_ n_clusters = clusterer . n_clusters # Create a subplot with 1 row and 2 columns fig , ( ax1 , ax2 ) = plt . subplots ( 1 , 2 ) fig . set_size_inches ( 11 , 8.5 ) # The 1st subplot is the silhouette plot # The silhouette coefficient can range from -1, 1 but in this example all # lie within [-0.1, 1] ax1 . set_xlim ([ - 0.1 , 1 ]) # The (n_clusters+1)*10 is for inserting blank space between silhouette # plots of individual clusters, to demarcate them clearly. ax1 . set_ylim ([ 0 , len ( X ) + ( n_clusters + 1 ) * 10 ]) # The silhouette_score gives the average value for all the samples. # This gives a perspective into the density and separation of the formed # clusters silhouette_avg = silhouette_score ( X , cluster_labels ) print ( \"For n_clusters = \" , n_clusters , \", the average silhouette_score is \" , silhouette_avg , \".\" , sep = \"\" ) # Compute the silhouette scores for each sample sample_silhouette_values = silhouette_samples ( X , cluster_labels ) y_lower = 10 for i in range ( 0 , n_clusters + 1 ): # Aggregate the silhouette scores for samples belonging to # cluster i, and sort them ith_cluster_silhouette_values = \\ sample_silhouette_values [ cluster_labels == i ] ith_cluster_silhouette_values . sort () size_cluster_i = ith_cluster_silhouette_values . shape [ 0 ] y_upper = y_lower + size_cluster_i color = cm . nipy_spectral ( float ( i ) / n_clusters ) ax1 . fill_betweenx ( np . arange ( y_lower , y_upper ), 0 , ith_cluster_silhouette_values , facecolor = color , edgecolor = color , alpha = 0.7 ) # Label the silhouette plots with their cluster numbers at the middle ax1 . text ( - 0.05 , y_lower + 0.5 * size_cluster_i , str ( i )) # Compute the new y_lower for next plot y_lower = y_upper + 10 # 10 for the 0 samples ax1 . set_title ( \"The silhouette plot for the various clusters.\" ) ax1 . set_xlabel ( \"The silhouette coefficient values\" ) ax1 . set_ylabel ( \"Cluster label\" ) # The vertical line for average silhouette score of all the values ax1 . axvline ( x = silhouette_avg , color = \"red\" , linestyle = \"--\" ) ax1 . set_yticks ([]) # Clear the yaxis labels / ticks ax1 . set_xticks ([ - 0.1 , 0 , 0.2 , 0.4 , 0.6 , 0.8 , 1 ]) # 2nd Plot showing the actual clusters formed colors = cm . nipy_spectral ( cluster_labels . astype ( float ) / n_clusters ) ax2 . scatter ( X [:, 0 ], X [:, 1 ], marker = '.' , s = 200 , lw = 0 , alpha = 0.7 , c = colors , edgecolor = 'k' ) xs = X [:, 0 ] ys = X [:, 1 ] if pointlabels is not None : for i in range ( len ( xs )): plt . text ( xs [ i ], ys [ i ], pointlabels [ i ]) # Labeling the clusters centers = clusterer . cluster_centers_ # Draw white circles at cluster centers ax2 . scatter ( centers [:, 0 ], centers [:, 1 ], marker = 'o' , c = \"white\" , alpha = 1 , s = 200 , edgecolor = 'k' ) for i , c in enumerate ( centers ): ax2 . scatter ( c [ 0 ], c [ 1 ], marker = '$ %d $' % int ( i ), alpha = 1 , s = 50 , edgecolor = 'k' ) ax2 . set_title ( \"The visualization of the clustered data.\" ) ax2 . set_xlabel ( \"Feature space for the 1st feature\" ) ax2 . set_ylabel ( \"Feature space for the 2nd feature\" ) plt . suptitle (( \"Silhouette analysis for KMeans clustering on sample data \" \"with n_clusters = %d \" % n_clusters ), fontsize = 14 , fontweight = 'bold' ) In [24]: silplot ( scaled_df . values , fitted_km ) For n_clusters = 5, the average silhouette_score is 0.41118597712860394. R To get the plot in R, we need to jump through a few hoops import the cluster library (once) call the silhouette function on cluster assignments and the inter-point distances call fviz_silhouette on the result Luckily, we can run multiple lines of R at a time In [25]: %% R - i r_km_out - i r_scaled_df library ( cluster ) sil = silhouette ( r_km_out $ cluster , dist ( r_scaled_df )) fviz_silhouette ( sil ) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) cluster size ave.sil.width 1 1 261 0.38 2 2 60 0.77 3 3 294 0.36 4 4 275 0.37 5 5 210 0.47 Exercise 2 Display the silhouette plots for your own model Discussion How do we know which of two silhouette plots is better? In [26]: silplot ( scaled_df . values , better_km ); For n_clusters = 2, the average silhouette_score is 0.5977026979462612. Algomerative Aglomerative clustering merges clusters together from the bottom up. There are many possible rules about which cluster(s) to combine next. Ward's rule wants to have the lowest possible total within-cluster distance, so it merges the two clusters that will harm this objective least. Python Scipy has Ward's method implemented, though the call sequence is a little convoluted, and the code is slow. In [27]: import scipy.cluster.hierarchy as hac from scipy.spatial.distance import pdist plt . figure ( figsize = ( 11 , 8.5 )) dist_mat = pdist ( scaled_df , metric = \"euclidean\" ) ward_data = hac . ward ( dist_mat ) hac . dendrogram ( ward_data ); R R's code runs much faster, and the code is cleaner. Note that hclust is from the cluster library and you'd need to import it if you haven't already. In [28]: %% R - i r_scaled_df stacked_cluster = hclust ( dist ( r_scaled_df ), method = \"ward.D\" ) plot ( stacked_cluster ) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Discussion How do you read a plot like the above? What are valid options for number of clusters, and how can you tell? Are some more valid than others? DBscan DBscan is one of many alternative clustering algorithms, that uses an intuitive notion of denseness to define clusters, rather than defining them by a central point as in Kmeans. Python DBscan is implemented in good 'ol sklearn, but there aren't great tools for working out the epsilon parameter. In [29]: # I couldn't find any easy code for epsilon-tuning plot In [30]: from sklearn.cluster import DBSCAN fitted_dbscan = DBSCAN ( eps = 0.15 ) . fit ( scaled_df ) plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = fitted_dbscan . labels_ ); R R's dbscan is in the dbscan library. It comes with kNNdistplot for tuning epsilon, and fviz_cluster will make a nice plot. In [31]: %% R - i r_scaled_df library ( dbscan ) kNNdistplot ( r_scaled_df , k = 5 ) /usr/share/anaconda3/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Remember, we can import and run functions like dbscan within Python In [32]: r_dbscan = importr ( \"dbscan\" ) r_db_out = r_dbscan . dbscan ( r_scaled_df , eps = 0.15 , minPts = 5 ) Or run directly in R In [33]: %% R - i r_scaled_df r_db_out = dbscan ( r_scaled_df , eps = 0.15 , minPts = 5 ) fviz_cluster ( r_db_out , r_scaled_df , ellipse = FALSE , geom = \"point\" ) Exercise 3 Use cross validation to select the optimal values of N and epsilon Discussion Or don't Streching: The arrest data and guided practice In this section you get to transfer the skills and code we learned above to new data. Because of how much this resembles your individual HW, we'll go over the solutions in lab, but not post them in writing. As always, we start by loading and exploring the data In [35]: arrest_data = pd . read_csv ( \"data/USArrests.csv\" ) arrest_data [ 'A' ] = arrest_data [ 'A' ] . astype ( 'float64' ) arrest_data [ 'UrbanPop' ] = arrest_data [ 'UrbanPop' ] . astype ( 'float64' ) arrest_data . head () Out[35]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } State M A UrbanPop R 0 Alabama 13.2 236.0 58.0 21.2 1 Alaska 10.0 263.0 48.0 44.5 2 Arizona 8.1 294.0 80.0 31.0 3 Arkansas 8.8 190.0 50.0 19.5 4 California 9.0 276.0 91.0 40.6 Exercise Scale the data Discussion Or don't Exercise Convert the pandas dataframe to R Exercise How many [KMeans] clusters do the 50 states fall into? Remember: we've seen three different methods for determining number of clusters Exercise Fit a k-means cclustering with the number of clusters you think is best Exercise How good is your clustering? Exercise Run an aglomerative clustering. What's the benefit of this method? How many clusters does it suggest? Exercise Run dbscan on this data. Remember to tune epsilon. How well does it perform? Discussion How did you synthsize the different suggestions for number of clusters? What method, and what clustering seems correct? Why is clustering useful? Bonus: A Hint About Why Clustering The States Is Hard In [48]: pca = PCA () pca_df = pca . fit_transform ( scaled_df ) In [49]: def biplot ( scaled_data , fitted_pca , axis_labels , point_labels ): pca_results = fitted_pca . transform ( scaled_data ) pca1_scores = pca_results [:, 0 ] pca2_scores = pca_results [:, 1 ] # plot each point in 2D post-PCA space plt . scatter ( pca1_scores , pca2_scores ) # label each point for i in range ( len ( pca1_scores )): plt . text ( pca1_scores [ i ], pca2_scores [ i ], point_labels [ i ]) #for each original dimension, plot what an increase of 1 in that dimension means in this space for i in range ( fitted_pca . components_ . shape [ 1 ]): raw_dims_delta_on_pca1 = fitted_pca . components_ [ 0 , i ] raw_dims_delta_on_pca2 = fitted_pca . components_ [ 1 , i ] plt . arrow ( 0 , 0 , raw_dims_delta_on_pca1 , raw_dims_delta_on_pca2 , color = 'r' , alpha = 1 ) plt . text ( raw_dims_delta_on_pca1 * 1.1 , raw_dims_delta_on_pca2 * 1.1 , axis_labels [ i ], color = 'g' , ha = 'center' , va = 'center' ) plt . figure ( figsize = ( 11 , 8.5 )) plt . xlim ( - 3.5 , 3.5 ) plt . ylim ( - 3.5 , 3.5 ) plt . xlabel ( \"PC {} \" . format ( 1 )) plt . ylabel ( \"PC {} \" . format ( 2 )) plt . grid () biplot ( scaled_df , pca , axis_labels = scaled_df . columns , point_labels = arrest_data [ 'State' ]) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab7/solutions/"},{"title":"Lab 7: Clustering","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 7 - Clustering Harvard University Spring 2019 Instructors : Mark Glickman and Pavlos Protopapas In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In [2]: import numpy as np import pandas as pd import matplotlib.pyplot as plt from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler % matplotlib inline In [3]: import rpy2 # import os # os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) In [4]: #If there are errors about missing R packages, run the relevant code below: #r_utils.install_packages('aplpack') # r_utils.install_packages('TeachingDemos') # r_utils.install_packages('ggplot2') # r_utils.install_packages('cluster') # r_utils.install_packages('factoextra') # r_utils.install_packages('dbscan') # # #If you need to install ggplot2 version 2.2.1, then run the following code: # r_utils.install_packages(\"devtools\") # r_remotes = importr(\"remotes\") # r_remotes.install_version(\"ggplot2\",version=\"2.2.1\") Import and plot the data We begin, as always, by importing and exploring the data. Here, we're exploring the crazy cluster data from the end of yesterday's lecture. As you know, by the end we'll have an essentially automated method for extracting the pattern in these data. Python In [5]: multishapes = pd . read_csv ( \"data/multishapes.csv\" ) scaled_df = multishapes [[ 'x' , 'y' ]] scaled_df . describe () Out[5]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } x y count 1100.000000 1100.000000 mean -0.081222 -0.625431 std 0.644967 1.176170 min -1.489180 -3.353462 25% -0.478839 -1.126752 50% -0.132920 -0.297040 75% 0.366072 0.250817 max 1.492208 1.253874 In [6]: scaled_df . plot . scatter ( x = 'x' , y = 'y' , c = 'Black' , title = \"Multishapes data\" , figsize = ( 11 , 8.5 )); R We'll work in parallel in R, as some later function work better in that language. In [7]: from rpy2.robjects import pandas2ri pandas2ri . activate () r_scaled_df = pandas2ri . py2ri ( scaled_df ) There is an 'automatic' function in rpy2 to convert a pnadas data frame into an R object. However, this function isn't included in the package's documentation, so use it at your own risk. The old style of building data frames will always work. In [8]: r_scaled_df = rpy2 . robjects . DataFrame ({ \"x\" : rpy2 . robjects . FloatVector ( scaled_df [ 'x' ]), \"y\" : rpy2 . robjects . FloatVector ( scaled_df [ 'y' ]) }) r_scaled_df Out[8]: R/rpy2 DataFrame (1100 x 2) x y -0.803739 -0.853053 0.852851 0.367618 0.927180 -0.274902 -0.752626 -0.511565 ... ... 0.930758 -2.366531 0.989555 -2.475225 0.979200 -2.637578 1.121931 -2.619054 Discussion Above, we named a data frame 'scaled', but didn't actually scale it! When we're clustering should we scale or not? Kmeans We kick things off with the old workhorse of clustering: KMeans. The \"who cares, it runs\" code is below, but first a small conceptual digression on how/why Kmeans does[n't] work: http://web.stanford.edu/class/ee103/visualizations/kmeans/kmeans.html Lessons: Initializations matter; run multiple times Total Squared dsitance should never get worse during an update KMeans can struggle with clusters that are close together; they can get lumped into one There's no notion of 'not part of any cluster' or 'part of two clusters' Python In [9]: from sklearn.cluster import KMeans fitted_km = KMeans ( n_clusters = 5 , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) display ( fitted_km . cluster_centers_ ) display ( fitted_km . labels_ [ 0 : 10 ]) array([[-0.35981394, -0.49384068], [-0.71581926, -2.48493748], [ 0.97688793, -2.38945886], [-0.28306103, 0.5234012 ], [ 0.58969517, -0.07953374]]) array([0, 4, 4, 0, 4, 4, 3, 0, 0, 0]) Above, we see two useful components of the kmeans fit: the coordinates of the 5 cluster centers, and the clusters assigned to (the first few) points of data R In R, Kmeans is part of the 'stats' library, so we first importr 'stats', then call the .kmeans function within that grouping. As always, we refer to R's documentation to figure out the name of the function and its arguments. Link to the documentation We also set R's random number generator, which allows us to get exatcly reproducible results. In [10]: r_base = importr ( 'base' ) r_base . set_seed ( 109 ) #set seed for random number generation r_stats = importr ( 'stats' ) r_km_out = r_stats . kmeans ( scaled_df , 5 , nstart = 5 ) display ( r_km_out ) display ( list ( r_km_out . names )) display ( r_km_out . rx2 ( \"size\" )) ListVector with 9 elements. cluster IntVector with 1100 elements. 4 3 3 4 ... 2 2 2 2 centers Matrix with 10 elements. -0.275288 0.976888 0.590826 -0.361774 ... -2.389459 -0.084235 -0.491818 -2.484937 totss FloatVector with 1 elements. 1977.496339 ... ... size IntVector with 5 elements. 261 60 294 275 210 iter IntVector with 1 elements. 3 ifault IntVector with 1 elements. 0 ['cluster', 'centers', 'totss', 'withinss', 'tot.withinss', 'betweenss', 'size', 'iter', 'ifault'] IntVector with 5 elements. 261 60 294 275 210 Recall that R functions typically return something between a named list and a dictionary. You can display it directly, and access particular segments via .rx2() Plotting Python As of 2019, python doesn't have many specialized plotting methods, you mostly have to do it yourself. Take note of matplotlib's c= argument to color items in a plot, and stacking two different plotting functions in the same cell. In [11]: plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = fitted_km . labels_ ); plt . scatter ( fitted_km . cluster_centers_ [:, 0 ], fitted_km . cluster_centers_ [:, 1 ], c = 'r' , marker = 'h' , s = 100 ); R As before, R is loaded with custom plotting. We're upgrading how we call R for plotting-- once you %load_ext rpy2.ipython (once per notebook, like %matplotlib inline ) use %R to run a single line of R code, or %%R to run a whole cell of R code. Transfer R objects from python to r by adding -i and the object name on the %%R line. Summary: %load_ext rpy2.ipython once %%R when you want to run multiple lines of R code Won't send outputs back into python Will display plots in the notebook Move robject variables to R via -i In [12]: % load_ext rpy2.ipython In [13]: %% R - i r_km_out - i r_scaled_df library ( factoextra ) fviz_cluster ( r_km_out , r_scaled_df , geom = \"point\" ) C:\\Users\\Will\\Anaconda3\\envs\\109b\\lib\\site-packages\\rpy2-2.9.4-py3.6-win-amd64.egg\\rpy2\\robjects\\pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Selecting size: Elbow This method measures the total (squared) distance from points to their cluster's centroid. Within a given cluster, this is equivalent , up to a factor of $2n$, to the summed (squared) distance from each point to the other points in the cluster (the phrasing we use in laer methods). Look for the place(s) where distance stops decreasing as much. Python In [14]: wss = [] for i in range ( 1 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) wss . append ( fitx . inertia_ ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), wss , 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Inertia' ) plt . title ( 'The Elbow Method showing the optimal $k$' ) plt . show () R Nearly all of our plots in R today come from the handy library factoextra (and nearly all of our plots will be from the fviz_clust function). Becuase we ran library(factoextra) in R earlier, the library is still loaded and we can invoke fviz_clust directly. Also, the -i is optional: R remembers what r_scaled_df is from before, but it can be wise to always send over the latest version. Summary: R remembers things you've loaded, saved, or passed it before, just like variables persist across cells in jupyter library(factoextra) and then fviz_nbclust is your main plotting tool Remember to set nstart= above its default of 1 whenever you use Kmeans in R Documentation here In [15]: %% R - i r_scaled_df fviz_nbclust ( r_scaled_df , kmeans , method = \"wss\" , nstart = 5 ) C:\\Users\\Will\\Anaconda3\\envs\\109b\\lib\\site-packages\\rpy2-2.9.4-py3.6-win-amd64.egg\\rpy2\\robjects\\pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Selecting size: Silhouette Silhouette scores measure how close an observation is (on average) to points in its cluster, compared to the next-closest cluster's points. The range is [-1,1]; 0 indicates a point on the decision boundary (equal average closeness to points in both clusters), and negative values mean that datum might be better in a different cluster. The silhouette score plotted below is the average of the above score across all points. Python The silhouette score is a metric available in sklearn. We have to manually loop over values of K, calculate, and plot. In [16]: from sklearn.metrics import silhouette_score scores = [ 0 ] for i in range ( 2 , 11 ): fitx = KMeans ( n_clusters = i , init = 'random' , n_init = 5 , random_state = 109 ) . fit ( scaled_df ) score = silhouette_score ( scaled_df , fitx . labels_ ) scores . append ( score ) plt . figure ( figsize = ( 11 , 8.5 )) plt . plot ( range ( 1 , 11 ), np . array ( scores ), 'bx-' ) plt . xlabel ( 'Number of clusters $k$' ) plt . ylabel ( 'Average Silhouette' ) plt . title ( 'The Elbow Method showing the optimal $k$' ) plt . show () R Again, fviz_clust will do the work, we just need to pass it a different method= . In [17]: %% R - i r_scaled_df fviz_nbclust ( r_scaled_df , kmeans , method = \"silhouette\" , nstart = 5 ) C:\\Users\\Will\\Anaconda3\\envs\\109b\\lib\\site-packages\\rpy2-2.9.4-py3.6-win-amd64.egg\\rpy2\\robjects\\pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Selecting size: Gap Statistic The gap statistic compares within-cluster distances (like in silhouette), but instead of comparing against the second-best existing cluster for that point, it compares our clustering's overall average to average we'd see when data don't have clusters at all. In essence, the within-cluster distances (in the elbow plot) will go down just becuse we have more clusters. We additionally calculate how much they'd go down on non-clustered data with the same spread as our data and subtract that trend out to produce the plot below. Python Again, we'd have to code it up ourselves. Though there are some implementations online, they're not ready for immediate use. In [18]: # you'd have to implement it yourself R And again, fviz_clust will do the work, we just need to pass it a different method= . In [19]: %% R - i r_scaled_df fviz_nbclust ( r_scaled_df , kmeans , method = \"gap\" , nstart = 5 ) Exercise 1 Determine the optimal number of clusters Re-fit a KNN model with that number of clusters In [20]: #your code here. Asessing Fit: Silhouette Python Below, we borrow from an SKlearn example. The second plot may be overkill. The second plot is JUST the first two dimensions in the data. It is not a PCA plot If you only need the raw silhouette scores, use the silhouette_samples function In [21]: from sklearn.metrics import silhouette_samples , silhouette_score import matplotlib.cm as cm #modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html def silplot ( X , clusterer , pointlabels = None ): cluster_labels = clusterer . labels_ n_clusters = clusterer . n_clusters # Create a subplot with 1 row and 2 columns fig , ( ax1 , ax2 ) = plt . subplots ( 1 , 2 ) fig . set_size_inches ( 11 , 8.5 ) # The 1st subplot is the silhouette plot # The silhouette coefficient can range from -1, 1 but in this example all # lie within [-0.1, 1] ax1 . set_xlim ([ - 0.1 , 1 ]) # The (n_clusters+1)*10 is for inserting blank space between silhouette # plots of individual clusters, to demarcate them clearly. ax1 . set_ylim ([ 0 , len ( X ) + ( n_clusters + 1 ) * 10 ]) # The silhouette_score gives the average value for all the samples. # This gives a perspective into the density and separation of the formed # clusters silhouette_avg = silhouette_score ( X , cluster_labels ) print ( \"For n_clusters = \" , n_clusters , \", the average silhouette_score is \" , silhouette_avg , \".\" , sep = \"\" ) # Compute the silhouette scores for each sample sample_silhouette_values = silhouette_samples ( X , cluster_labels ) y_lower = 10 for i in range ( 0 , n_clusters + 1 ): # Aggregate the silhouette scores for samples belonging to # cluster i, and sort them ith_cluster_silhouette_values = \\ sample_silhouette_values [ cluster_labels == i ] ith_cluster_silhouette_values . sort () size_cluster_i = ith_cluster_silhouette_values . shape [ 0 ] y_upper = y_lower + size_cluster_i color = cm . nipy_spectral ( float ( i ) / n_clusters ) ax1 . fill_betweenx ( np . arange ( y_lower , y_upper ), 0 , ith_cluster_silhouette_values , facecolor = color , edgecolor = color , alpha = 0.7 ) # Label the silhouette plots with their cluster numbers at the middle ax1 . text ( - 0.05 , y_lower + 0.5 * size_cluster_i , str ( i )) # Compute the new y_lower for next plot y_lower = y_upper + 10 # 10 for the 0 samples ax1 . set_title ( \"The silhouette plot for the various clusters.\" ) ax1 . set_xlabel ( \"The silhouette coefficient values\" ) ax1 . set_ylabel ( \"Cluster label\" ) # The vertical line for average silhouette score of all the values ax1 . axvline ( x = silhouette_avg , color = \"red\" , linestyle = \"--\" ) ax1 . set_yticks ([]) # Clear the yaxis labels / ticks ax1 . set_xticks ([ - 0.1 , 0 , 0.2 , 0.4 , 0.6 , 0.8 , 1 ]) # 2nd Plot showing the actual clusters formed colors = cm . nipy_spectral ( cluster_labels . astype ( float ) / n_clusters ) ax2 . scatter ( X [:, 0 ], X [:, 1 ], marker = '.' , s = 200 , lw = 0 , alpha = 0.7 , c = colors , edgecolor = 'k' ) xs = X [:, 0 ] ys = X [:, 1 ] if pointlabels is not None : for i in range ( len ( xs )): plt . text ( xs [ i ], ys [ i ], pointlabels [ i ]) # Labeling the clusters centers = clusterer . cluster_centers_ # Draw white circles at cluster centers ax2 . scatter ( centers [:, 0 ], centers [:, 1 ], marker = 'o' , c = \"white\" , alpha = 1 , s = 200 , edgecolor = 'k' ) for i , c in enumerate ( centers ): ax2 . scatter ( c [ 0 ], c [ 1 ], marker = '$ %d $' % int ( i ), alpha = 1 , s = 50 , edgecolor = 'k' ) ax2 . set_title ( \"The visualization of the clustered data.\" ) ax2 . set_xlabel ( \"Feature space for the 1st feature\" ) ax2 . set_ylabel ( \"Feature space for the 2nd feature\" ) plt . suptitle (( \"Silhouette analysis for KMeans clustering on sample data \" \"with n_clusters = %d \" % n_clusters ), fontsize = 14 , fontweight = 'bold' ) In [22]: silplot ( scaled_df . values , fitted_km ) For n_clusters = 5, the average silhouette_score is 0.41118597712860394. R To get the plot in R, we need to jump through a few hoops import the cluster library (once) call the silhouette function on cluster assignments and the inter-point distances call fviz_silhouette on the result Luckily, we can run multiple lines of R at a time In [23]: %% R - i r_km_out - i r_scaled_df library ( cluster ) sil = silhouette ( r_km_out $ cluster , dist ( r_scaled_df )) fviz_silhouette ( sil ) C:\\Users\\Will\\Anaconda3\\envs\\109b\\lib\\site-packages\\rpy2-2.9.4-py3.6-win-amd64.egg\\rpy2\\robjects\\pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Exercise 2 Display the silhouette plots for your own model Discussion How do we know which of two silhouette plots is better? In [24]: #your code here Algomerative Aglomerative clustering merges clusters together from the bottom up. There are many possible rules about which cluster(s) to combine next. Ward's rule wants to have the lowest possible total within-cluster distance, so it merges the two clusters that will harm this objective least. Python Scipy has Ward's method implemented, though the call sequence is a little convoluted, and the code is slow. In [25]: import scipy.cluster.hierarchy as hac from scipy.spatial.distance import pdist plt . figure ( figsize = ( 11 , 8.5 )) dist_mat = pdist ( scaled_df , metric = \"euclidean\" ) ward_data = hac . ward ( dist_mat ) hac . dendrogram ( ward_data ); R R's code runs much faster, and the code is cleaner. Note that hclust is from the cluster library and you'd need to import it if you haven't already. In [26]: %% R - i r_scaled_df stacked_cluster = hclust ( dist ( r_scaled_df ), method = \"ward.D\" ) plot ( stacked_cluster ) Discussion How do you read a plot like the above? What are valid options for number of clusters, and how can you tell? Are some more valid than others? DBscan DBscan is one of many alternative clustering algorithms, that uses an intuitive notion of denseness to define clusters, rather than defining them by a central point as in Kmeans. Python DBscan is implemented in good 'ol sklearn, but there aren't great tools for working out the epsilon parameter. In [27]: # I couldn't find any easy code for epsilon-tuning plot In [28]: from sklearn.cluster import DBSCAN fitted_dbscan = DBSCAN ( eps = 0.15 ) . fit ( scaled_df ) plt . scatter ( scaled_df [ 'x' ], scaled_df [ 'y' ], c = fitted_dbscan . labels_ ); R R's dbscan is in the dbscan library. It comes with kNNdistplot for tuning epsilon, and fviz_cluster will make a nice plot. In [29]: %% R - i r_scaled_df library ( dbscan ) kNNdistplot ( r_scaled_df , k = 5 ) C:\\Users\\Will\\Anaconda3\\envs\\109b\\lib\\site-packages\\rpy2-2.9.4-py3.6-win-amd64.egg\\rpy2\\robjects\\pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order. res = PandasDataFrame.from_items(items) Remember, we can import and run functions like dbscan within Python In [30]: r_dbscan = importr ( \"dbscan\" ) r_db_out = r_dbscan . dbscan ( r_scaled_df , eps = 0.15 , minPts = 5 ) Or run directly in R In [31]: %% R - i r_scaled_df r_db_out = dbscan ( r_scaled_df , eps = 0.15 , minPts = 5 ) fviz_cluster ( r_db_out , r_scaled_df , ellipse = FALSE , geom = \"point\" ) Exercise 3 Discussion Use cross validation to select the optimal values of N and epsilon In [32]: #your code here? Streching: The arrest data and guided practice In this section you get to transfer the skills and code we learned above to new data. Because of how much this resembles your individual HW, we'll go over the solutions in lab, but not post them in writing. As always, we start by loading and exploring the data In [33]: arrest_data = pd . read_csv ( \"data/USArrests.csv\" ) arrest_data [ 'A' ] = arrest_data [ 'A' ] . astype ( 'float64' ) arrest_data [ 'UrbanPop' ] = arrest_data [ 'UrbanPop' ] . astype ( 'float64' ) arrest_data . head () Out[33]: .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } State M A UrbanPop R 0 Alabama 13.2 236.0 58.0 21.2 1 Alaska 10.0 263.0 48.0 44.5 2 Arizona 8.1 294.0 80.0 31.0 3 Arkansas 8.8 190.0 50.0 19.5 4 California 9.0 276.0 91.0 40.6 Exercise Scale the data Discussion Or don't In [34]: #your code here Exercise Convert the pandas dataframe to R In [35]: #your code here Exercise How many [KMeans] clusters do the 50 states fall into? Remember: we've seen three different methods for determining number of clusters In [36]: #your code here In [37]: #your code here In [38]: #your code here Exercise Fit a k-means cclustering with the number of clusters you think is best In [39]: #your code here Exercise How good is your clustering? In [40]: #your code here Exercise Run an aglomerative clustering. What's the benefit of this method? How many clusters does it suggest? In [41]: #your code here Exercise Run dbscan on this data. Remember to tune epsilon. How well does it perform? In [42]: #your code here Discussion How did you synthsize the different suggestions for number of clusters? What method, and what clustering seems correct? Why is clustering useful? Bonus: A Hint About Why Clustering The States Is Hard In [43]: numeric_cols = [ 'M' , 'A' , 'UrbanPop' , 'R' ] pca = PCA () scaled_df = pd . DataFrame ( StandardScaler () . fit_transform ( arrest_data [ numeric_cols ]), columns = arrest_data [ numeric_cols ] . columns , index = arrest_data . index ) pca_df = pca . fit_transform ( scaled_df ) In [44]: def biplot ( scaled_data , fitted_pca , axis_labels , point_labels ): pca_results = fitted_pca . transform ( scaled_data ) pca1_scores = pca_results [:, 0 ] pca2_scores = pca_results [:, 1 ] # plot each point in 2D post-PCA space plt . scatter ( pca1_scores , pca2_scores ) # label each point for i in range ( len ( pca1_scores )): plt . text ( pca1_scores [ i ], pca2_scores [ i ], point_labels [ i ]) #for each original dimension, plot what an increase of 1 in that dimension means in this space for i in range ( fitted_pca . components_ . shape [ 1 ]): raw_dims_delta_on_pca1 = fitted_pca . components_ [ 0 , i ] raw_dims_delta_on_pca2 = fitted_pca . components_ [ 1 , i ] plt . arrow ( 0 , 0 , raw_dims_delta_on_pca1 , raw_dims_delta_on_pca2 , color = 'r' , alpha = 1 ) plt . text ( raw_dims_delta_on_pca1 * 1.1 , raw_dims_delta_on_pca2 * 1.1 , axis_labels [ i ], color = 'g' , ha = 'center' , va = 'center' ) plt . figure ( figsize = ( 11 , 8.5 )) plt . xlim ( - 3.5 , 3.5 ) plt . ylim ( - 3.5 , 3.5 ) plt . xlabel ( \"PC {} \" . format ( 1 )) plt . ylabel ( \"PC {} \" . format ( 2 )) plt . grid () biplot ( scaled_df , pca , axis_labels = scaled_df . columns , point_labels = arrest_data [ 'State' ]) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab7/students/"},{"title":"Advanced Section 4: RNNs","text":"Slides PDF PPTX Lecture notes PDF","tags":"A-sections","url":"a-sections/a-section4/"},{"title":"Lecture 11: RNN-2","text":"Slides Lecture 11 PDF Lecture 11 PPTX Associated Materials Advanced Sections Advanced Section 4 PDF Labs Lab6 Notebook","tags":"lectures","url":"lectures/lecture11/"},{"title":"Lecture 10: RNN-1","text":"Slides Lecture 10 PDF Lecture 10 PPTX Associated Materials Advanced Sections Advanced Section 4 PDF Labs Lab6 Notebook","tags":"lectures","url":"lectures/lecture10/"},{"title":"Lab 5: Convolutional Neural Networks","text":"Notebooks Lab5 CNNs Lab5 CNNs with solutions","tags":"pages","url":"pages/lab5/"},{"title":"Lab 5: CNNs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 5: Convolutional Neural Networks Harvard University Spring 2019 Lab instructor: Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman Authors: Eleni Kaxiras, Pavlos Protopapas, Patrick Ohiomoba, and Davis Sontag In [1]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab we will look at Convolutional Neural Networks (CNNs), and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in CNNs - such as convolutional layers and pooling layers - in keras with an example. have a good undertanding on how images, a common type of data for a CNN, are represented in the computer and how to think of them as arrays of numbers. be familiar with preprocessing images with keras and sckit-learn . use keras-viz to produce Saliency maps. learn best practices for configuring the hyperparameters of a CNN. run your first CNN and see the error rate. In [2]: import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) import numpy as np from scipy.optimize import minimize import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras.preprocessing.image import ImageDataGenerator from keras.callbacks import LearningRateScheduler from keras.callbacks import History from keras import losses from keras.datasets import mnist from keras.utils import to_categorical from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) % matplotlib inline 1.12.0 2.1.6-tf Using TensorFlow backend. Prologue: keras-viz Visualization Toolkit keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization Saliency maps Class activation maps All visualizations by default support N-dimensional image inputs. i.e., it generalizes to N-dim image inputs to your model. Compatible with both theano and tensorflow backends with 'channels_first', 'channels_last' data format. Read the documentation at https://raghakot.github.io/keras-vis.https://github.com/raghakot/keras-vis To install use pip install git+https://github.com/raghakot/keras-vis.git --upgrade SEAS JupyterHub Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class (accessible from the 'Jupyter' menu link in Canvas). These are AWS p2 instances with a GPU, 10GB of disk space, and 61 GB of RAM, for faster training for your networks. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. You are not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Part 1: Parts of a Convolutional Neural Net There are three types of layers in a Convolutional Neural Network: Convolutional Layers Pooling Layers. Dropout Layers. Fully Connected Layers. a. Convolutional Layers. Convolutional layers are comprised of filters and feature maps . The filters are essentially the neurons of the layer. They have the weights and produce the input for the next layer. The feature map is the output of one filter applied to the previous layer. The fundamental difference between a densely connected layer and a convolution layer is that dense layers learn global patterns in their input feature space (for example, for an MNIST digit, patterns involving all pixels), whereas convolution layers learn local patterns: in the case of images, patterns found in small 2D windows of the inputs called receptive fields . This key characteristic gives convnets two interesting properties: The patterns they learn are translation invariant . After learning a certain pattern in the lower-right corner of a picture, a convnet can recognize it anywhere: for example, in the upper-left corner. A densely connected network would have to learn the pattern anew if it appeared at a new location. This makes convnets data efficient when processing images (because the visual world is fundamentally translation invariant): they need fewer training samples to learn representations that have generalization power. They can learn spatial hierarchies of patterns . A first convolution layer will learn small local patterns such as edges, a second convolution layer will learn larger patterns made of the features of the first layers, and so on. This allows convnets to efficiently learn increasingly complex and abstract visual concepts (because the visual world is fundamentally spatially hierarchical). Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height and width) as well as a depth axis (also called the channels axis). For an RGB image, the dimension of the depth axis is 3, because the image has three color channels: red, green, and blue. For a black-and-white picture, like the MNIST digits, the depth is 1 (levels of gray). The convolution operation extracts patches from its input feature map and applies the same transformation to all of these patches, producing an output feature map. This output feature map is still a 3D tensor: it has a width and a height. Its depth can be arbitrary, because the output depth is a parameter of the layer, and the different channels in that depth axis no longer stand for specific colors as in RGB input; rather, they stand for filters. Filters encode specific aspects of the input data: at a high level, a single filter could encode the concept \"presence of a face in the input,\" for instance. In the MNIST example that we will see, the first convolution layer takes a feature map of size (28, 28, 1) and outputs a feature map of size (26, 26, 32): it computes 32 filters over its input. Each of these 32 output channels contains a 26×26 grid of values, which is a response map of the filter over the input, indicating the response of that filter pattern at different locations in the input. Convolutions are defined by two key parameters: Size of the patches extracted from the inputs. These are typically 3×3 or 5×5 The number of filters computed by the convolution. Padding : One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, In keras see convolutional layers keras.layers.Conv2D (filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True, kernel_initializer='glorot_uniform', data_format='channels_last', bias_initializer='zeros') How are the values in feature maps calculated? Exercise 1: Compute the operations by hand (assuming zero padding and same arrays for all channels) to produce the first element of the 4x4 feature map. How did we get the 4x4 output size? Write this Conv layer in keras -- your answer here b. Pooling Layers. Pooling layers are also comprised of filters and feature maps. Let's say the pooling layer has a 2x2 receptive field and a stride of 2. This stride results in feature maps that are one half the size of the input feature maps. We can use a max() operation for each receptive field. In keras see pooling layers keras.layers.MaxPooling2D (pool_size=(2, 2), strides=None, padding='valid', data_format=None) c. Dropout Layers. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. In keras see Dropout layers keras.layers.Dropout(rate, seed=None) rate: float between 0 and 1. Fraction of the input units to drop. seed: A Python integer to use as random seed. References Dropout: A Simple Way to Prevent Neural Networks from Overfitting d. Fully Connected Layers. A fully connected layer flattens the square feature map into a vector. Then we can use a sigmoid or softmax activation function to output probabilities of classes. In keras see FC layers keras.layers.Dense (units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros') IT'S ALL ABOUT THE HYPERPARAMETERS! stride size of filter number of filters poolsize Part 2: Preprocessing the data Taking a look at how images are represented in a computer using a photo of a Picasso sculpture In [3]: img = plt . imread ( 'data/picasso.png' ) img . shape Out[3]: (150, 200, 4) In [4]: img [ 1 ,:, 1 ] Out[4]: array([0.5411765 , 0.5372549 , 0.53333336, 0.5372549 , 0.5372549 , 0.5372549 , 0.54509807, 0.4509804 , 0.41568628, 0.4392157 , 0.4509804 , 0.5372549 , 0.54901963, 0.54901963, 0.54509807, 0.54901963, 0.5411765 , 0.54509807, 0.54509807, 0.56078434, 0.56078434, 0.56078434, 0.5568628 , 0.56078434, 0.5647059 , 0.5647059 , 0.5647059 , 0.56078434, 0.5411765 , 0.53333336, 0.5372549 , 0.53333336, 0.5294118 , 0.53333336, 0.53333336, 0.5294118 , 0.53333336, 0.5372549 , 0.5411765 , 0.53333336, 0.5176471 , 0.5176471 , 0.5254902 , 0.5176471 , 0.50980395, 0.5176471 , 0.5294118 , 0.5254902 , 0.5254902 , 0.5176471 , 0.5176471 , 0.5254902 , 0.53333336, 0.53333336, 0.54509807, 0.5568628 , 0.56078434, 0.5686275 , 0.5764706 , 0.5686275 , 0.5686275 , 0.5764706 , 0.57254905, 0.5686275 , 0.5647059 , 0.56078434, 0.5529412 , 0.56078434, 0.5568628 , 0.5529412 , 0.5568628 , 0.56078434, 0.5568628 , 0.56078434, 0.5568628 , 0.54901963, 0.5411765 , 0.53333336, 0.5372549 , 0.5372549 , 0.53333336, 0.5294118 , 0.5372549 , 0.5411765 , 0.5411765 , 0.54509807, 0.5411765 , 0.54509807, 0.54509807, 0.53333336, 0.5294118 , 0.5294118 , 0.5294118 , 0.5294118 , 0.5411765 , 0.5372549 , 0.5411765 , 0.54901963, 0.5411765 , 0.5254902 , 0.5294118 , 0.5294118 , 0.5294118 , 0.52156866, 0.5137255 , 0.52156866, 0.5372549 , 0.5411765 , 0.5411765 , 0.5254902 , 0.52156866, 0.5294118 , 0.52156866, 0.5176471 , 0.5254902 , 0.5294118 , 0.5294118 , 0.52156866, 0.52156866, 0.5254902 , 0.5294118 , 0.53333336, 0.5294118 , 0.53333336, 0.5372549 , 0.53333336, 0.54509807, 0.54509807, 0.5411765 , 0.54901963, 0.5529412 , 0.5529412 , 0.54901963, 0.54509807, 0.5529412 , 0.54509807, 0.54901963, 0.54509807, 0.54509807, 0.54509807, 0.5411765 , 0.54509807, 0.54901963, 0.5529412 , 0.54509807, 0.54509807, 0.54901963, 0.5411765 , 0.54509807, 0.54901963, 0.54901963, 0.54901963, 0.54509807, 0.54509807, 0.54509807, 0.5372549 , 0.5411765 , 0.5411765 , 0.5372549 , 0.5372549 , 0.5372549 , 0.5372549 , 0.5411765 , 0.5294118 , 0.53333336, 0.5372549 , 0.54509807, 0.5372549 , 0.53333336, 0.5294118 , 0.52156866, 0.5254902 , 0.50980395, 0.5176471 , 0.5176471 , 0.5176471 , 0.5254902 , 0.52156866, 0.5176471 , 0.5254902 , 0.53333336, 0.53333336, 0.5176471 , 0.50980395, 0.5176471 , 0.50980395, 0.5176471 , 0.5137255 , 0.5137255 , 0.5137255 , 0.5058824 , 0.5019608 , 0.5137255 , 0.5058824 , 0.49803922, 0.5058824 , 0.48235294, 0.48235294, 0.47058824, 0.48235294], dtype=float32) In [5]: print ( type ( img [ 50 ][ 0 ][ 0 ])) In [6]: # let's see the image imgplot = plt . imshow ( img ) Visualizing the channels In [7]: R_img = img [:,:, 0 ] G_img = img [:,:, 1 ] B_img = img [:,:, 2 ] plt . subplot ( 221 ) plt . imshow ( R_img , cmap = plt . cm . Reds ) plt . subplot ( 222 ) plt . imshow ( G_img , cmap = plt . cm . Greens ) plt . subplot ( 223 ) plt . imshow ( B_img , cmap = plt . cm . Blues ) plt . subplot ( 224 ) plt . imshow ( img ) plt . show () More on preprocessing data below! If you want to learn more: Image Processing with Python and Scipy Part 3: Putting the Parts together to make a small ConvNet Model Let's put all the parts together to make a convnet for classifying our good old MNIST digits. In [8]: # Load data and preprocess ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # load MNIST data train_images . shape Out[8]: (60000, 28, 28) In [9]: train_images . max (), train_images . min () Out[9]: (255, 0) In [10]: train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) # Reshape to get third dimension train_images = train_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) # Reshape to get third dimension test_images = test_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 # Convert labels to categorical data train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) In [11]: mnist_cnn_model = models . Sequential () # Create sequential model # Add network layers mnist_cnn_model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 28 , 28 , 1 ))) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network like those you're already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top. In [12]: mnist_cnn_model . add ( layers . Flatten ()) mnist_cnn_model . add ( layers . Dense ( 64 , activation = 'relu' )) mnist_cnn_model . add ( layers . Dense ( 10 , activation = 'softmax' )) mnist_cnn_model . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_1 (Conv2D) (None, 26, 26, 32) 320 _________________________________________________________________ max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32) 0 _________________________________________________________________ conv2d_2 (Conv2D) (None, 11, 11, 64) 18496 _________________________________________________________________ max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64) 0 _________________________________________________________________ conv2d_3 (Conv2D) (None, 3, 3, 64) 36928 _________________________________________________________________ flatten_1 (Flatten) (None, 576) 0 _________________________________________________________________ dense_1 (Dense) (None, 64) 36928 _________________________________________________________________ dense_2 (Dense) (None, 10) 650 ================================================================= Total params: 93,322 Trainable params: 93,322 Non-trainable params: 0 _________________________________________________________________ In [13]: # Compile model mnist_cnn_model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # Fit the model mnist_cnn_model . fit ( train_images , train_labels , epochs = 5 , batch_size = 64 ) # Evaluate the model on the test data: test_loss , test_acc = mnist_cnn_model . evaluate ( test_images , test_labels ) test_acc Epoch 1/5 60000/60000 [==============================] - 21s 343us/step - loss: 0.1780 - acc: 0.9456 Epoch 2/5 60000/60000 [==============================] - 21s 352us/step - loss: 0.0479 - acc: 0.9854 Epoch 3/5 60000/60000 [==============================] - 25s 419us/step - loss: 0.0341 - acc: 0.9896 Epoch 4/5 60000/60000 [==============================] - 21s 349us/step - loss: 0.0254 - acc: 0.9922 Epoch 5/5 60000/60000 [==============================] - 21s 347us/step - loss: 0.0200 - acc: 0.9941 10000/10000 [==============================] - 1s 124us/step Out[13]: 0.9902 A densely connected network (MLP) running MNIST usually has a test accuracy of 97.8%, whereas our basic convnet has a test accuracy of 99.03%: we decreased the error rate by 68% (relative) with only 5 epochs. Not bad! But why does this simple convnet work so well, compared to a densely connected model? The answer is above on how convolutional layers work! Data Preprocessing : Meet the ImageDataGenerator class in keras (docs) The MNIST and other pre-loaded dataset are formatted in a way that is almost ready for feeding into the model. What about plain images? They should be formatted into appropriately preprocessed floating-point tensors before being fed into the network. The Dogs vs. Cats dataset that you'll use isn't packaged with Keras. It was made available by Kaggle as part of a computer-vision competition in late 2013, back when convnets weren't mainstream. The data has been downloaded for you from https://www.kaggle.com/c/dogs-vs-cats/data The pictures are medium-resolution color JPEGs. In [14]: # TODO: set your base dir to your correct local location base_dir = 'data/cats_and_dogs_small' import os , shutil # Set up directory information train_dir = os . path . join ( base_dir , 'train' ) validation_dir = os . path . join ( base_dir , 'validation' ) test_dir = os . path . join ( base_dir , 'test' ) train_cats_dir = os . path . join ( train_dir , 'cats' ) train_dogs_dir = os . path . join ( train_dir , 'dogs' ) validation_cats_dir = os . path . join ( validation_dir , 'cats' ) validation_dogs_dir = os . path . join ( validation_dir , 'dogs' ) test_cats_dir = os . path . join ( test_dir , 'cats' ) test_dogs_dir = os . path . join ( test_dir , 'dogs' ) print ( 'total training cat images:' , len ( os . listdir ( train_cats_dir ))) print ( 'total training dog images:' , len ( os . listdir ( train_dogs_dir ))) print ( 'total validation cat images:' , len ( os . listdir ( validation_cats_dir ))) print ( 'total validation dog images:' , len ( os . listdir ( validation_dogs_dir ))) print ( 'total test cat images:' , len ( os . listdir ( test_cats_dir ))) print ( 'total test dog images:' , len ( os . listdir ( test_dogs_dir ))) total training cat images: 1000 total training dog images: 1000 total validation cat images: 500 total validation dog images: 500 total test cat images: 500 total test dog images: 500 So you do indeed have 2,000 training images, 1,000 validation images, and 1,000 test images. Each split contains the same number of samples from each class: this is a balanced binary-classification problem, which means classification accuracy will be an appropriate measure of success. Building the network In [15]: from keras import layers from keras import models model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= conv2d_4 (Conv2D) (None, 148, 148, 32) 896 _________________________________________________________________ max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32) 0 _________________________________________________________________ conv2d_5 (Conv2D) (None, 72, 72, 64) 18496 _________________________________________________________________ max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64) 0 _________________________________________________________________ conv2d_6 (Conv2D) (None, 34, 34, 128) 73856 _________________________________________________________________ max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128) 0 _________________________________________________________________ conv2d_7 (Conv2D) (None, 15, 15, 128) 147584 _________________________________________________________________ max_pooling2d_6 (MaxPooling2 (None, 7, 7, 128) 0 _________________________________________________________________ flatten_2 (Flatten) (None, 6272) 0 _________________________________________________________________ dense_3 (Dense) (None, 512) 3211776 _________________________________________________________________ dense_4 (Dense) (None, 1) 513 ================================================================= Total params: 3,453,121 Trainable params: 3,453,121 Non-trainable params: 0 _________________________________________________________________ For the compilation step, you'll go with the RMSprop optimizer. Because you ended the network with a single sigmoid unit, you'll use binary crossentropy as the loss. In [16]: from keras import optimizers model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) The steps for getting it into the network are roughly as follows: Read the picture files. Decode the JPEG content to RGB grids of pixels. Convert these into floating-point tensors. Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values). It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically with the class ImageDataGenerator , which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors. This is what you'll use here. In [17]: from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator ( rescale = 1. / 255 ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. Let's look at the output of one of these generators: it yields batches of 150×150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, you need to break the iteration loop at some point: In [18]: for data_batch , labels_batch in train_generator : print ( 'data batch shape:' , data_batch . shape ) print ( 'labels batch shape:' , labels_batch . shape ) break data batch shape: (20, 150, 150, 3) labels batch shape: (20,) Let's fit the model to the data using the generator. You do so using the .fit_generator method, the equivalent of .fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely, like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps - the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples. When using fit_generator, you can pass a validation_data argument, much as with the fit method. It's important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation In [19]: history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 30 validation_data = validation_generator , validation_steps = 50 ) # It's good practice to always save your models after training. model . save ( 'cats_and_dogs_small_1.h5' ) Epoch 1/5 100/100 [==============================] - 55s 549ms/step - loss: 0.6885 - acc: 0.5320 - val_loss: 0.6711 - val_acc: 0.6220 Epoch 2/5 100/100 [==============================] - 56s 558ms/step - loss: 0.6620 - acc: 0.5950 - val_loss: 0.6500 - val_acc: 0.6170 Epoch 3/5 100/100 [==============================] - 56s 562ms/step - loss: 0.6198 - acc: 0.6510 - val_loss: 0.6771 - val_acc: 0.5790 Epoch 4/5 100/100 [==============================] - 57s 567ms/step - loss: 0.5733 - acc: 0.6955 - val_loss: 0.5993 - val_acc: 0.6740 Epoch 5/5 100/100 [==============================] - 57s 566ms/step - loss: 0.5350 - acc: 0.7305 - val_loss: 0.6140 - val_acc: 0.6520 Let's plot the loss and accuracy of the model over the training and validation data during training: In [20]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Let's try data augmentation In [21]: datagen = ImageDataGenerator ( rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True , fill_mode = 'nearest' ) These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over this code: rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures. width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally. shear_range is for randomly applying shearing transformations. zoom_range is for randomly zooming inside pictures. horizontal_flip is for randomly flipping half the images horizontally—relevant when there are no assumptions of - horizontal asymmetry (for example, real-world pictures). fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift. Let's look at the augmented images In [22]: from keras.preprocessing import image fnames = [ os . path . join ( train_dogs_dir , fname ) for fname in os . listdir ( train_dogs_dir )] img_path = fnames [ 3 ] # Chooses one image to augment img = image . load_img ( img_path , target_size = ( 150 , 150 )) # Reads the image and resizes it x = image . img_to_array ( img ) # Converts it to a Numpy array with shape (150, 150, 3) x = x . reshape (( 1 ,) + x . shape ) # Reshapes it to (1, 150, 150, 3) i = 0 for batch in datagen . flow ( x , batch_size = 1 ): plt . figure ( i ) imgplot = plt . imshow ( image . array_to_img ( batch [ 0 ])) i += 1 if i % 4 == 0 : break plt . show () If you train a new network using this data-augmentation configuration, the network will never see the same input twice. But the inputs it sees are still heavily intercorrelated, because they come from a small number of original images—you can't produce new information, you can only remix existing information. As such, this may not be enough to completely get rid of overfitting. To further fight overfitting, you'll also add a Dropout layer to your model right before the densely connected classifier. In [23]: model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) In [24]: # Let's train the network using data augmentation and dropout. train_datagen = ImageDataGenerator ( rescale = 1. / 255 , rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ,) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) # Note that the validation data shouldn't be augmented! train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 100 validation_data = validation_generator , validation_steps = 50 ) model . save ( 'cats_and_dogs_small_2.h5' ) Found 2000 images belonging to 2 classes. Found 1000 images belonging to 2 classes. Epoch 1/5 100/100 [==============================] - 94s 935ms/step - loss: 0.6902 - acc: 0.5294 - val_loss: 0.7003 - val_acc: 0.4924 Epoch 2/5 100/100 [==============================] - 88s 882ms/step - loss: 0.6763 - acc: 0.5703 - val_loss: 0.7350 - val_acc: 0.5090 Epoch 3/5 100/100 [==============================] - 90s 899ms/step - loss: 0.6681 - acc: 0.5816 - val_loss: 0.6458 - val_acc: 0.6098 Epoch 4/5 100/100 [==============================] - 88s 877ms/step - loss: 0.6496 - acc: 0.6241 - val_loss: 0.6431 - val_acc: 0.6192 Epoch 5/5 100/100 [==============================] - 89s 886ms/step - loss: 0.6298 - acc: 0.6369 - val_loss: 0.5897 - val_acc: 0.6580 And let's plot the results again. Thanks to data augmentation and dropout, you're no longer overfitting: the training curves are closely tracking the validation curves. You now reach an accuracy of 82%, a 15% relative improvement over the non-regularized model. (Note: these numbers are for 100 epochs..) In [25]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) By using regularization techniques even further, and by tuning the network's parameters (such as the number of filters per convolution layer, or the number of layers in the network), you may be able to get an even better accuracy, likely up to 86% or 87%. But it would prove difficult to go any higher just by training your own convnet from scratch, because you have so little data to work with. As a next step to improve your accuracy on this problem, you'll have to use a pretrained model. Part 4: keras viz toolkit https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb In [10]: class_idx = 0 indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] # pick some random input from here. idx = indices [ 0 ] # Lets sanity check the picked image. from matplotlib import pyplot as plt % matplotlib inline plt . rcParams [ 'figure.figsize' ] = ( 18 , 6 ) plt . imshow ( test_images [ idx ][ ... , 0 ]) Out[10]: In [11]: input_shape = ( 28 , 28 , 1 ) num_classes = 10 batch_size = 128 epochs = 5 model = Sequential () model . add ( layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ), activation = 'relu' , input_shape = input_shape )) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D ( pool_size = ( 2 , 2 ))) model . add ( layers . Dropout ( 0.25 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 128 , activation = 'relu' )) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( num_classes , activation = 'softmax' , name = 'preds' )) model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . Adam (), metrics = [ 'accuracy' ]) model . fit ( train_images , train_labels , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( test_images , test_labels )) score = model . evaluate ( test_images , test_labels , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) Train on 60000 samples, validate on 10000 samples Epoch 1/5 60000/60000 [==============================] - 81s 1ms/step - loss: 0.2462 - acc: 0.9248 - val_loss: 0.0524 - val_acc: 0.9828 Epoch 2/5 60000/60000 [==============================] - 86s 1ms/step - loss: 0.0905 - acc: 0.9726 - val_loss: 0.0391 - val_acc: 0.9857 Epoch 3/5 60000/60000 [==============================] - 83s 1ms/step - loss: 0.0691 - acc: 0.9788 - val_loss: 0.0376 - val_acc: 0.9876 Epoch 4/5 60000/60000 [==============================] - 81s 1ms/step - loss: 0.0544 - acc: 0.9832 - val_loss: 0.0307 - val_acc: 0.9896 Epoch 5/5 60000/60000 [==============================] - 84s 1ms/step - loss: 0.0467 - acc: 0.9854 - val_loss: 0.0305 - val_acc: 0.9904 Test loss: 0.030515316201592212 Test accuracy: 0.9904 In [12]: from vis.visualization import visualize_saliency from vis.utils import utils from keras import activations # Utility to search for layer index by name. # Alternatively we can specify this as -1 since it corresponds to the last layer. layer_idx = utils . find_layer_idx ( model , 'preds' ) In [13]: plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) from vis.visualization import visualize_cam import warnings warnings . filterwarnings ( 'ignore' ) # This corresponds to the Dense linear layer. for class_idx in np . arange ( 10 ): indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] idx = indices [ 0 ] f , ax = plt . subplots ( 1 , 4 ) ax [ 0 ] . imshow ( test_images [ idx ][ ... , 0 ]) for i , modifier in enumerate ([ None , 'guided' , 'relu' ]): grads = visualize_cam ( model , layer_idx , filter_indices = class_idx , seed_input = test_images [ idx ], backprop_modifier = modifier ) if modifier is None : modifier = 'vanilla' ax [ i + 1 ] . set_title ( modifier ) ax [ i + 1 ] . imshow ( grads , cmap = 'jet' ) References and Acknowledgements The cats and dogs part of this lab is based on the book Deep Learning with Python, Chapter 5 written by the Francois Chollet, the author of Keras. It is a very practical introduction to Deep Learning. It is appropriate for those with some Python knowledge who want to start with machine learning. The saliency maps are from https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab5/solutions/"},{"title":"Advanced Section 3: CNNs and Object Detection","text":"Slides PDF Lecture notes on ConvNets and architectures PDF External resources on object recognition What do we learn from region based object detectors (Faster R-CNN, R-FCN, FPN)? What do we learn from single shot object detectors (SSD, YOLOv3), FPN & Focal loss (RetinaNet)? Image segmentation with Mask R-CNN Face recognition references FaceNet: A Unified Embedding for Face Recognition and Clustering DeepFace: Face Generation using Deep Learning Deep Face Recognition: A Survey","tags":"A-sections","url":"a-sections/a-section3/"},{"title":"Lecture 9: CNN-2","text":"Slides Lecture 9 PDF Lecture 9 PPTX Associated Materials Advanced Sections Advanced Section 3 PDF Labs Lab5 Notebook with Solutions","tags":"lectures","url":"lectures/lecture9/"},{"title":"Lecture 9 Notebook","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lecture 9: NLP example with CNN Harvard University Spring 2019 Instructors: Pavlos Protopapas and Mark Glickman In [1]: #RUN THIS CELL import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } span.sub-q { font-weight: bold; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } In this example, we will try to implement a CNN for text. We will use the task of IMDB movie review classification. Response variable is positive/negative review. A sentence can be thought of as a sequence of words which have semantic connections across time. By semantic connection, we mean that the words that occur earlier in the sentence influence the sentence's structure and meaning in the latter part of the sentence. Note: There are also semantic connections backwards in a sentence (we will revisit this idea when we do RNNs from both directions and combine their outputs which we will see in the next few lectures). In [30]: import numpy from keras.datasets import imdb from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM , SimpleRNN from keras.layers.embeddings import Embedding from keras.layers import Flatten from keras.preprocessing import sequence from keras.layers.convolutional import Conv1D from keras.layers.convolutional import MaxPooling1D from keras.layers.embeddings import Embedding import numpy as np # fix random seed for reproducibility numpy . random . seed ( 1 ) SEEDING - Important thing to do in many machine learning tasks which involve stochastic sampling (where random numbers are generated for different samples) is to do seeding so that the results are fairly reproducible. WHY SEEDING ? Most random number generators in computers are pseudo-random number generators i.e. they generate random numbers starting from a seed, but internally have a deterministic formula to calculate the next random number it generates and thus, if you fix your seed, the set of random numbers produced are the same in every run. STEP 1 : Load and visualize the data In [43]: # We want to have a finite vocabulary (9,999 most frequent words, one for everything else) vocabulary_size = 10000 #We also want to have a finite length of reviews and not have to process really long sentences. # Anything longer will be chopped! max_review_length = 500 For practical data science applications, we need to convert text into tokens since the machine understands only numbers and not really English words like humans can. As a simple example of tokenization, we can see a small example. Assume we have 5 sentences. This is how we tokenize them into numbers once we create a dictionary. I have books - [1, 4, 7] Interesting books are useful [10,2,9,8] I have computers [1,4,6] Computers are interesting and useful [6,9,11,10,8] Books and computers are both valuable. [7,10,2,9,13,12] Create tokens for vocabulary based on frequency of occurrence. Hence, we assign the following tokens I-1, books-2, computers-3, have-4, are-5, computers-6,books-7, useful-8, are-9, and-10,interesting-11, valuable-12, both-13 Thankfully, in our dataset it is internally handled and each sentence is represented in such tokenized form. In [32]: ( X_train , y_train ), ( X_test , y_test ) = imdb . load_data ( num_words = vocabulary_size ) In [33]: print ( 'Number of reviews' , len ( X_train )) print ( 'Length of first and fifth review before padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) print ( 'First review' , X_train [ 0 ]) print ( 'First label' , y_train [ 0 ]) Number of reviews 25000 Length of first and fifth review before padding 218 147 First review [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32] First label 1 Pad sequences in order to ensure that all inputs have same sentence length and dimensions. DISCUSSION : Why are we padding here? In [34]: X_train = sequence . pad_sequences ( X_train , maxlen = max_review_length ) X_test = sequence . pad_sequences ( X_test , maxlen = max_review_length ) print ( 'Length of first and fifth review after padding' , len ( X_train [ 0 ]) , len ( X_train [ 4 ])) Length of first and fifth review after padding 500 500 Is Accuracy the right metric to look at ? Discuss : In what cases is accuracy a good metric to measure classification models ? What other metrics are useful incase accuracy proves to be incompetent metric for our dataset ? https://towardsdatascience.com/understanding-data-science-classification-metrics-in-scikit-learn-in-python-3bc336865019 In [35]: from collections import Counter counts = dict ( Counter ( y_train )) print ( 'Number of zeroes : ' , counts [ 0 ], ' and Number of ones : ' , counts [ 1 ]) Number of zeroes : 12500 and Number of ones : 12500 MODEL 1(a) : FEEDFORWARD NETWORKS WITHOUT EMBEDDINGS Let us build a single layer feedforward net with 250 nodes. GOAL : Calculate the number of parameters involved in this network and implement a feedforward net to do classification. In [36]: model = Sequential () model . add ( Dense ( 250 , activation = 'relu' , input_dim = max_review_length )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 3 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_16 (Dense) (None, 250) 125250 _________________________________________________________________ dense_17 (Dense) (None, 1) 251 ================================================================= Total params: 125,501 Trainable params: 125,501 Non-trainable params: 0 _________________________________________________________________ None Train on 25000 samples, validate on 25000 samples Epoch 1/3 - 1s - loss: 8.0534 - acc: 0.4990 - val_loss: 7.9612 - val_acc: 0.5053 Epoch 2/3 - 1s - loss: 8.0372 - acc: 0.5012 - val_loss: 8.0608 - val_acc: 0.4998 Epoch 3/3 - 1s - loss: 8.0574 - acc: 0.5001 - val_loss: 8.0603 - val_acc: 0.4999 Accuracy: 49.99% Any idea why the performance is terrible ? Hint : Tokenization. Obvious Workaround : One-Hot Encodings EMBEDDINGS - Sparse to Dense Transformations We use embeddings to reduce dimensions of our data since the tokens we assign based on our word frequency are discrete and do not have a continuous structure. What are embeddings ? Embeddings are functional transformations from a sparse discrete vector representation of text (either as tokens or as one-hot encodings) into a dense vector representation of a fixed size(usually of much lower dimensions than the vocabulary length of the text). The dense representations allow the neural network to generalize better. Here we are training our own embedding while training our neural network. To transfer \"knowledge\" from other sources, in more complicated projects we can also use pre-trained embeddings such as word-2-vec, GloVE, Fastext etc. https://nlpforhackers.io/word-embeddings/ Example Embeddings Transformation Let us first understand how Keras embedding layer works through a dummy example to see how the dimensions are transformed. In this example, each input is mapped to a 64 dimensional vector (via the embedding layer). EXERCISE : Manually calculate the number of parameters needed in the embedding layer before executing the code. In [37]: model = Sequential () #input - Number of categorical inputs, embedding dimension, input length. model . add ( Embedding ( 1000 , 64 , input_length = 10 )) print ( model . summary ()) # the model will take as input an integer matrix of size (batch, input_length). # the largest integer (i.e. word index) in the input should be # no larger than 999 (vocabulary size). # now model.output_shape == (None, 10, 64), where None is the batch dimension. input_array = np . random . randint ( 1000 , size = ( 32 , 10 )) print ( \"Shape of input : \" , input_array . shape ) model . compile ( 'rmsprop' , 'mse' ) output_array = model . predict ( input_array ) assert output_array . shape == ( 32 , 10 , 64 ) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_8 (Embedding) (None, 10, 64) 64000 ================================================================= Total params: 64,000 Trainable params: 64,000 Non-trainable params: 0 _________________________________________________________________ None Shape of input : (32, 10) In [44]: print ( input_array [ 0 ]) print ( output_array [ 0 ] . shape ) [905 644 12 451 965 181 64 621 703 214] (10, 64) MODEL 1(b) : FEEDFORWARD NETWORKS WITH EMBEDDINGS EXERCISE : Implement the feedforward net combining the embedding layer and the feedforward layer(one layer, 250 nodes) without looking at cells below. Manually calculate the number of parameters needed in the feedforward network before executing the code. In [39]: embedding_dim = 100 In [40]: model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_9 (Embedding) (None, 500, 100) 1000000 _________________________________________________________________ flatten_4 (Flatten) (None, 50000) 0 _________________________________________________________________ dense_18 (Dense) (None, 250) 12500250 _________________________________________________________________ dense_19 (Dense) (None, 1) 251 ================================================================= Total params: 13,500,501 Trainable params: 13,500,501 Non-trainable params: 0 _________________________________________________________________ None In [41]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) Train on 25000 samples, validate on 25000 samples Epoch 1/2 - 89s - loss: 0.5811 - acc: 0.6663 - val_loss: 0.3381 - val_acc: 0.8514 Epoch 2/2 - 84s - loss: 0.2002 - acc: 0.9222 - val_loss: 0.3017 - val_acc: 0.8726 Accuracy: 87.26% MODEL 2 : Convolutional Nets Text can be thought of as 1-dimensional sequence and we can apply 1-D Convolutions over a set of words. Let us walk through convolutions on text data with this blog. http://debajyotidatta.github.io/nlp/deep/learning/word-embeddings/2016/11/27/Understanding-Convolutions-In-Text/ EXERCISE : Manually calculate the number of parameters needed in the feedforward network before executing the code. In [20]: # create the model model = Sequential () model . add ( Embedding ( vocabulary_size , embedding_dim , input_length = max_review_length )) model . add ( Conv1D ( filters = embedding_dim , kernel_size = 3 , padding = 'same' , activation = 'relu' )) model . add ( MaxPooling1D ( pool_size = 2 )) model . add ( Flatten ()) model . add ( Dense ( 250 , activation = 'relu' )) model . add ( Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = 'adam' , metrics = [ 'accuracy' ]) print ( model . summary ()) _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_4 (Embedding) (None, 500, 100) 1000000 _________________________________________________________________ conv1d_1 (Conv1D) (None, 500, 100) 30100 _________________________________________________________________ max_pooling1d_1 (MaxPooling1 (None, 250, 100) 0 _________________________________________________________________ flatten_2 (Flatten) (None, 25000) 0 _________________________________________________________________ dense_11 (Dense) (None, 250) 6250250 _________________________________________________________________ dense_12 (Dense) (None, 1) 251 ================================================================= Total params: 7,280,601 Trainable params: 7,280,601 Non-trainable params: 0 _________________________________________________________________ None In [21]: # Fit the model model . fit ( X_train , y_train , validation_data = ( X_test , y_test ), epochs = 2 , batch_size = 128 , verbose = 2 ) # Final evaluation of the model scores = model . evaluate ( X_test , y_test , verbose = 0 ) print ( \"Accuracy: %.2f%% \" % ( scores [ 1 ] * 100 )) Train on 25000 samples, validate on 25000 samples Epoch 1/2 - 314s - loss: 0.4952 - acc: 0.7055 - val_loss: 0.2996 - val_acc: 0.8768 Epoch 2/2 - 147s - loss: 0.2043 - acc: 0.9216 - val_loss: 0.2849 - val_acc: 0.8819 Accuracy: 88.19% EXERCISE Try other CNNs with Different kernel sizes Different pooling operations(AveragePooling1D) DISCUSSION : What does max and average pooling mean in terms of processing text sequences ? if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"lectures","url":"lectures/lecture9/notebook/"},{"title":"Lecture 8: CNN-1","text":"Slides Lecture 8 PDF Lecture 8 PPTX Associated Materials Advanced Sections Advanced Section 3 PDF Labs Lab5 Notebook with Solutions","tags":"lectures","url":"lectures/lecture8/"},{"title":"Lecture 7: Scaling","text":"Slides Lecture 7 PDF Associated Materials Labs","tags":"lectures","url":"lectures/lecture7/"},{"title":"Advanced Section 2: Optimal Transport","text":"Slides PDF Lecture Notes PDF Intro to optimization notes PDF References for further reading Computation optimal transport Learning with a Wasserstein Loss Optimal Transport for Domain Adaptation","tags":"A-sections","url":"a-sections/a-section2/"},{"title":"Lab 3: Optimization of Neural Networks","text":"Lab 3 Notebooks Lab3 Optimization in NNs Lab3 Optimization with solutions","tags":"lab","url":"lab/lab3/"},{"title":"Lab 3: Optimization of Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 3: Optimization in Artificial Neural Networks Harvard University Spring 2019 Lab instructor : Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore ways to optimize the loss function of a Multilayer Learning Perceptor (MLP) by tuning the model hyperparameters. We'll also explore the use of cross-validation as a technique for checking potential values for these hyperparameters. By the end of this lab, you should: Be familiar with the use of sklearn 's optimize function. Be able to identify the hyperparameters that go into the training of a MLP. Be familiar with the implementation in keras of various optimization techniques. Know how to use callbacks Apply cross-validation to check for multiple values of hyperparameters. In [2]: import matplotlib.pyplot as plt import numpy as np from scipy.optimize import minimize % matplotlib inline Part 1: Beale's function First let's look at function optimization in scipy.optimize , using Beale's function as an example Optimizing a function $f: A\\rightarrow R$, from some set A to the real numbers is finding an element $x_0\\,\\epsilon\\, A$ such that $f(x_0)\\leq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the minimum) or such that $f(x_0)\\geq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the maximum). To illustrate our point we will use a function of two parameters. Our goal is to optimize over these 2 parameters. We can extend to higher dimensions by plotting pairs of parameters against each other. The Wikipedia article on Test functions for optimization has a few functions that are useful for evaluating optimization algorithms. Here is Beale's function: $f(x,y)$ = $(1.5−x+xy)&#94;2+(2.25−x+xy&#94;2)&#94;2+(2.625−x+xy&#94;3)&#94;2$ We already know that this function has a minimum at [3.0, 0.5]. Let's see if scipy will find it. source: https://en.wikipedia.org/wiki/Test_functions_for_optimization In [3]: # define Beale's function which we want to minimize def objective ( X ): x = X [ 0 ]; y = X [ 1 ] return ( 1.5 - x + x * y ) ** 2 + ( 2.25 - x + x * y ** 2 ) ** 2 + ( 2.625 - x + x * y ** 3 ) ** 2 In [4]: # function boundaries xmin , xmax , xstep = - 4.5 , 4.5 , . 9 ymin , ymax , ystep = - 4.5 , 4.5 , . 9 In [5]: # Let's create some points x1 , y1 = np . meshgrid ( np . arange ( xmin , xmax + xstep , xstep ), np . arange ( ymin , ymax + ystep , ystep )) Let's make an initial guess In [6]: # initial guess x0 = [ 4. , 4. ] f0 = objective ( x0 ) print ( f0 ) 68891.203125 In [7]: bnds = (( xmin , xmax ), ( ymin , ymax )) minimum = minimize ( objective , x0 , bounds = bnds ) In [8]: print ( minimum ) fun: 2.068025638865627e-12 hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64> jac: array([-1.55969780e-06, 9.89837957e-06]) message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL' nfev: 60 nit: 14 status: 0 success: True x: array([3.00000257, 0.50000085]) In [9]: real_min = [ 3.0 , 0.5 ] print ( f 'The answer, {minimum.x} , is very close to the optimum as we know it, which is {real_min} ' ) print ( f 'The value of the objective for {real_min} is {objective(real_min)}' ) The answer, [3.00000257 0.50000085], is very close to the optimum as we know it, which is [3.0, 0.5] The value of the objective for [3.0, 0.5] is 0.0 Part 2: Optimization in neural networks In general: Learning Representation --> Objective function --> Optimization algorithm A neural network can be defined as a framework that combines inputs and tries to guess the output. If we are lucky enough to have some results, called \"the ground truth\", to compare the outputs produced by the network, we can calculate the error . So the network guesses, calculates some error function, guesses again, trying to minimize this error, guesses again, until the error does not go down any more. This is optimization. In neural networks the most common used optimization algorithms, are flavors of GD (gradient descent) . The objective function used in gradient descent is the loss function which we want to minimize . A keras Refresher Keras is a Python library for deep learning that can run on top of both Theano or TensorFlow, two powerful Python libraries for fast numerical computing created and released by Facebook and Google, respectevely. Keras was developed to make developing deep learning models as fast and easy as possible for research and practical applications. It runs on Python 2.7 or 3.5 and can seamlessly execute on GPUs and CPUs. Keras is built on the idea of a model. At its core we have a sequence of layers called the Sequential model which is a linear stack of layers. Keras also provides the functional API , a way to define complex models, such as multi-output models, directed acyclic graphs, or models with shared layers. We can summarize the construction of deep learning models in Keras using the Sequential model as follows: Define your model : create a Sequential model and add layers. Compile your model : specify loss function and optimizers and call the .compile() function. Fit your model : train the model on data by calling the .fit() function. Make predictions : use the model to generate predictions on new data by calling functions such as .evaluate() or .predict() . Callbacks: taking a peek into our model while it's training You can look at what is happening in various stages of your model by using callbacks . A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training. A callback function you are already familiar with is keras.callbacks.History() . This is automatically included in .fit() . Another very useful one is keras.callbacks.ModelCheckpoint which saves the model with its weights at a certain point in the training. This can prove useful if your model is running for a long time and a system failure happens. Not all is lost then. It's a good practice to save the model weights only when an improvement is observed as measured by the acc , for example. keras.callbacks.EarlyStopping stops the training when a monitored quantity has stopped improving. keras.callbacks.LearningRateScheduler will change the learning rate during training. We will apply some callbacks later. For full documentation on callbacks see https://keras.io/callbacks/ What are the steps to optimizing our network? In [10]: import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras.callbacks import LearningRateScheduler from keras.callbacks import History from keras import losses from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) 1.12.0 2.1.6-tf Using TensorFlow backend. In [11]: # fix random seed for reproducibility np . random . seed ( 5 ) Step 1 - Deciding on the network topology (not really considered optimization but is obviously very important) We will use the MNIST dataset which consists of grayscale images of handwritten digits (0-9) whose dimension is 28x28 pixels. Each pixel is 8 bits so its value ranges from 0 to 255. In [12]: #mnist = tf.keras.datasets.mnist mnist = keras . datasets . mnist ( x_train , y_train ),( x_test , y_test ) = mnist . load_data () x_train . shape , y_train . shape Out[12]: ((60000, 28, 28), (60000,)) Each label is a number between 0 and 9 In [13]: print ( y_train ) [5 0 4 ... 5 6 8] Let's look at some 10 of the images In [14]: plt . figure ( figsize = ( 10 , 10 )) for i in range ( 10 ): plt . subplot ( 5 , 5 , i + 1 ) plt . xticks ([]) plt . yticks ([]) plt . grid ( False ) plt . imshow ( x_train [ i ], cmap = plt . cm . binary ) plt . xlabel ( y_train [ i ]) In [15]: x_train [ 45 ] . shape x_train [ 45 , 15 : 20 , 15 : 20 ] Out[15]: array([[ 11, 198, 231, 41, 0], [ 82, 252, 204, 0, 0], [253, 253, 141, 0, 0], [252, 220, 36, 0, 0], [252, 96, 0, 0, 0]], dtype=uint8) In [17]: print ( f 'We have {x_train.shape[0]} train samples' ) print ( f 'We have {x_test.shape[0]} test samples' ) We have 60000 train samples We have 10000 test samples Preprocessing the data To run our NN we need to pre-process the data First we need to make the 2D image arrays into 1D (flatten them). We can either perform this by using array reshaping with numpy.reshape() or the keras ' method for this: a layer called tf.keras.layers.Flatten which transforms the format of the images from a 2d-array (of 28 by 28 pixels), to a 1D-array of 28 * 28 = 784 pixels. Then we need to normalize the pixel values (give them values between 0 and 1) using the following transformation: \\begin{align} x := \\dfrac{x - x_{min}}{x_{max} - x_{min}} \\textrm{} \\end{align} In our case $x_{min} = 0$ and $x_{max} = 255$ so the formula becomes simply $x := {x}/255$ In [18]: # normalize the data x_train , x_test = x_train / 255.0 , x_test / 255.0 In [19]: # reshape the data into 1D vectors x_train = x_train . reshape ( 60000 , 784 ) x_test = x_test . reshape ( 10000 , 784 ) num_classes = 10 In [20]: x_train . shape [ 1 ] Out[20]: 784 Now let's prepare our class vector (y) to a binary class matrix, e.g. for use with categorical_crossentropy. In [21]: # Convert class vectors to binary class matrices y_train = keras . utils . to_categorical ( y_train , num_classes ) y_test = keras . utils . to_categorical ( y_test , num_classes ) In [22]: y_train [ 0 ] Out[22]: array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32) Now we are ready to build the model! Step 2 - Adjusting the learning rate One of the most common optimization algorithm is Stochastic Gradient Descent (SGD). The hyperparameters that can be optimized in SGD are learning rate , momentum , decay and nesterov . Learning rate controls the weight at the end of each batch, and momentum controls how much to let the previous update influence the current weight update. Decay indicates the learning rate decay over each update, and nesterov takes the value True or False depending on if we want to apply Nesterov momentum. Typical values for those hyperparameters are lr=0.01, decay=1e-6, momentum=0.9, and nesterov=True. The learning rate hyperparameter goes into the optimizer function which we will see below. Keras has a default learning rate scheduler in the SGD optimizer that decreases the learning rate during the stochastic gradient descent optimization algorithm. The learning rate is decreased according to this formula: \\begin{align} lr = lr * 1./(1. + decay * epoch) \\textrm{} \\end{align} source: http://cs231n.github.io/neural-networks-3 Let's implement a learning rate adaptation schedule in Keras . We'll start with SGD and a learning rate value of 0.1. We will then train the model for 60 epochs and set the decay argument to 0.0016 (0.1/60). We also include a momentum value of 0.8 since that seems to work well when using an adaptive learning rate. In [23]: epochs = 60 learning_rate = 0.1 decay_rate = learning_rate / epochs momentum = 0.8 sgd = SGD ( lr = learning_rate , momentum = momentum , decay = decay_rate , nesterov = False ) In [24]: # build the model input_dim = x_train . shape [ 1 ] lr_model = Sequential () lr_model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) lr_model . add ( Dropout ( 0.1 )) lr_model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) lr_model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) # compile the model lr_model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'acc' ]) In [25]: %%time # Fit the model batch_size = int ( input_dim / 100 ) lr_model_history = lr_model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 9s 145us/step - loss: 0.3158 - acc: 0.9043 - val_loss: 0.1467 - val_acc: 0.9550 Epoch 2/60 60000/60000 [==============================] - 8s 136us/step - loss: 0.1478 - acc: 0.9555 - val_loss: 0.1194 - val_acc: 0.9617 Epoch 3/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.1248 - acc: 0.9620 - val_loss: 0.1122 - val_acc: 0.9646 Epoch 4/60 60000/60000 [==============================] - 8s 136us/step - loss: 0.1167 - acc: 0.9638 - val_loss: 0.1075 - val_acc: 0.9681 Epoch 5/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.1103 - acc: 0.9666 - val_loss: 0.1039 - val_acc: 0.9691 Epoch 6/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.1051 - acc: 0.9677 - val_loss: 0.1015 - val_acc: 0.9694 Epoch 7/60 60000/60000 [==============================] - 8s 136us/step - loss: 0.1003 - acc: 0.9691 - val_loss: 0.1002 - val_acc: 0.9694 Epoch 8/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0961 - acc: 0.9707 - val_loss: 0.0998 - val_acc: 0.9694 Epoch 9/60 60000/60000 [==============================] - 9s 154us/step - loss: 0.0951 - acc: 0.9707 - val_loss: 0.0989 - val_acc: 0.9699 Epoch 10/60 60000/60000 [==============================] - 9s 150us/step - loss: 0.0919 - acc: 0.9721 - val_loss: 0.0978 - val_acc: 0.9696 Epoch 11/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0930 - acc: 0.9720 - val_loss: 0.0964 - val_acc: 0.9702 Epoch 12/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0899 - acc: 0.9728 - val_loss: 0.0965 - val_acc: 0.9703 Epoch 13/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0883 - acc: 0.9732 - val_loss: 0.0951 - val_acc: 0.9713 Epoch 14/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0871 - acc: 0.9733 - val_loss: 0.0958 - val_acc: 0.9705 Epoch 15/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0888 - acc: 0.9731 - val_loss: 0.0952 - val_acc: 0.9709 Epoch 16/60 60000/60000 [==============================] - 9s 145us/step - loss: 0.0857 - acc: 0.9743 - val_loss: 0.0950 - val_acc: 0.9713 Epoch 17/60 60000/60000 [==============================] - 9s 157us/step - loss: 0.0843 - acc: 0.9742 - val_loss: 0.0957 - val_acc: 0.9709 Epoch 18/60 60000/60000 [==============================] - 8s 142us/step - loss: 0.0842 - acc: 0.9749 - val_loss: 0.0942 - val_acc: 0.9719 Epoch 19/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0839 - acc: 0.9750 - val_loss: 0.0936 - val_acc: 0.9723 Epoch 20/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0824 - acc: 0.9748 - val_loss: 0.0942 - val_acc: 0.9723 Epoch 21/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0824 - acc: 0.9749 - val_loss: 0.0940 - val_acc: 0.9725 Epoch 22/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0829 - acc: 0.9752 - val_loss: 0.0938 - val_acc: 0.9718 Epoch 23/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0795 - acc: 0.9763 - val_loss: 0.0939 - val_acc: 0.9718 Epoch 24/60 60000/60000 [==============================] - 9s 149us/step - loss: 0.0796 - acc: 0.9763 - val_loss: 0.0936 - val_acc: 0.9722 Epoch 25/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0783 - acc: 0.9759 - val_loss: 0.0935 - val_acc: 0.9724 Epoch 26/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0805 - acc: 0.9755 - val_loss: 0.0937 - val_acc: 0.9721 Epoch 27/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0795 - acc: 0.9759 - val_loss: 0.0930 - val_acc: 0.9721 Epoch 28/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0786 - acc: 0.9765 - val_loss: 0.0931 - val_acc: 0.9721 Epoch 29/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0780 - acc: 0.9764 - val_loss: 0.0926 - val_acc: 0.9726 Epoch 30/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0759 - acc: 0.9768 - val_loss: 0.0925 - val_acc: 0.9726 Epoch 31/60 60000/60000 [==============================] - 9s 147us/step - loss: 0.0780 - acc: 0.9768 - val_loss: 0.0931 - val_acc: 0.9727 Epoch 32/60 60000/60000 [==============================] - 9s 155us/step - loss: 0.0768 - acc: 0.9765 - val_loss: 0.0925 - val_acc: 0.9726 Epoch 33/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0762 - acc: 0.9770 - val_loss: 0.0927 - val_acc: 0.9723 Epoch 34/60 60000/60000 [==============================] - 9s 149us/step - loss: 0.0765 - acc: 0.9770 - val_loss: 0.0928 - val_acc: 0.9723 Epoch 35/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0751 - acc: 0.9778 - val_loss: 0.0928 - val_acc: 0.9721 Epoch 36/60 60000/60000 [==============================] - 8s 138us/step - loss: 0.0756 - acc: 0.9772 - val_loss: 0.0919 - val_acc: 0.9721 Epoch 37/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0760 - acc: 0.9769 - val_loss: 0.0923 - val_acc: 0.9723 Epoch 38/60 60000/60000 [==============================] - 8s 138us/step - loss: 0.0751 - acc: 0.9772 - val_loss: 0.0921 - val_acc: 0.9726 Epoch 39/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0756 - acc: 0.9774 - val_loss: 0.0924 - val_acc: 0.9728 Epoch 40/60 60000/60000 [==============================] - 8s 141us/step - loss: 0.0750 - acc: 0.9774 - val_loss: 0.0924 - val_acc: 0.9728 Epoch 41/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0760 - acc: 0.9774 - val_loss: 0.0926 - val_acc: 0.9724 Epoch 42/60 60000/60000 [==============================] - 8s 142us/step - loss: 0.0719 - acc: 0.9783 - val_loss: 0.0920 - val_acc: 0.9730 Epoch 43/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0730 - acc: 0.9779 - val_loss: 0.0919 - val_acc: 0.9726 Epoch 44/60 60000/60000 [==============================] - 8s 140us/step - loss: 0.0722 - acc: 0.9785 - val_loss: 0.0920 - val_acc: 0.9728 Epoch 45/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0746 - acc: 0.9774 - val_loss: 0.0923 - val_acc: 0.9730 Epoch 46/60 60000/60000 [==============================] - 9s 148us/step - loss: 0.0736 - acc: 0.9778 - val_loss: 0.0920 - val_acc: 0.9729 Epoch 47/60 60000/60000 [==============================] - 9s 156us/step - loss: 0.0739 - acc: 0.9777 - val_loss: 0.0920 - val_acc: 0.9725 Epoch 48/60 60000/60000 [==============================] - 9s 151us/step - loss: 0.0720 - acc: 0.9783 - val_loss: 0.0917 - val_acc: 0.9731 Epoch 49/60 60000/60000 [==============================] - 9s 146us/step - loss: 0.0735 - acc: 0.9780 - val_loss: 0.0917 - val_acc: 0.9729 Epoch 50/60 60000/60000 [==============================] - 9s 152us/step - loss: 0.0729 - acc: 0.9780 - val_loss: 0.0923 - val_acc: 0.9723 Epoch 51/60 60000/60000 [==============================] - 9s 151us/step - loss: 0.0716 - acc: 0.9777 - val_loss: 0.0919 - val_acc: 0.9727 Epoch 52/60 60000/60000 [==============================] - 9s 145us/step - loss: 0.0716 - acc: 0.9784 - val_loss: 0.0915 - val_acc: 0.9726 Epoch 53/60 60000/60000 [==============================] - 9s 149us/step - loss: 0.0715 - acc: 0.9782 - val_loss: 0.0912 - val_acc: 0.9722 Epoch 54/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0704 - acc: 0.9786 - val_loss: 0.0911 - val_acc: 0.9720 Epoch 55/60 60000/60000 [==============================] - 9s 142us/step - loss: 0.0721 - acc: 0.9782 - val_loss: 0.0917 - val_acc: 0.9727 Epoch 56/60 60000/60000 [==============================] - 9s 143us/step - loss: 0.0717 - acc: 0.9784 - val_loss: 0.0918 - val_acc: 0.9725 Epoch 57/60 60000/60000 [==============================] - 9s 151us/step - loss: 0.0717 - acc: 0.9783 - val_loss: 0.0918 - val_acc: 0.9726 Epoch 58/60 60000/60000 [==============================] - 9s 144us/step - loss: 0.0708 - acc: 0.9783 - val_loss: 0.0916 - val_acc: 0.9725 Epoch 59/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.0703 - acc: 0.9782 - val_loss: 0.0916 - val_acc: 0.9731 Epoch 60/60 60000/60000 [==============================] - 8s 137us/step - loss: 0.0703 - acc: 0.9785 - val_loss: 0.0918 - val_acc: 0.9727 CPU times: user 15min 16s, sys: 3min 41s, total: 18min 57s Wall time: 8min 37s In [26]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [27]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Exercise 1: Apply a custon learning rate change using LearningRateScheduler Write a function that performs the exponential learning rate decay as indicated by the following formula: \\begin{align} lr = lr0 * e&#94;{(-kt)} \\textrm{} \\end{align} In [28]: # your code here In [29]: # solution epochs = 60 learning_rate = 0.1 # initial learning rate decay_rate = 0.1 momentum = 0.8 # define the optimizer function sgd = SGD ( lr = learning_rate , momentum = momentum , decay = decay_rate , nesterov = False ) In [30]: input_dim = x_train . shape [ 1 ] num_classes = 10 batch_size = 196 # build the model exponential_decay_model = Sequential () exponential_decay_model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) exponential_decay_model . add ( Dropout ( 0.1 )) exponential_decay_model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) exponential_decay_model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) # compile the model exponential_decay_model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'acc' ]) In [31]: # define the learning rate change def exp_decay ( epoch ): lrate = learning_rate * np . exp ( - decay_rate * epoch ) return lrate In [32]: # learning schedule callback loss_history = History () lr_rate = LearningRateScheduler ( exp_decay ) callbacks_list = [ loss_history , lr_rate ] # you invoke the LearningRateScheduler during the .fit() phase exponential_decay_model_history = exponential_decay_model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , callbacks = callbacks_list , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 1s 16us/step - loss: 1.9924 - acc: 0.3865 - val_loss: 1.4953 - val_acc: 0.5841 Epoch 2/60 60000/60000 [==============================] - 1s 11us/step - loss: 1.2430 - acc: 0.6362 - val_loss: 1.0153 - val_acc: 0.7164 Epoch 3/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.9789 - acc: 0.7141 - val_loss: 0.8601 - val_acc: 0.7617 Epoch 4/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.8710 - acc: 0.7452 - val_loss: 0.7811 - val_acc: 0.7865 Epoch 5/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.8115 - acc: 0.7609 - val_loss: 0.7336 - val_acc: 0.7968 Epoch 6/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7749 - acc: 0.7678 - val_loss: 0.7030 - val_acc: 0.8035 Epoch 7/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7524 - acc: 0.7742 - val_loss: 0.6822 - val_acc: 0.8095 Epoch 8/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7342 - acc: 0.7788 - val_loss: 0.6673 - val_acc: 0.8122 Epoch 9/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7218 - acc: 0.7840 - val_loss: 0.6562 - val_acc: 0.8148 Epoch 10/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7144 - acc: 0.7836 - val_loss: 0.6475 - val_acc: 0.8168 Epoch 11/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7054 - acc: 0.7857 - val_loss: 0.6408 - val_acc: 0.8175 Epoch 12/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.7008 - acc: 0.7896 - val_loss: 0.6354 - val_acc: 0.8185 Epoch 13/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6950 - acc: 0.7885 - val_loss: 0.6311 - val_acc: 0.8197 Epoch 14/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6921 - acc: 0.7895 - val_loss: 0.6274 - val_acc: 0.8199 Epoch 15/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6888 - acc: 0.7913 - val_loss: 0.6244 - val_acc: 0.8204 Epoch 16/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6833 - acc: 0.7932 - val_loss: 0.6219 - val_acc: 0.8206 Epoch 17/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6831 - acc: 0.7942 - val_loss: 0.6199 - val_acc: 0.8208 Epoch 18/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6822 - acc: 0.7937 - val_loss: 0.6182 - val_acc: 0.8212 Epoch 19/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6790 - acc: 0.7955 - val_loss: 0.6167 - val_acc: 0.8215 Epoch 20/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6797 - acc: 0.7935 - val_loss: 0.6155 - val_acc: 0.8218 Epoch 21/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6773 - acc: 0.7953 - val_loss: 0.6144 - val_acc: 0.8222 Epoch 22/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6742 - acc: 0.7960 - val_loss: 0.6135 - val_acc: 0.8227 Epoch 23/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6746 - acc: 0.7958 - val_loss: 0.6127 - val_acc: 0.8236 Epoch 24/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6729 - acc: 0.7973 - val_loss: 0.6120 - val_acc: 0.8237 Epoch 25/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6749 - acc: 0.7963 - val_loss: 0.6114 - val_acc: 0.8238 Epoch 26/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6715 - acc: 0.7967 - val_loss: 0.6109 - val_acc: 0.8241 Epoch 27/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6728 - acc: 0.7975 - val_loss: 0.6105 - val_acc: 0.8241 Epoch 28/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6721 - acc: 0.7964 - val_loss: 0.6101 - val_acc: 0.8246 Epoch 29/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6707 - acc: 0.7972 - val_loss: 0.6098 - val_acc: 0.8247 Epoch 30/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6711 - acc: 0.7980 - val_loss: 0.6095 - val_acc: 0.8247 Epoch 31/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6721 - acc: 0.7960 - val_loss: 0.6092 - val_acc: 0.8248 Epoch 32/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6708 - acc: 0.7981 - val_loss: 0.6090 - val_acc: 0.8249 Epoch 33/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6720 - acc: 0.7968 - val_loss: 0.6088 - val_acc: 0.8249 Epoch 34/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6700 - acc: 0.7973 - val_loss: 0.6086 - val_acc: 0.8250 Epoch 35/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6714 - acc: 0.7979 - val_loss: 0.6084 - val_acc: 0.8250 Epoch 36/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6687 - acc: 0.7980 - val_loss: 0.6083 - val_acc: 0.8250 Epoch 37/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6700 - acc: 0.7963 - val_loss: 0.6082 - val_acc: 0.8250 Epoch 38/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6702 - acc: 0.7964 - val_loss: 0.6081 - val_acc: 0.8252 Epoch 39/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6711 - acc: 0.7963 - val_loss: 0.6080 - val_acc: 0.8250 Epoch 40/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6698 - acc: 0.7971 - val_loss: 0.6079 - val_acc: 0.8251 Epoch 41/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6696 - acc: 0.7967 - val_loss: 0.6079 - val_acc: 0.8252 Epoch 42/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6699 - acc: 0.7989 - val_loss: 0.6078 - val_acc: 0.8252 Epoch 43/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6701 - acc: 0.7952 - val_loss: 0.6077 - val_acc: 0.8252 Epoch 44/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6704 - acc: 0.7973 - val_loss: 0.6077 - val_acc: 0.8252 Epoch 45/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6697 - acc: 0.7971 - val_loss: 0.6076 - val_acc: 0.8252 Epoch 46/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6718 - acc: 0.7969 - val_loss: 0.6076 - val_acc: 0.8252 Epoch 47/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6708 - acc: 0.7965 - val_loss: 0.6076 - val_acc: 0.8252 Epoch 48/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6690 - acc: 0.7968 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 49/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6700 - acc: 0.7959 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 50/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6722 - acc: 0.7963 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 51/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6698 - acc: 0.7950 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 52/60 60000/60000 [==============================] - 1s 12us/step - loss: 0.6689 - acc: 0.7978 - val_loss: 0.6075 - val_acc: 0.8252 Epoch 53/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6696 - acc: 0.7973 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 54/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6678 - acc: 0.7975 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 55/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6694 - acc: 0.7969 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 56/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6688 - acc: 0.7981 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 57/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6674 - acc: 0.7988 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 58/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6685 - acc: 0.7970 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 59/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6702 - acc: 0.7953 - val_loss: 0.6074 - val_acc: 0.8252 Epoch 60/60 60000/60000 [==============================] - 1s 11us/step - loss: 0.6701 - acc: 0.7965 - val_loss: 0.6074 - val_acc: 0.8252 In [33]: # check on the variables that can show me the learning rate decay exponential_decay_model_history . history . keys () Out[33]: dict_keys(['val_loss', 'val_acc', 'loss', 'acc', 'lr']) In [34]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( exponential_decay_model_history . history [ 'lr' ] , 'r' ) #, label='learn rate') ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Learning Rate' , fontsize = 20 ) #ax.legend() ax . tick_params ( labelsize = 20 ) In [35]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( exponential_decay_model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( exponential_decay_model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Step 3 - Choosing an optimizer and a loss function When constructing a model and using it to make our predictions, for example to assign label scores to images (\"cat\", \"plane\", etc), we want to measure our success or failure by defining a \"loss\" function (or objective function). The goal of optimization is to efficiently calculate the parameters/weights that minimize this loss function. keras provides various types of loss functions . Sometimes the \"loss\" function measures the \"distance\". We can define this \"distance\" between two data points in various ways suitable to the problem or dataset. Distance Euclidean Manhattan others such as Hamming which measures distances between strings, for example. The Hamming distance of \"carolin\" and \"cathrin\" is 3. Loss functions MSE (for regression) categorical cross-entropy (for classification) binary cross entropy (for classification) In [40]: # build the model input_dim = x_train . shape [ 1 ] model = Sequential () model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) # fully-connected layer with 64 hidden units model . add ( Dropout ( 0.1 )) model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) In [41]: # defining the parameters for RMSprop (I used the keras defaults here) rms = RMSprop ( lr = 0.001 , rho = 0.9 , epsilon = None , decay = 0.0 ) model . compile ( loss = 'categorical_crossentropy' , optimizer = rms , metrics = [ 'acc' ]) Step 4 - Deciding on the batch size and number of epochs In [42]: %%time batch_size = input_dim epochs = 60 model_history = model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 1s 14us/step - loss: 1.1320 - acc: 0.7067 - val_loss: 0.5628 - val_acc: 0.8237 Epoch 2/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.4831 - acc: 0.8570 - val_loss: 0.3674 - val_acc: 0.8934 Epoch 3/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.3665 - acc: 0.8931 - val_loss: 0.3199 - val_acc: 0.9061 Epoch 4/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.3100 - acc: 0.9092 - val_loss: 0.2664 - val_acc: 0.9233 Epoch 5/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.2699 - acc: 0.9206 - val_loss: 0.2295 - val_acc: 0.9326 Epoch 6/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.2391 - acc: 0.9305 - val_loss: 0.2104 - val_acc: 0.9362 Epoch 7/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.2115 - acc: 0.9383 - val_loss: 0.1864 - val_acc: 0.9459 Epoch 8/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.1900 - acc: 0.9451 - val_loss: 0.1658 - val_acc: 0.9493 Epoch 9/60 60000/60000 [==============================] - 1s 9us/step - loss: 0.1714 - acc: 0.9492 - val_loss: 0.1497 - val_acc: 0.9538 Epoch 10/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1565 - acc: 0.9539 - val_loss: 0.1404 - val_acc: 0.9591 Epoch 11/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1443 - acc: 0.9569 - val_loss: 0.1305 - val_acc: 0.9616 Epoch 12/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1334 - acc: 0.9596 - val_loss: 0.1224 - val_acc: 0.9628 Epoch 13/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1257 - acc: 0.9627 - val_loss: 0.1133 - val_acc: 0.9660 Epoch 14/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1169 - acc: 0.9652 - val_loss: 0.1116 - val_acc: 0.9674 Epoch 15/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1091 - acc: 0.9675 - val_loss: 0.1104 - val_acc: 0.9670 Epoch 16/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.1051 - acc: 0.9689 - val_loss: 0.1030 - val_acc: 0.9692 Epoch 17/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0978 - acc: 0.9697 - val_loss: 0.1044 - val_acc: 0.9686 Epoch 18/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0929 - acc: 0.9718 - val_loss: 0.0996 - val_acc: 0.9689 Epoch 19/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0882 - acc: 0.9738 - val_loss: 0.1035 - val_acc: 0.9695 Epoch 20/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0850 - acc: 0.9737 - val_loss: 0.0941 - val_acc: 0.9717 Epoch 21/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0803 - acc: 0.9751 - val_loss: 0.0953 - val_acc: 0.9715 Epoch 22/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0793 - acc: 0.9762 - val_loss: 0.0898 - val_acc: 0.9729 Epoch 23/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0747 - acc: 0.9775 - val_loss: 0.0901 - val_acc: 0.9732 Epoch 24/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0718 - acc: 0.9778 - val_loss: 0.0948 - val_acc: 0.9720 Epoch 25/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0697 - acc: 0.9781 - val_loss: 0.0908 - val_acc: 0.9727 Epoch 26/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0668 - acc: 0.9794 - val_loss: 0.0917 - val_acc: 0.9726 Epoch 27/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0648 - acc: 0.9800 - val_loss: 0.0895 - val_acc: 0.9737 Epoch 28/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0637 - acc: 0.9798 - val_loss: 0.0868 - val_acc: 0.9728 Epoch 29/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0598 - acc: 0.9813 - val_loss: 0.0883 - val_acc: 0.9736 Epoch 30/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0570 - acc: 0.9820 - val_loss: 0.0869 - val_acc: 0.9741 Epoch 31/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0555 - acc: 0.9825 - val_loss: 0.0896 - val_acc: 0.9732 Epoch 32/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0554 - acc: 0.9827 - val_loss: 0.0843 - val_acc: 0.9743 Epoch 33/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0512 - acc: 0.9836 - val_loss: 0.0843 - val_acc: 0.9746 Epoch 34/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0509 - acc: 0.9835 - val_loss: 0.0868 - val_acc: 0.9753 Epoch 35/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0491 - acc: 0.9842 - val_loss: 0.0841 - val_acc: 0.9755 Epoch 36/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0471 - acc: 0.9848 - val_loss: 0.0887 - val_acc: 0.9728 Epoch 37/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0466 - acc: 0.9850 - val_loss: 0.0876 - val_acc: 0.9756 Epoch 38/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0456 - acc: 0.9856 - val_loss: 0.0833 - val_acc: 0.9769 Epoch 39/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0431 - acc: 0.9866 - val_loss: 0.0869 - val_acc: 0.9759 Epoch 40/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0413 - acc: 0.9869 - val_loss: 0.0926 - val_acc: 0.9743 Epoch 41/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0401 - acc: 0.9872 - val_loss: 0.0851 - val_acc: 0.9756 Epoch 42/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0401 - acc: 0.9876 - val_loss: 0.0856 - val_acc: 0.9764 Epoch 43/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0392 - acc: 0.9870 - val_loss: 0.0861 - val_acc: 0.9771 Epoch 44/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0396 - acc: 0.9870 - val_loss: 0.0918 - val_acc: 0.9756 Epoch 45/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0371 - acc: 0.9883 - val_loss: 0.0866 - val_acc: 0.9766 Epoch 46/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0374 - acc: 0.9883 - val_loss: 0.0888 - val_acc: 0.9748 Epoch 47/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0376 - acc: 0.9878 - val_loss: 0.0850 - val_acc: 0.9761 Epoch 48/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0351 - acc: 0.9890 - val_loss: 0.0848 - val_acc: 0.9777 Epoch 49/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0361 - acc: 0.9884 - val_loss: 0.0850 - val_acc: 0.9771 Epoch 50/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0341 - acc: 0.9887 - val_loss: 0.0889 - val_acc: 0.9769 Epoch 51/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.9897 - val_loss: 0.0882 - val_acc: 0.9771 Epoch 52/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0322 - acc: 0.9895 - val_loss: 0.0892 - val_acc: 0.9762 Epoch 53/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0313 - acc: 0.9892 - val_loss: 0.0916 - val_acc: 0.9771 Epoch 54/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0300 - acc: 0.9897 - val_loss: 0.0913 - val_acc: 0.9772 Epoch 55/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0306 - acc: 0.9902 - val_loss: 0.0904 - val_acc: 0.9763 Epoch 56/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0307 - acc: 0.9900 - val_loss: 0.0910 - val_acc: 0.9777 Epoch 57/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0918 - val_acc: 0.9763 Epoch 58/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0914 - val_acc: 0.9778 Epoch 59/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0284 - acc: 0.9909 - val_loss: 0.0907 - val_acc: 0.9769 Epoch 60/60 60000/60000 [==============================] - 0s 8us/step - loss: 0.0283 - acc: 0.9908 - val_loss: 0.0962 - val_acc: 0.9761 CPU times: user 1min 17s, sys: 7.4 s, total: 1min 24s Wall time: 29.3 s In [43]: score = model . evaluate ( x_test , y_test , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) Test loss: 0.09620895183624088 Test accuracy: 0.9761 In [44]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'acc' ]), 'r' , label = 'train_acc' ) ax . plot ( np . sqrt ( model_history . history [ 'val_acc' ]), 'b' , label = 'val_acc' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [45]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Step 5 - Random restarts This method does not seem to have an implementation in keras . We will leave it as a home exercise! Hint: you can use keras.callbacks.LearningRateScheduler . See how we used it to set a custom learning rate. Tuning the Hyperparameters using Cross Validation Now instead of trying different values by hand, we will use GridSearchCV from Scikit-Learn to try out several values for our hyperparameters and compare the results. To do cross-validation with keras we will use the wrappers for the Scikit-Learn API. They provide a way to use Sequential Keras models (single-input only) as part of your Scikit-Learn workflow. There are two wrappers available: keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params) , which implements the Scikit-Learn classifier interface, keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params) , which implements the Scikit-Learn regressor interface. In [46]: import numpy from sklearn.model_selection import GridSearchCV from keras.wrappers.scikit_learn import KerasClassifier Trying different weight initializations In [47]: # let's create a function that creates the model (required for KerasClassifier) # while accepting the hyperparameters we want to tune # we also pass some default values such as optimizer='rmsprop' def create_model ( init_mode = 'uniform' ): # define model model = Sequential () model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu , input_dim = 784 )) model . add ( Dropout ( 0.1 )) model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu )) model . add ( Dense ( 10 , kernel_initializer = init_mode , activation = tf . nn . softmax )) # compile model model . compile ( loss = 'categorical_crossentropy' , optimizer = RMSprop (), metrics = [ 'accuracy' ]) return model In [49]: %%time seed = 7 numpy . random . seed ( seed ) batch_size = 128 epochs = 10 model_CV = KerasClassifier ( build_fn = create_model , epochs = epochs , batch_size = batch_size , verbose = 1 ) # define the grid search parameters init_mode = [ 'uniform' , 'lecun_uniform' , 'normal' , 'zero' , 'glorot_normal' , 'glorot_uniform' , 'he_normal' , 'he_uniform' ] param_grid = dict ( init_mode = init_mode ) grid = GridSearchCV ( estimator = model_CV , param_grid = param_grid , n_jobs =- 1 , cv = 3 ) grid_result = grid . fit ( x_train , y_train ) Epoch 1/10 60000/60000 [==============================] - 1s 21us/step - loss: 0.4118 - acc: 0.8824 Epoch 2/10 60000/60000 [==============================] - 1s 15us/step - loss: 0.1936 - acc: 0.9437 Epoch 3/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.1482 - acc: 0.9553 Epoch 4/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.1225 - acc: 0.9631 Epoch 5/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.1064 - acc: 0.9676 Epoch 6/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.0944 - acc: 0.9710 Epoch 7/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.0876 - acc: 0.9732 Epoch 8/10 60000/60000 [==============================] - 1s 15us/step - loss: 0.0809 - acc: 0.9745 Epoch 9/10 60000/60000 [==============================] - 1s 14us/step - loss: 0.0741 - acc: 0.9775 Epoch 10/10 60000/60000 [==============================] - 1s 15us/step - loss: 0.0709 - acc: 0.9783 CPU times: user 21 s, sys: 3.56 s, total: 24.5 s Wall time: 1min 20s In [50]: # print results print ( f 'Best Accuracy for {grid_result.best_score_} using {grid_result.best_params_} ' ) means = grid_result . cv_results_ [ 'mean_test_score' ] stds = grid_result . cv_results_ [ 'std_test_score' ] params = grid_result . cv_results_ [ 'params' ] for mean , stdev , param in zip ( means , stds , params ): print ( f ' mean= {mean:.4} , std= {stdev:.4} using {param} ' ) Best Accuracy for 0.9689333333333333 using {'init_mode': 'lecun_uniform'} mean=0.9647, std=0.001438 using {'init_mode': 'uniform'} mean=0.9689, std=0.001044 using {'init_mode': 'lecun_uniform'} mean=0.9651, std=0.001515 using {'init_mode': 'normal'} mean=0.1124, std=0.002416 using {'init_mode': 'zero'} mean=0.9657, std=0.0005104 using {'init_mode': 'glorot_normal'} mean=0.9687, std=0.0008436 using {'init_mode': 'glorot_uniform'} mean=0.9681, std=0.002145 using {'init_mode': 'he_normal'} mean=0.9685, std=0.001952 using {'init_mode': 'he_uniform'} Save Your Neural Network Model to JSON The Hierarchical Data Format (HDF5) is a data storage format for storing large arrays of data including values for the weights in a neural network. You can install HDF5 Python module: pip install h5py Keras gives you the ability to describe and save any model using the JSON format. In [51]: from keras.models import model_from_json # serialize model to JSON model_json = model . to_json () with open ( \"model.json\" , \"w\" ) as json_file : json_file . write ( model_json ) # save weights to HDF5 model . save_weights ( \"model.h5\" ) print ( \"Model saved\" ) # when you want to retrieve the model: load json and create model json_file = open ( 'model.json' , 'r' ) saved_model = json_file . read () # close the file as good practice json_file . close () model_from_json = model_from_json ( saved_model ) # load weights into new model model_from_json . load_weights ( \"model.h5\" ) print ( \"Model loaded\" ) Model saved Model loaded Exercise 2: Cross-validation with more than one hyperparameters We can do cross-validation with more than one parameters simultaneously, effectively trying out combinations of them. Note: Cross-validation in neural networks is computationally expensive . Think before you experiment! Multiply the number of features you are validating on to see how many combinations there are. Each combination is evaluated using the cv-fold cross-validation (cv is a parameter we choose). For example, we can choose to search for different values of: batch size, number of epochs and initialization mode. The choises are specifed into a dictionary and passed to GridSearchCV. Perform a GridSearch for batch size , number of epochs and initializer combined. In [52]: #your code here In [53]: # solutions # repeat some of the initial values here so we make sure they were not changed input_dim = x_train . shape [ 1 ] num_classes = 10 # let's create a function that creates the model (required for KerasClassifier) # while accepting the hyperparameters we want to tune # we also pass some default values such as optimizer='rmsprop' def create_model_2 ( optimizer = 'rmsprop' , init = 'glorot_uniform' ): model = Sequential () model . add ( Dense ( 64 , input_dim = input_dim , kernel_initializer = init , activation = 'relu' )) model . add ( Dropout ( 0.1 )) model . add ( Dense ( 64 , kernel_initializer = init , activation = tf . nn . relu )) model . add ( Dense ( num_classes , kernel_initializer = init , activation = tf . nn . softmax )) # compile model model . compile ( loss = 'categorical_crossentropy' , optimizer = optimizer , metrics = [ 'accuracy' ]) return model In [54]: %%time # fix random seed for reproducibility (this might work or might not work # depending on each library's implenentation) seed = 7 numpy . random . seed ( seed ) # create the sklearn model for the network model_init_batch_epoch_CV = KerasClassifier ( build_fn = create_model_2 , verbose = 1 ) # we choose the initializers that came at the top in our previous cross-validation!! init_mode = [ 'glorot_uniform' , 'uniform' ] batches = [ 128 , 512 ] epochs = [ 10 , 20 ] # grid search for initializer, batch size and number of epochs param_grid = dict ( epochs = epochs , batch_size = batches , init = init_mode ) grid = GridSearchCV ( estimator = model_init_batch_epoch_CV , param_grid = param_grid , cv = 3 ) grid_result = grid . fit ( x_train , y_train ) Epoch 1/10 40000/40000 [==============================] - 1s 21us/step - loss: 0.4801 - acc: 0.8601 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2309 - acc: 0.9310 Epoch 3/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.1744 - acc: 0.9479 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1422 - acc: 0.9575 Epoch 5/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.1214 - acc: 0.9625 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1081 - acc: 0.9675 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0974 - acc: 0.9693 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0874 - acc: 0.9730 Epoch 9/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0800 - acc: 0.9750 Epoch 10/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0750 - acc: 0.9765 20000/20000 [==============================] - 0s 10us/step 40000/40000 [==============================] - 0s 6us/step Epoch 1/10 40000/40000 [==============================] - 1s 22us/step - loss: 0.4746 - acc: 0.8656 Epoch 2/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.2264 - acc: 0.9336 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1734 - acc: 0.9487 Epoch 4/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.1436 - acc: 0.9568 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1256 - acc: 0.9614 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1104 - acc: 0.9660 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0973 - acc: 0.9707 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0870 - acc: 0.9733 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0818 - acc: 0.9748 Epoch 10/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0730 - acc: 0.9770 20000/20000 [==============================] - 0s 10us/step 40000/40000 [==============================] - 0s 6us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 0.4639 - acc: 0.8671 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2208 - acc: 0.9344 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1693 - acc: 0.9491 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1388 - acc: 0.9580 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1206 - acc: 0.9634 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1062 - acc: 0.9678 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0956 - acc: 0.9711 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0870 - acc: 0.9728 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0794 - acc: 0.9750 Epoch 10/10 40000/40000 [==============================] - 1s 14us/step - loss: 0.0748 - acc: 0.9774 20000/20000 [==============================] - 0s 11us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 0.7144 - acc: 0.7894 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.3246 - acc: 0.9045 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2482 - acc: 0.9268 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2005 - acc: 0.9407 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1673 - acc: 0.9485 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1462 - acc: 0.9559 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1305 - acc: 0.9604 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1166 - acc: 0.9643 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1079 - acc: 0.9675 Epoch 10/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0983 - acc: 0.9695 20000/20000 [==============================] - 0s 12us/step 40000/40000 [==============================] - 0s 6us/step Epoch 1/10 40000/40000 [==============================] - 1s 24us/step - loss: 0.6894 - acc: 0.7944 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.3171 - acc: 0.9061 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2358 - acc: 0.9312 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1911 - acc: 0.9422 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1595 - acc: 0.9526 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1401 - acc: 0.9579 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1230 - acc: 0.9636 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1096 - acc: 0.9672 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1027 - acc: 0.9692 Epoch 10/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0936 - acc: 0.9718 20000/20000 [==============================] - 0s 12us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/10 40000/40000 [==============================] - 1s 24us/step - loss: 0.7028 - acc: 0.7976 Epoch 2/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.3189 - acc: 0.9055 Epoch 3/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.2390 - acc: 0.9307 Epoch 4/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1910 - acc: 0.9435 Epoch 5/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1595 - acc: 0.9528 Epoch 6/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1376 - acc: 0.9583 Epoch 7/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1213 - acc: 0.9629 Epoch 8/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.1100 - acc: 0.9664 Epoch 9/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0987 - acc: 0.9697 Epoch 10/10 40000/40000 [==============================] - 1s 15us/step - loss: 0.0932 - acc: 0.9714 20000/20000 [==============================] - 0s 13us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 25us/step - loss: 0.4938 - acc: 0.8589 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2286 - acc: 0.9324 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1751 - acc: 0.9470 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1458 - acc: 0.9553 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1237 - acc: 0.9620 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1106 - acc: 0.9669 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0998 - acc: 0.9696 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0898 - acc: 0.9729 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0799 - acc: 0.9749 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0746 - acc: 0.9769 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0688 - acc: 0.9783 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0655 - acc: 0.9792 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0619 - acc: 0.9801 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0574 - acc: 0.9814 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0549 - acc: 0.9836 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0512 - acc: 0.9837 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0464 - acc: 0.9855 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0466 - acc: 0.9850 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0431 - acc: 0.9863 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0430 - acc: 0.9861 20000/20000 [==============================] - 0s 13us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 25us/step - loss: 0.4956 - acc: 0.8584 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2286 - acc: 0.9321 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1746 - acc: 0.9474 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1438 - acc: 0.9574 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1232 - acc: 0.9634 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1104 - acc: 0.9665 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0986 - acc: 0.9696 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0886 - acc: 0.9723 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0828 - acc: 0.9741 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0763 - acc: 0.9768 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0679 - acc: 0.9781 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0656 - acc: 0.9788 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0601 - acc: 0.9810 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0571 - acc: 0.9817 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0517 - acc: 0.9832 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0509 - acc: 0.9834 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0478 - acc: 0.9850 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0461 - acc: 0.9852 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0442 - acc: 0.9854 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0427 - acc: 0.9866 20000/20000 [==============================] - 0s 14us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.4694 - acc: 0.8670 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2196 - acc: 0.9336 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1681 - acc: 0.9495 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1391 - acc: 0.9589 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1200 - acc: 0.9630 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1067 - acc: 0.9671 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0968 - acc: 0.9713 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0880 - acc: 0.9730 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0815 - acc: 0.9754 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0742 - acc: 0.9771 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0711 - acc: 0.9778 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0643 - acc: 0.9806 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9815 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0561 - acc: 0.9818 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0534 - acc: 0.9832 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0528 - acc: 0.9832 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0479 - acc: 0.9848 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0486 - acc: 0.9844 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0438 - acc: 0.9861 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0427 - acc: 0.9861 20000/20000 [==============================] - 0s 14us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.6830 - acc: 0.8003 Epoch 2/20 40000/40000 [==============================] - 1s 16us/step - loss: 0.3234 - acc: 0.9044 Epoch 3/20 40000/40000 [==============================] - 1s 16us/step - loss: 0.2456 - acc: 0.9269 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1982 - acc: 0.9407 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1627 - acc: 0.9506 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1422 - acc: 0.9561 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1251 - acc: 0.9618 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1134 - acc: 0.9650 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1037 - acc: 0.9677 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0957 - acc: 0.9705 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0891 - acc: 0.9730 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0832 - acc: 0.9745 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0760 - acc: 0.9768 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0727 - acc: 0.9778 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0681 - acc: 0.9782 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0628 - acc: 0.9803 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0613 - acc: 0.9801 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0572 - acc: 0.9824 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0549 - acc: 0.9821 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0521 - acc: 0.9834 20000/20000 [==============================] - 0s 15us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 28us/step - loss: 0.6742 - acc: 0.8034 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.3142 - acc: 0.9081 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2365 - acc: 0.9306 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1873 - acc: 0.9453 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1563 - acc: 0.9531 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1373 - acc: 0.9580 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1212 - acc: 0.9640 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1084 - acc: 0.9665 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1014 - acc: 0.9695 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0917 - acc: 0.9732 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0838 - acc: 0.9739 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0788 - acc: 0.9749 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0720 - acc: 0.9779 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0685 - acc: 0.9793 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0666 - acc: 0.9797 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0618 - acc: 0.9807 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0578 - acc: 0.9819 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0557 - acc: 0.9825 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0535 - acc: 0.9831 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0482 - acc: 0.9848 20000/20000 [==============================] - 0s 15us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/20 40000/40000 [==============================] - 1s 29us/step - loss: 0.6865 - acc: 0.8001 Epoch 2/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.3089 - acc: 0.9106 Epoch 3/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.2292 - acc: 0.9304 Epoch 4/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1845 - acc: 0.9435 Epoch 5/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1562 - acc: 0.9527 Epoch 6/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1371 - acc: 0.9584 Epoch 7/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1206 - acc: 0.9629 Epoch 8/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.1098 - acc: 0.9667 Epoch 9/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0990 - acc: 0.9699 Epoch 10/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0912 - acc: 0.9718 Epoch 11/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0863 - acc: 0.9740 Epoch 12/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0792 - acc: 0.9757 Epoch 13/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0721 - acc: 0.9782 Epoch 14/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0696 - acc: 0.9782 Epoch 15/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0661 - acc: 0.9796 Epoch 16/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0621 - acc: 0.9810 Epoch 17/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0588 - acc: 0.9813 Epoch 18/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0541 - acc: 0.9831 Epoch 19/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0513 - acc: 0.9834 Epoch 20/20 40000/40000 [==============================] - 1s 15us/step - loss: 0.0514 - acc: 0.9835 20000/20000 [==============================] - 0s 16us/step 40000/40000 [==============================] - 0s 7us/step Epoch 1/10 40000/40000 [==============================] - 1s 22us/step - loss: 0.7656 - acc: 0.7926 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3345 - acc: 0.9021 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2633 - acc: 0.9225 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2207 - acc: 0.9357 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1877 - acc: 0.9450 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1684 - acc: 0.9500 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1517 - acc: 0.9552 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1358 - acc: 0.9587 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1236 - acc: 0.9627 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1153 - acc: 0.9661 20000/20000 [==============================] - 0s 14us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 22us/step - loss: 0.7640 - acc: 0.7905 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3207 - acc: 0.9055 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2455 - acc: 0.9276 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2050 - acc: 0.9392 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1755 - acc: 0.9484 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1573 - acc: 0.9524 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1385 - acc: 0.9594 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1247 - acc: 0.9634 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1181 - acc: 0.9644 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1074 - acc: 0.9679 20000/20000 [==============================] - 0s 15us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 0.7858 - acc: 0.7867 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3358 - acc: 0.9017 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2603 - acc: 0.9250 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2160 - acc: 0.9367 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1879 - acc: 0.9435 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1663 - acc: 0.9513 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1493 - acc: 0.9552 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1363 - acc: 0.9591 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1262 - acc: 0.9609 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1147 - acc: 0.9653 20000/20000 [==============================] - 0s 16us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 23us/step - loss: 1.1193 - acc: 0.6932 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.4829 - acc: 0.8573 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3785 - acc: 0.8885 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3208 - acc: 0.9062 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2811 - acc: 0.9167 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2472 - acc: 0.9263 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2200 - acc: 0.9362 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1963 - acc: 0.9422 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1772 - acc: 0.9475 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1611 - acc: 0.9519 20000/20000 [==============================] - 0s 16us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 24us/step - loss: 1.1189 - acc: 0.6828 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.4867 - acc: 0.8556 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3713 - acc: 0.8919 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3125 - acc: 0.9090 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2748 - acc: 0.9214 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2443 - acc: 0.9285 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2141 - acc: 0.9383 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1919 - acc: 0.9445 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1767 - acc: 0.9485 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1617 - acc: 0.9528 20000/20000 [==============================] - 0s 17us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/10 40000/40000 [==============================] - 1s 25us/step - loss: 1.0997 - acc: 0.7128 Epoch 2/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.4652 - acc: 0.8638 Epoch 3/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3716 - acc: 0.8919 Epoch 4/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.3165 - acc: 0.9072 Epoch 5/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2735 - acc: 0.9199 Epoch 6/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2381 - acc: 0.9299 Epoch 7/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.2094 - acc: 0.9380 Epoch 8/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1863 - acc: 0.9442 Epoch 9/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1693 - acc: 0.9491 Epoch 10/10 40000/40000 [==============================] - 0s 8us/step - loss: 0.1549 - acc: 0.9538 20000/20000 [==============================] - 0s 17us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 26us/step - loss: 0.7406 - acc: 0.7936 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3331 - acc: 0.9019 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2623 - acc: 0.9229 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2174 - acc: 0.9372 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1876 - acc: 0.9436 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1659 - acc: 0.9498 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1493 - acc: 0.9559 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1358 - acc: 0.9602 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1244 - acc: 0.9624 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1135 - acc: 0.9655 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1063 - acc: 0.9683 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0963 - acc: 0.9711 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0924 - acc: 0.9720 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0897 - acc: 0.9732 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0811 - acc: 0.9752 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0798 - acc: 0.9750 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0733 - acc: 0.9770 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0695 - acc: 0.9789 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0652 - acc: 0.9798 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0622 - acc: 0.9815 20000/20000 [==============================] - 0s 18us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.7349 - acc: 0.8012 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3201 - acc: 0.9060 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2541 - acc: 0.9257 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2149 - acc: 0.9375 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1894 - acc: 0.9443 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1694 - acc: 0.9496 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1552 - acc: 0.9541 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1421 - acc: 0.9580 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1307 - acc: 0.9605 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1200 - acc: 0.9642 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1110 - acc: 0.9663 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1041 - acc: 0.9681 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0971 - acc: 0.9698 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0943 - acc: 0.9713 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0864 - acc: 0.9733 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0809 - acc: 0.9748 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0776 - acc: 0.9762 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0745 - acc: 0.9762 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0712 - acc: 0.9777 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0654 - acc: 0.9793 20000/20000 [==============================] - 0s 18us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 27us/step - loss: 0.7435 - acc: 0.8001 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3335 - acc: 0.9029 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2555 - acc: 0.9254 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2168 - acc: 0.9359 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1872 - acc: 0.9458 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1640 - acc: 0.9514 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1452 - acc: 0.9578 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1313 - acc: 0.9607 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1193 - acc: 0.9644 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1104 - acc: 0.9670 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1024 - acc: 0.9691 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0955 - acc: 0.9715 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0881 - acc: 0.9734 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0815 - acc: 0.9756 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0772 - acc: 0.9764 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0745 - acc: 0.9780 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0681 - acc: 0.9788 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0649 - acc: 0.9806 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0640 - acc: 0.9800 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0604 - acc: 0.9813 20000/20000 [==============================] - 0s 19us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 28us/step - loss: 1.1126 - acc: 0.6943 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.4792 - acc: 0.8568 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3712 - acc: 0.8910 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3155 - acc: 0.9068 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2746 - acc: 0.9196 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2392 - acc: 0.9293 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2126 - acc: 0.9363 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1923 - acc: 0.9437 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1706 - acc: 0.9489 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1591 - acc: 0.9530 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1462 - acc: 0.9560 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1342 - acc: 0.9593 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1272 - acc: 0.9609 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1188 - acc: 0.9639 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1126 - acc: 0.9660 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1072 - acc: 0.9673 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1016 - acc: 0.9692 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0971 - acc: 0.9697 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0901 - acc: 0.9719 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0869 - acc: 0.9729 20000/20000 [==============================] - 0s 19us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 28us/step - loss: 1.0906 - acc: 0.7216 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.4527 - acc: 0.8658 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3559 - acc: 0.8956 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3055 - acc: 0.9109 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2642 - acc: 0.9219 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2333 - acc: 0.9317 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2057 - acc: 0.9386 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1858 - acc: 0.9462 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1674 - acc: 0.9501 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1514 - acc: 0.9548 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1410 - acc: 0.9571 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1303 - acc: 0.9607 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1193 - acc: 0.9643 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1131 - acc: 0.9649 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1054 - acc: 0.9680 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0999 - acc: 0.9696 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0937 - acc: 0.9712 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0895 - acc: 0.9731 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0830 - acc: 0.9758 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0790 - acc: 0.9760 20000/20000 [==============================] - 0s 20us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 40000/40000 [==============================] - 1s 29us/step - loss: 1.1233 - acc: 0.6955 Epoch 2/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.4793 - acc: 0.8588 Epoch 3/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3751 - acc: 0.8898 Epoch 4/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.3203 - acc: 0.9069 Epoch 5/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2760 - acc: 0.9196 Epoch 6/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2422 - acc: 0.9286 Epoch 7/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.2155 - acc: 0.9363 Epoch 8/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1910 - acc: 0.9437 Epoch 9/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1718 - acc: 0.9489 Epoch 10/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1584 - acc: 0.9530 Epoch 11/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1435 - acc: 0.9570 Epoch 12/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1326 - acc: 0.9603 Epoch 13/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1244 - acc: 0.9615 Epoch 14/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1171 - acc: 0.9644 Epoch 15/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1093 - acc: 0.9670 Epoch 16/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.1047 - acc: 0.9692 Epoch 17/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0984 - acc: 0.9698 Epoch 18/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0910 - acc: 0.9720 Epoch 19/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0860 - acc: 0.9734 Epoch 20/20 40000/40000 [==============================] - 0s 8us/step - loss: 0.0827 - acc: 0.9748 20000/20000 [==============================] - 0s 21us/step 40000/40000 [==============================] - 0s 4us/step Epoch 1/20 60000/60000 [==============================] - 2s 31us/step - loss: 0.4007 - acc: 0.8851 Epoch 2/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1892 - acc: 0.9439 Epoch 3/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1432 - acc: 0.9567 Epoch 4/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1185 - acc: 0.9643 Epoch 5/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.1050 - acc: 0.9678 Epoch 6/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0929 - acc: 0.9715 Epoch 7/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0848 - acc: 0.9737 Epoch 8/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0775 - acc: 0.9764 Epoch 9/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0723 - acc: 0.9780 Epoch 10/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0693 - acc: 0.9785 Epoch 11/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0637 - acc: 0.9802 Epoch 12/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0602 - acc: 0.9814 Epoch 13/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0585 - acc: 0.9816 Epoch 14/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0546 - acc: 0.9827 Epoch 15/20 60000/60000 [==============================] - 1s 18us/step - loss: 0.0512 - acc: 0.9834 Epoch 16/20 60000/60000 [==============================] - 1s 18us/step - loss: 0.0501 - acc: 0.9841 Epoch 17/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0481 - acc: 0.9844 Epoch 18/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0456 - acc: 0.9860 Epoch 19/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0444 - acc: 0.9857 Epoch 20/20 60000/60000 [==============================] - 1s 17us/step - loss: 0.0439 - acc: 0.9861 CPU times: user 7min 56s, sys: 1min 6s, total: 9min 3s Wall time: 3min 43s In [55]: # print results print ( f 'Best Accuracy for {grid_result.best_score_:.4} using {grid_result.best_params_} ' ) means = grid_result . cv_results_ [ 'mean_test_score' ] stds = grid_result . cv_results_ [ 'std_test_score' ] params = grid_result . cv_results_ [ 'params' ] for mean , stdev , param in zip ( means , stds , params ): print ( f 'mean= {mean:.4} , std= {stdev:.4} using {param} ' ) Best Accuracy for 0.9712 using {'batch_size': 128, 'epochs': 20, 'init': 'glorot_uniform'} mean=0.9687, std=0.002174 using {'batch_size': 128, 'epochs': 10, 'init': 'glorot_uniform'} mean=0.966, std=0.000827 using {'batch_size': 128, 'epochs': 10, 'init': 'uniform'} mean=0.9712, std=0.0006276 using {'batch_size': 128, 'epochs': 20, 'init': 'glorot_uniform'} mean=0.97, std=0.001214 using {'batch_size': 128, 'epochs': 20, 'init': 'uniform'} mean=0.9594, std=0.001476 using {'batch_size': 512, 'epochs': 10, 'init': 'glorot_uniform'} mean=0.9516, std=0.003239 using {'batch_size': 512, 'epochs': 10, 'init': 'uniform'} mean=0.9684, std=0.003607 using {'batch_size': 512, 'epochs': 20, 'init': 'glorot_uniform'} mean=0.9633, std=0.0007962 using {'batch_size': 512, 'epochs': 20, 'init': 'uniform'} if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"pages","url":"pages/lab3/solutions/"},{"title":"Lab 3: Optimization of Neural Networks","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 3: Optimization in Artificial Neural Networks Harvard University Spring 2019 Lab instructor Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals In this lab, we'll explore ways to optimize the loss function of a Multilayer Learning Perceptor (MLP) by tuning the model hyperparameters. We'll also explore the use of cross-validation as a technique for checking potential values for these hyperparameters. By the end of this lab, you should: Be familiar with the use of sklearn 's optimize function. Be able to identify the hyperparameters that go into the training of a MLP. Be familiar with the implementation in keras of various optimization techniques. Apply cross-validation to check for multiple values of hyperparameters. In [2]: import matplotlib.pyplot as plt import numpy as np from scipy.optimize import minimize % matplotlib inline Part 1: Beale's function First let's look at function optimization in scipy.optimize , using Beale's function as an example Optimizing a function $f: A\\rightarrow R$, from some set A to the real numbers is finding an element $x_0\\,\\epsilon\\, A$ such that $f(x_0)\\leq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the minimum) or such that $f(x_0)\\geq f(x)$ for all $x\\,\\epsilon\\, A$ (finding the maximum). To illustrate our point we will use a function of two parameters. Our goal is to optimize over these 2 parameters. We can extend to higher dimensions by plotting pairs of parameters against each other. The Wikipedia article on Test functions for optimization has a few functions that are useful for evaluating optimization algorithms. Here is Beale's function: $f(x,y)$ = $(1.5−x+xy)&#94;2+(2.25−x+xy&#94;2)&#94;2+(2.625−x+xy&#94;3)&#94;2$ [source: Wikipedia ] We already know that this function has a minimum at [3.0, 0.5]. Let's see if scipy will find it. In [3]: # define Beale's function which we want to minimize def objective ( X ): x = X [ 0 ]; y = X [ 1 ] return ( 1.5 - x + x * y ) ** 2 + ( 2.25 - x + x * y ** 2 ) ** 2 + ( 2.625 - x + x * y ** 3 ) ** 2 In [4]: # function boundaries xmin , xmax , xstep = - 4.5 , 4.5 , . 9 ymin , ymax , ystep = - 4.5 , 4.5 , . 9 In [5]: # Let's create some points x1 , y1 = np . meshgrid ( np . arange ( xmin , xmax + xstep , xstep ), np . arange ( ymin , ymax + ystep , ystep )) Let's make an initial guess In [6]: # initial guess x0 = [ 4. , 4. ] f0 = objective ( x0 ) print ( f0 ) 68891.203125 In [7]: bnds = (( xmin , xmax ), ( ymin , ymax )) minimum = minimize ( objective , x0 , bounds = bnds ) In [8]: print ( minimum ) fun: 2.068025638865627e-12 hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64> jac: array([-1.55969780e-06, 9.89837957e-06]) message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL' nfev: 60 nit: 14 status: 0 success: True x: array([3.00000257, 0.50000085]) In [9]: real_min = [ 3.0 , 0.5 ] print ( f 'The answer, {minimum.x} , is very close to the optimum as we know it, which is {real_min} ' ) print ( f 'The value of the objective for {real_min} is {objective(real_min)}' ) The answer, [3.00000257 0.50000085], is very close to the optimum as we know it, which is [3.0, 0.5] The value of the objective for [3.0, 0.5] is 0.0 Part 2: Optimization in neural networks In general: Learning Representation --> Objective function --> Optimization algorithm A neural network can be defined as a framework that combines inputs and tries to guess the output. If we are lucky enough to have some results, called \"the ground truth\", to compare the outputs produced by the network, we can calculate the error . So the network guesses, calculates some error function, guesses again, trying to minimize this error, guesses again, until the error does not go down any more. This is optimization. In neural networks the most common used optimization algorithms, are flavors of GD (gradient descent) . The objective function used in gradient descent is the loss function which we want to minimize . A keras Refresher Keras is a Python library for deep learning that can run on top of both Theano or TensorFlow, two powerful Python libraries for fast numerical computing created and released by Facebook and Google, respectevely. Keras was developed to make developing deep learning models as fast and easy as possible for research and practical applications. It runs on Python 2.7 or 3.5 and can seamlessly execute on GPUs and CPUs. Keras is built on the idea of a model. At its core we have a sequence of layers called the Sequential model which is a linear stack of layers. Keras also provides the functional API , a way to define complex models, such as multi-output models, directed acyclic graphs, or models with shared layers. We can summarize the construction of deep learning models in Keras using the Sequential model as follows: Define your model : create a Sequential model and add layers. Compile your model : specify loss function and optimizers and call the .compile() function. Fit your model : train the model on data by calling the .fit() function. Make predictions : use the model to generate predictions on new data by calling functions such as .evaluate() or .predict() . Callbacks: taking a peek into our model while it's training You can look at what is happening in various stages of your model by using callbacks . A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training. You can pass a list of callbacks (as the keyword argument callbacks) to the .fit() method of the Sequential or Model classes. The relevant methods of the callbacks will then be called at each stage of the training. A callback function you are already familiar with is keras.callbacks.History() . This is automatically included in .fit() . Another very useful one is keras.callbacks.ModelCheckpoint which saves the model with its weights at a certain point in the training. This can prove useful if your model is running for a long time and a system failure happens. Not all is lost then. It's a good practice to save the model weights only when an improvement is observed as measured by the acc , for example. keras.callbacks.EarlyStopping stops the training when a monitored quantity has stopped improving. keras.callbacks.LearningRateScheduler will change the learning rate during training. We will apply some callbacks later. For full documentation on callbacks see https://keras.io/callbacks/ What are the steps to optimizing our network? In [10]: import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras import losses from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) # fix random seed for reproducibility np . random . seed ( 5 ) 1.12.0 2.1.6-tf Using TensorFlow backend. Step 1 - Deciding on the network topology (not really considered optimization but is obviously very important) We will use the MNIST dataset which consists of grayscale images of handwritten digits (0-9) whose dimension is 28x28 pixels. Each pixel is 8 bits so its value ranges from 0 to 255. In [11]: #mnist = tf.keras.datasets.mnist mnist = keras . datasets . mnist ( x_train , y_train ),( x_test , y_test ) = mnist . load_data () x_train . shape , y_train . shape Out[11]: ((60000, 28, 28), (60000,)) Each label is a number between 0 and 9 In [12]: print ( y_train ) [5 0 4 ... 5 6 8] Let's look at some 10 of the images In [13]: plt . figure ( figsize = ( 10 , 10 )) for i in range ( 10 ): plt . subplot ( 5 , 5 , i + 1 ) plt . xticks ([]) plt . yticks ([]) plt . grid ( False ) plt . imshow ( x_train [ i ], cmap = plt . cm . binary ) plt . xlabel ( y_train [ i ]) In [14]: x_train [ 45 ] . shape x_train [ 45 , 15 : 20 , 15 : 20 ] Out[14]: array([[ 11, 198, 231, 41, 0], [ 82, 252, 204, 0, 0], [253, 253, 141, 0, 0], [252, 220, 36, 0, 0], [252, 96, 0, 0, 0]], dtype=uint8) In [15]: print ( f 'We have {x_train.shape[0]} train samples' ) print ( f 'We have {x_test.shape[0]} test samples' ) We have 60000 train samples We have 10000 test samples Preprocessing the data To run our NN we need to pre-process the data First we need to make the 2D image arrays into 1D (flatten them). We can either perform this by using array reshaping with numpy.reshape() or the keras ' method for this: a layer called tf.keras.layers.Flatten which transforms the format of the images from a 2d-array (of 28 by 28 pixels), to a 1D-array of 28 * 28 = 784 pixels. Then we need to normalize the pixel values (give them values between 0 and 1) using the following transformation: \\begin{align} x := \\dfrac{x - x_{min}}{x_{max} - x_{min}} \\textrm{} \\end{align} In our case $x_{min} = 0$ and $x_{max} = 255$ so the formula becomes simply $x := {x}/255$ In [16]: # normalize the data x_train , x_test = x_train / 255.0 , x_test / 255.0 In [17]: # reshape the data into 1D vectors x_train = x_train . reshape ( 60000 , 784 ) x_test = x_test . reshape ( 10000 , 784 ) num_classes = 10 In [18]: x_train . shape [ 1 ] Out[18]: 784 Now let's prepare our class vector (y) to a binary class matrix, e.g. for use with categorical_crossentropy. In [19]: # Convert class vectors to binary class matrices y_train = keras . utils . to_categorical ( y_train , num_classes ) y_test = keras . utils . to_categorical ( y_test , num_classes ) In [20]: y_train [ 0 ] Out[20]: array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32) Now we are ready to build the model! Step 2 - Adjusting the learning rate One of the most common optimization algorithm is Stochastic Gradient Descent (SGD). The hyperparameters that can be optimized in SGD are learning rate , momentum , decay and nesterov . Learning rate controls the weight at the end of each batch, and momentum controls how much to let the previous update influence the current weight update. Decay indicates the learning rate decay over each update, and nesterov takes the value True or False depending on if we want to apply Nesterov momentum. Typical values for those hyperparameters are lr=0.01, decay=1e-6, momentum=0.9, and nesterov=True. The learning rate hyperparameter goes into the optimizer function which we will see below. Let's implement a learning rate adaptation schedule in Keras . We'll start with SGD and a learning rate value of 0.1. We will then train the model for 40 epochs and set the decay argument to 0.002 (0.1/50). We also include a momentum value of 0.8 since that seems to work well when using an adaptive learning rate. In [21]: epochs = 60 learning_rate = 0.1 decay_rate = learning_rate / epochs momentum = 0.8 sgd = SGD ( lr = learning_rate , momentum = momentum , decay = decay_rate , nesterov = False ) In [22]: # build the model input_dim = x_train . shape [ 1 ] lr_model = Sequential () lr_model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) # fully-connected layer with 64 hidden units lr_model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) lr_model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) # compile the model lr_model . compile ( loss = 'categorical_crossentropy' , optimizer = sgd , metrics = [ 'acc' ]) In [23]: %%time # Fit the model batch_size = 28 lr_model_history = lr_model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/60 60000/60000 [==============================] - 3s 43us/step - loss: 0.2856 - acc: 0.9072 - val_loss: 0.1419 - val_acc: 0.9559 Epoch 2/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.1043 - acc: 0.9684 - val_loss: 0.1052 - val_acc: 0.9663 Epoch 3/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0778 - acc: 0.9759 - val_loss: 0.0948 - val_acc: 0.9715 Epoch 4/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0652 - acc: 0.9798 - val_loss: 0.0866 - val_acc: 0.9728 Epoch 5/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0571 - acc: 0.9828 - val_loss: 0.0861 - val_acc: 0.9729 Epoch 6/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0516 - acc: 0.9843 - val_loss: 0.0837 - val_acc: 0.9741 Epoch 7/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0473 - acc: 0.9857 - val_loss: 0.0842 - val_acc: 0.9745 Epoch 8/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0439 - acc: 0.9870 - val_loss: 0.0858 - val_acc: 0.9725 Epoch 9/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0414 - acc: 0.9879 - val_loss: 0.0824 - val_acc: 0.9748 Epoch 10/60 60000/60000 [==============================] - 3s 42us/step - loss: 0.0392 - acc: 0.9889 - val_loss: 0.0820 - val_acc: 0.9750 Epoch 11/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0373 - acc: 0.9895 - val_loss: 0.0824 - val_acc: 0.9745 Epoch 12/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0355 - acc: 0.9903 - val_loss: 0.0823 - val_acc: 0.9741 Epoch 13/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0343 - acc: 0.9907 - val_loss: 0.0817 - val_acc: 0.9750 Epoch 14/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0330 - acc: 0.9912 - val_loss: 0.0812 - val_acc: 0.9754 Epoch 15/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0320 - acc: 0.9912 - val_loss: 0.0809 - val_acc: 0.9757 Epoch 16/60 60000/60000 [==============================] - 3s 44us/step - loss: 0.0310 - acc: 0.9917 - val_loss: 0.0815 - val_acc: 0.9761 Epoch 17/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0302 - acc: 0.9919 - val_loss: 0.0814 - val_acc: 0.9759 Epoch 18/60 60000/60000 [==============================] - 3s 46us/step - loss: 0.0292 - acc: 0.9924 - val_loss: 0.0815 - val_acc: 0.9755 Epoch 19/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0286 - acc: 0.9928 - val_loss: 0.0811 - val_acc: 0.9759 Epoch 20/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0279 - acc: 0.9929 - val_loss: 0.0808 - val_acc: 0.9759 Epoch 21/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0272 - acc: 0.9931 - val_loss: 0.0819 - val_acc: 0.9767 Epoch 22/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0267 - acc: 0.9933 - val_loss: 0.0820 - val_acc: 0.9753 Epoch 23/60 60000/60000 [==============================] - 3s 42us/step - loss: 0.0261 - acc: 0.9936 - val_loss: 0.0812 - val_acc: 0.9765 Epoch 24/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0256 - acc: 0.9935 - val_loss: 0.0821 - val_acc: 0.9759 Epoch 25/60 60000/60000 [==============================] - 3s 50us/step - loss: 0.0250 - acc: 0.9939 - val_loss: 0.0821 - val_acc: 0.9760 Epoch 26/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0246 - acc: 0.9939 - val_loss: 0.0822 - val_acc: 0.9755 Epoch 27/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0242 - acc: 0.9941 - val_loss: 0.0820 - val_acc: 0.9768 Epoch 28/60 60000/60000 [==============================] - 3s 49us/step - loss: 0.0238 - acc: 0.9941 - val_loss: 0.0825 - val_acc: 0.9761 Epoch 29/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0233 - acc: 0.9944 - val_loss: 0.0824 - val_acc: 0.9761 Epoch 30/60 60000/60000 [==============================] - 3s 46us/step - loss: 0.0231 - acc: 0.9946 - val_loss: 0.0830 - val_acc: 0.9760 Epoch 31/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0228 - acc: 0.9947 - val_loss: 0.0829 - val_acc: 0.9755 Epoch 32/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0224 - acc: 0.9947 - val_loss: 0.0829 - val_acc: 0.9760 Epoch 33/60 60000/60000 [==============================] - 3s 48us/step - loss: 0.0220 - acc: 0.9948 - val_loss: 0.0831 - val_acc: 0.9758 Epoch 34/60 60000/60000 [==============================] - 3s 51us/step - loss: 0.0218 - acc: 0.9949 - val_loss: 0.0827 - val_acc: 0.9754 Epoch 35/60 60000/60000 [==============================] - 3s 44us/step - loss: 0.0215 - acc: 0.9951 - val_loss: 0.0832 - val_acc: 0.9762 Epoch 36/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0213 - acc: 0.9952 - val_loss: 0.0833 - val_acc: 0.9759 Epoch 37/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0210 - acc: 0.9953 - val_loss: 0.0836 - val_acc: 0.9764 Epoch 38/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0208 - acc: 0.9952 - val_loss: 0.0836 - val_acc: 0.9758 Epoch 39/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0205 - acc: 0.9954 - val_loss: 0.0835 - val_acc: 0.9760 Epoch 40/60 60000/60000 [==============================] - 2s 38us/step - loss: 0.0203 - acc: 0.9955 - val_loss: 0.0838 - val_acc: 0.9761 Epoch 41/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0201 - acc: 0.9956 - val_loss: 0.0840 - val_acc: 0.9764 Epoch 42/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0198 - acc: 0.9957 - val_loss: 0.0841 - val_acc: 0.9761 Epoch 43/60 60000/60000 [==============================] - 3s 47us/step - loss: 0.0196 - acc: 0.9957 - val_loss: 0.0842 - val_acc: 0.9761 Epoch 44/60 60000/60000 [==============================] - 3s 43us/step - loss: 0.0194 - acc: 0.9958 - val_loss: 0.0840 - val_acc: 0.9760 Epoch 45/60 60000/60000 [==============================] - 2s 42us/step - loss: 0.0193 - acc: 0.9959 - val_loss: 0.0841 - val_acc: 0.9757 Epoch 46/60 60000/60000 [==============================] - 3s 42us/step - loss: 0.0190 - acc: 0.9958 - val_loss: 0.0848 - val_acc: 0.9760 Epoch 47/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0189 - acc: 0.9959 - val_loss: 0.0846 - val_acc: 0.9760 Epoch 48/60 60000/60000 [==============================] - 2s 40us/step - loss: 0.0187 - acc: 0.9961 - val_loss: 0.0846 - val_acc: 0.9764 Epoch 49/60 60000/60000 [==============================] - 3s 45us/step - loss: 0.0185 - acc: 0.9961 - val_loss: 0.0845 - val_acc: 0.9763 Epoch 50/60 60000/60000 [==============================] - 2s 41us/step - loss: 0.0184 - acc: 0.9963 - val_loss: 0.0846 - val_acc: 0.9761 Epoch 51/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0182 - acc: 0.9962 - val_loss: 0.0846 - val_acc: 0.9762 Epoch 52/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0181 - acc: 0.9963 - val_loss: 0.0849 - val_acc: 0.9761 Epoch 53/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0179 - acc: 0.9962 - val_loss: 0.0851 - val_acc: 0.9764 Epoch 54/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0177 - acc: 0.9964 - val_loss: 0.0852 - val_acc: 0.9768 Epoch 55/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0176 - acc: 0.9963 - val_loss: 0.0852 - val_acc: 0.9763 Epoch 56/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0175 - acc: 0.9965 - val_loss: 0.0854 - val_acc: 0.9763 Epoch 57/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0174 - acc: 0.9965 - val_loss: 0.0854 - val_acc: 0.9763 Epoch 58/60 60000/60000 [==============================] - 2s 39us/step - loss: 0.0172 - acc: 0.9965 - val_loss: 0.0855 - val_acc: 0.9763 Epoch 59/60 60000/60000 [==============================] - 2s 38us/step - loss: 0.0171 - acc: 0.9966 - val_loss: 0.0855 - val_acc: 0.9763 Epoch 60/60 60000/60000 [==============================] - 2s 38us/step - loss: 0.0170 - acc: 0.9967 - val_loss: 0.0853 - val_acc: 0.9757 CPU times: user 4min 27s, sys: 1min 1s, total: 5min 28s Wall time: 2min 32s In [24]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [26]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( lr_model_history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( lr_model_history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Exercise: Write a function that performs exponential learning rate decay using LearningRateScheduler $lr = lr0*e&#94;{(-kt)}$ t is the iteration number Step 3 - Choosing an optimizer and a loss function When constructing a model and using it to make our predictions, for example to assign label scores to images (\"cat\", \"plane\", etc), we want to measure our success or failure by defining a \"loss\" function (or objective function). The goal of optimization is to efficiently calculate the parameters/weights that minimize this loss function. keras provides various types of loss functions . Sometimes the \"loss\" function measures the \"distance\". We can define this \"distance\" between two data points in various ways suitable to the problem or dataset. Distance Euclidean Manhattan others such as Hamming which measures distances between strings, for example. The Hamming distance of \"carolin\" and \"cathrin\" is 3. Loss functions MSE (for regression) categorical cross-entropy (for classification) binary cross entropy (for classification) In [33]: # build the model input_dim = x_train . shape [ 1 ] model = Sequential () model . add ( Dense ( 64 , activation = tf . nn . relu , kernel_initializer = 'uniform' , input_dim = input_dim )) # fully-connected layer with 64 hidden units #model.add(Dropout(0.5)) model . add ( Dense ( 64 , kernel_initializer = 'uniform' , activation = tf . nn . relu )) #model.add(Dropout(0.5)) model . add ( Dense ( num_classes , kernel_initializer = 'uniform' , activation = tf . nn . softmax )) In [34]: # defining the parameters for RMSprop (I used the keras defaults here) rms = RMSprop ( lr = 0.001 , rho = 0.9 , epsilon = None , decay = 0.0 ) model . compile ( loss = 'categorical_crossentropy' , optimizer = rms , metrics = [ 'acc' ]) Step 4 - Deciding on the batch size and number of epochs In [35]: %%time batch_size = 32 epochs = 20 model_history = model . fit ( x_train , y_train , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( x_test , y_test )) Train on 60000 samples, validate on 10000 samples Epoch 1/20 60000/60000 [==============================] - 3s 46us/step - loss: 0.3931 - acc: 0.8850 - val_loss: 0.2082 - val_acc: 0.9400 Epoch 2/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.1696 - acc: 0.9502 - val_loss: 0.1334 - val_acc: 0.9595 Epoch 3/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.1208 - acc: 0.9641 - val_loss: 0.1162 - val_acc: 0.9677 Epoch 4/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0995 - acc: 0.9710 - val_loss: 0.1068 - val_acc: 0.9712 Epoch 5/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0846 - acc: 0.9751 - val_loss: 0.1035 - val_acc: 0.9728 Epoch 6/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.0733 - acc: 0.9784 - val_loss: 0.1203 - val_acc: 0.9713 Epoch 7/20 60000/60000 [==============================] - 2s 42us/step - loss: 0.0660 - acc: 0.9807 - val_loss: 0.0993 - val_acc: 0.9735 Epoch 8/20 60000/60000 [==============================] - 3s 43us/step - loss: 0.0599 - acc: 0.9834 - val_loss: 0.1143 - val_acc: 0.9713 Epoch 9/20 60000/60000 [==============================] - 3s 46us/step - loss: 0.0533 - acc: 0.9851 - val_loss: 0.1217 - val_acc: 0.9695 Epoch 10/20 60000/60000 [==============================] - 3s 47us/step - loss: 0.0493 - acc: 0.9866 - val_loss: 0.1109 - val_acc: 0.9735 Epoch 11/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.0441 - acc: 0.9875 - val_loss: 0.1186 - val_acc: 0.9742 Epoch 12/20 60000/60000 [==============================] - 2s 41us/step - loss: 0.0422 - acc: 0.9883 - val_loss: 0.1222 - val_acc: 0.9725 Epoch 13/20 60000/60000 [==============================] - 2s 41us/step - loss: 0.0397 - acc: 0.9897 - val_loss: 0.1327 - val_acc: 0.9725 Epoch 14/20 60000/60000 [==============================] - 3s 43us/step - loss: 0.0359 - acc: 0.9905 - val_loss: 0.1365 - val_acc: 0.9724 Epoch 15/20 60000/60000 [==============================] - 3s 42us/step - loss: 0.0342 - acc: 0.9910 - val_loss: 0.1445 - val_acc: 0.9748 Epoch 16/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0317 - acc: 0.9915 - val_loss: 0.1420 - val_acc: 0.9758 Epoch 17/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0303 - acc: 0.9920 - val_loss: 0.1534 - val_acc: 0.9740 Epoch 18/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0280 - acc: 0.9928 - val_loss: 0.1549 - val_acc: 0.9727 Epoch 19/20 60000/60000 [==============================] - 2s 40us/step - loss: 0.0263 - acc: 0.9938 - val_loss: 0.1691 - val_acc: 0.9731 Epoch 20/20 60000/60000 [==============================] - 3s 43us/step - loss: 0.0266 - acc: 0.9934 - val_loss: 0.1504 - val_acc: 0.9759 CPU times: user 1min 32s, sys: 20.9 s, total: 1min 53s Wall time: 50.7 s In [36]: from sklearn.metrics import r2_score as r2 score = model . evaluate ( x_test , y_test , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) print ( 'Test R2:' , r2 ( y_test , model . predict ( x_test ))) Test loss: 0.1503745241531124 Test accuracy: 0.9759 Test R2: 0.9542278387249276 In [37]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'acc' ]), 'r' , label = 'train_acc' ) ax . plot ( np . sqrt ( model_history . history [ 'val_acc' ]), 'b' , label = 'val_acc' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [38]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot ( np . sqrt ( model_history . history [ 'loss' ]), 'r' , label = 'train' ) ax . plot ( np . sqrt ( model_history . history [ 'val_loss' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Loss' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) In [39]: print ( model_history . history . keys ()) dict_keys(['val_loss', 'val_acc', 'loss', 'acc']) Step 5 - Random restarts This method does not seem to have an implementation in keras . We will leave it as a home exercise! Hint: you can use keras.callbacks.LearningRateScheduler . Tuning the Hyperparameters using Cross Validation Now instead of trying different values by hand, we will use GridSearchCV from Scikit-Learn to try out several values for our hyperparameters and compare the results. To do cross-validation with keras we will use the wrappers for the Scikit-Learn API. They provide a way to use Sequential Keras models (single-input only) as part of your Scikit-Learn workflow. There are two wrappers available: keras.wrappers.scikit_learn.KerasClassifier(build_fn=None, **sk_params) , which implements the Scikit-Learn classifier interface, keras.wrappers.scikit_learn.KerasRegressor(build_fn=None, **sk_params) , which implements the Scikit-Learn regressor interface. In [41]: import numpy from sklearn.model_selection import GridSearchCV from keras.wrappers.scikit_learn import KerasClassifier Trying different weight initializations In [42]: # Function to create model, required for KerasClassifier def create_model ( init_mode = 'uniform' ): # define model model = Sequential () model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu , input_dim = 784 )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 64 , kernel_initializer = init_mode , activation = tf . nn . relu )) model . add ( Dropout ( 0.5 )) model . add ( Dense ( 10 , kernel_initializer = init_mode , activation = tf . nn . softmax )) # compile model model . compile ( loss = 'categorical_crossentropy' , optimizer = RMSprop (), metrics = [ 'accuracy' ]) return model In [43]: %%time seed = 7 numpy . random . seed ( seed ) batch_size = 128 epochs = 10 model_CV = KerasClassifier ( build_fn = create_model , epochs = epochs , batch_size = batch_size , verbose = 0 ) # define the grid search parameters init_mode = [ 'uniform' , 'lecun_uniform' , 'normal' , 'zero' , 'glorot_normal' , 'glorot_uniform' , 'he_normal' , 'he_uniform' ] param_grid = dict ( init_mode = init_mode ) grid = GridSearchCV ( estimator = model_CV , param_grid = param_grid , n_jobs =- 1 , cv = 3 ) grid_result = grid . fit ( x_train , y_train ) # summarize results print ( \"Best: %f using %s \" % ( grid_result . best_score_ , grid_result . best_params_ )) means = grid_result . cv_results_ [ 'mean_test_score' ] stds = grid_result . cv_results_ [ 'std_test_score' ] params = grid_result . cv_results_ [ 'params' ] for mean , stdev , param in zip ( means , stds , params ): print ( \" %f ( %f ) with: %r \" % ( mean , stdev , param )) Best: 0.948967 using {'init_mode': 'glorot_uniform'} 0.946117 (0.002852) with: {'init_mode': 'uniform'} 0.948400 (0.001192) with: {'init_mode': 'lecun_uniform'} 0.948117 (0.001310) with: {'init_mode': 'normal'} 0.112367 (0.002416) with: {'init_mode': 'zero'} 0.948367 (0.002593) with: {'init_mode': 'glorot_normal'} 0.948967 (0.002210) with: {'init_mode': 'glorot_uniform'} 0.947400 (0.002060) with: {'init_mode': 'he_normal'} 0.946983 (0.002908) with: {'init_mode': 'he_uniform'} CPU times: user 21 s, sys: 3.6 s, total: 24.6 s Wall time: 1min 36s Save Your Neural Network Model to JSON The Hierarchical Data Format (HDF5) is a data storage format for storing large arrays of data including values for the weights in a neural network. You can install HDF5 Python module: pip install h5py Keras gives you the ability to describe and save any model using the JSON format. In [ ]: from keras.models import model_from_json # serialize model to JSON model_json = model . to_json () with open ( \"model.json\" , \"w\" ) as json_file : json_file . write ( model_json ) # save weights to HDF5 model . save_weights ( \"model.h5\" ) print ( \"Model saved\" ) # when you want to retrieve the model: load json and create model json_file = open ( 'model.json' , 'r' ) saved_model = json_file . read () # close the file as good practice json_file . close () model_from_json = model_from_json ( saved_model ) # load weights into new model model_from_json . load_weights ( \"model.h5\" ) print ( \"Model loaded\" ) Exercise 1: Perform a GridSearch for Learning rate and number of epochs combined We will try various small standard learning rates, and momentum values from 0.1 to 0.9 in steps of 0.2. We want to include the number of epochs in an optimization as there is a dependency between the learning rate, the batch size, and the number of epochs. In [ ]: #your code here if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"pages","url":"pages/lab3/students/"},{"title":"Lab 5:","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS-109B Introduction to Data Science Lab 5: Convolutional Neural Networks Harvard University Spring 2019 Lab instructor: Eleni Kaxiras Instructors: Pavlos Protopapas and Mark Glickman Authors: Eleni Kaxiras, Pavlos Protopapas, Patrick Ohiomoba, and Davis Sontag In [ ]: # RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Learning Goals In this lab we will look at Convolutional Neural Networks (CNNs), and their building blocks. By the end of this lab, you should: know how to put together the building blocks used in CNNs - such as convolutional layers and pooling layers - in keras with an example. have a good undertanding on how images, a common type of data for a CNN, are represented in the computer and how to think of them as arrays of numbers. be familiar with preprocessing images with keras and sckit-learn . use keras-viz to produce Saliency maps. learn best practices for configuring the hyperparameters of a CNN. run your first CNN and see the error rate. In [ ]: import matplotlib.pyplot as plt plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) import numpy as np from scipy.optimize import minimize import tensorflow as tf import keras from keras import layers from keras import models from keras import utils from keras.layers import Dense from keras.models import Sequential from keras.layers import Flatten from keras.layers import Dropout from keras.layers import Activation from keras.regularizers import l2 from keras.optimizers import SGD from keras.optimizers import RMSprop from keras import datasets from keras.preprocessing.image import ImageDataGenerator from keras.callbacks import LearningRateScheduler from keras.callbacks import History from keras import losses from keras.datasets import mnist from keras.utils import to_categorical from sklearn.utils import shuffle print ( tf . VERSION ) print ( tf . keras . __version__ ) % matplotlib inline Prologue: keras-viz Visualization Toolkit keras-vis is a high-level toolkit for visualizing and debugging your trained keras neural net models. Currently supported visualizations include: Activation maximization Saliency maps Class activation maps All visualizations by default support N-dimensional image inputs. i.e., it generalizes to N-dim image inputs to your model. Compatible with both theano and tensorflow backends with 'channels_first', 'channels_last' data format. Read the documentation at https://raghakot.github.io/keras-vis.https://github.com/raghakot/keras-vis To install use pip install git+https://github.com/raghakot/keras-vis.git --upgrade SEAS JupyterHub Instructions for Using SEAS JupyterHub SEAS and FAS are providing you with a platform in AWS to use for the class (accessible from the 'Jupyter' menu link in Canvas). These are AWS p2 instances with a GPU, 10GB of disk space, and 61 GB of RAM, for faster training for your networks. Most of the libraries such as keras, tensorflow, pandas, etc. are pre-installed. If a library is missing you may install it via the Terminal. NOTE : The AWS platform is funded by SEAS and FAS for the purposes of the class. It is not running against your individual credit. You are not allowed to use it for purposes not related to this course. Help us keep this service: Make sure you stop your instance as soon as you do not need it. Part 1: Parts of a Convolutional Neural Net There are three types of layers in a Convolutional Neural Network: Convolutional Layers Pooling Layers. Dropout Layers. Fully Connected Layers. a. Convolutional Layers. Convolutional layers are comprised of filters and feature maps . The filters are essentially the neurons of the layer. They have the weights and produce the input for the next layer. The feature map is the output of one filter applied to the previous layer. The fundamental difference between a densely connected layer and a convolution layer is that dense layers learn global patterns in their input feature space (for example, for an MNIST digit, patterns involving all pixels), whereas convolution layers learn local patterns: in the case of images, patterns found in small 2D windows of the inputs called receptive fields . This key characteristic gives convnets two interesting properties: The patterns they learn are translation invariant . After learning a certain pattern in the lower-right corner of a picture, a convnet can recognize it anywhere: for example, in the upper-left corner. A densely connected network would have to learn the pattern anew if it appeared at a new location. This makes convnets data efficient when processing images (because the visual world is fundamentally translation invariant): they need fewer training samples to learn representations that have generalization power. They can learn spatial hierarchies of patterns . A first convolution layer will learn small local patterns such as edges, a second convolution layer will learn larger patterns made of the features of the first layers, and so on. This allows convnets to efficiently learn increasingly complex and abstract visual concepts (because the visual world is fundamentally spatially hierarchical). Convolutions operate over 3D tensors, called feature maps, with two spatial axes (height and width) as well as a depth axis (also called the channels axis). For an RGB image, the dimension of the depth axis is 3, because the image has three color channels: red, green, and blue. For a black-and-white picture, like the MNIST digits, the depth is 1 (levels of gray). The convolution operation extracts patches from its input feature map and applies the same transformation to all of these patches, producing an output feature map. This output feature map is still a 3D tensor: it has a width and a height. Its depth can be arbitrary, because the output depth is a parameter of the layer, and the different channels in that depth axis no longer stand for specific colors as in RGB input; rather, they stand for filters. Filters encode specific aspects of the input data: at a high level, a single filter could encode the concept \"presence of a face in the input,\" for instance. In the MNIST example that we will see, the first convolution layer takes a feature map of size (28, 28, 1) and outputs a feature map of size (26, 26, 32): it computes 32 filters over its input. Each of these 32 output channels contains a 26×26 grid of values, which is a response map of the filter over the input, indicating the response of that filter pattern at different locations in the input. Convolutions are defined by two key parameters: Size of the patches extracted from the inputs. These are typically 3×3 or 5×5 The number of filters computed by the convolution. Padding : One of \"valid\", \"causal\" or \"same\" (case-insensitive). \"valid\" means \"no padding\". \"same\" results in padding the input such that the output has the same length as the original input. \"causal\" results in causal (dilated) convolutions, In keras see convolutional layers keras.layers.Conv2D (filters, kernel_size, strides=(1, 1), padding='valid', activation=None, use_bias=True, kernel_initializer='glorot_uniform', data_format='channels_last', bias_initializer='zeros') How are the values in feature maps calculated? Exercise 1: Compute the operations by hand (assuming zero padding and same arrays for all channels) to produce the first element of the 4x4 feature map. How did we get the 4x4 output size? Write this Conv layer in keras -- your answer here b. Pooling Layers. Pooling layers are also comprised of filters and feature maps. Let's say the pooling layer has a 2x2 receptive field and a stride of 2. This stride results in feature maps that are one half the size of the input feature maps. We can use a max() operation for each receptive field. In keras see pooling layers keras.layers.MaxPooling2D (pool_size=(2, 2), strides=None, padding='valid', data_format=None) c. Dropout Layers. Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting. In keras see Dropout layers keras.layers.Dropout(rate, seed=None) rate: float between 0 and 1. Fraction of the input units to drop. seed: A Python integer to use as random seed. References Dropout: A Simple Way to Prevent Neural Networks from Overfitting d. Fully Connected Layers. A fully connected layer flattens the square feature map into a vector. Then we can use a sigmoid or softmax activation function to output probabilities of classes. In keras see FC layers keras.layers.Dense (units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros') IT'S ALL ABOUT THE HYPERPARAMETERS! stride size of filter number of filters poolsize Part 2: Preprocessing the data Taking a look at how images are represented in a computer using a photo of a Picasso sculpture In [ ]: img = plt . imread ( 'data/picasso.png' ) img . shape In [ ]: img [ 1 ,:, 1 ] In [ ]: print ( type ( img [ 50 ][ 0 ][ 0 ])) In [ ]: # let's see the image imgplot = plt . imshow ( img ) Visualizing the channels In [ ]: R_img = img [:,:, 0 ] G_img = img [:,:, 1 ] B_img = img [:,:, 2 ] plt . subplot ( 221 ) plt . imshow ( R_img , cmap = plt . cm . Reds ) plt . subplot ( 222 ) plt . imshow ( G_img , cmap = plt . cm . Greens ) plt . subplot ( 223 ) plt . imshow ( B_img , cmap = plt . cm . Blues ) plt . subplot ( 224 ) plt . imshow ( img ) plt . show () More on preprocessing data below! If you want to learn more: Image Processing with Python and Scipy Part 3: Putting the Parts together to make a small ConvNet Model Let's put all the parts together to make a convnet for classifying our good old MNIST digits. In [ ]: # Load data and preprocess ( train_images , train_labels ), ( test_images , test_labels ) = mnist . load_data () # load MNIST data train_images . shape In [ ]: train_images . max (), train_images . min () In [ ]: train_images = train_images . reshape (( 60000 , 28 , 28 , 1 )) # Reshape to get third dimension train_images = train_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 test_images = test_images . reshape (( 10000 , 28 , 28 , 1 )) # Reshape to get third dimension test_images = test_images . astype ( 'float32' ) / 255 # Normalize between 0 and 1 # Convert labels to categorical data train_labels = to_categorical ( train_labels ) test_labels = to_categorical ( test_labels ) In [ ]: mnist_cnn_model = models . Sequential () # Create sequential model # Add network layers mnist_cnn_model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 28 , 28 , 1 ))) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) mnist_cnn_model . add ( layers . MaxPooling2D (( 2 , 2 ))) mnist_cnn_model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) The next step is to feed the last output tensor (of shape (3, 3, 64)) into a densely connected classifier network like those you're already familiar with: a stack of Dense layers. These classifiers process vectors, which are 1D, whereas the current output is a 3D tensor. First we have to flatten the 3D outputs to 1D, and then add a few Dense layers on top. In [ ]: mnist_cnn_model . add ( layers . Flatten ()) mnist_cnn_model . add ( layers . Dense ( 64 , activation = 'relu' )) mnist_cnn_model . add ( layers . Dense ( 10 , activation = 'softmax' )) mnist_cnn_model . summary () In [ ]: # Compile model mnist_cnn_model . compile ( optimizer = 'rmsprop' , loss = 'categorical_crossentropy' , metrics = [ 'accuracy' ]) # Fit the model mnist_cnn_model . fit ( train_images , train_labels , epochs = 5 , batch_size = 64 ) # Evaluate the model on the test data: test_loss , test_acc = mnist_cnn_model . evaluate ( test_images , test_labels ) test_acc A densely connected network (MLP) running MNIST usually has a test accuracy of 97.8%, whereas our basic convnet has a test accuracy of 99.03%: we decreased the error rate by 68% (relative) with only 5 epochs. Not bad! But why does this simple convnet work so well, compared to a densely connected model? The answer is above on how convolutional layers work! Data Preprocessing : Meet the ImageDataGenerator class in keras (docs) The MNIST and other pre-loaded dataset are formatted in a way that is almost ready for feeding into the model. What about plain images? They should be formatted into appropriately preprocessed floating-point tensors before being fed into the network. The Dogs vs. Cats dataset that you'll use isn't packaged with Keras. It was made available by Kaggle as part of a computer-vision competition in late 2013, back when convnets weren't mainstream. The data has been downloaded for you from https://www.kaggle.com/c/dogs-vs-cats/data The pictures are medium-resolution color JPEGs. In [ ]: # TODO: set your base dir to your correct local location base_dir = 'data/cats_and_dogs_small' import os , shutil # Set up directory information train_dir = os . path . join ( base_dir , 'train' ) validation_dir = os . path . join ( base_dir , 'validation' ) test_dir = os . path . join ( base_dir , 'test' ) train_cats_dir = os . path . join ( train_dir , 'cats' ) train_dogs_dir = os . path . join ( train_dir , 'dogs' ) validation_cats_dir = os . path . join ( validation_dir , 'cats' ) validation_dogs_dir = os . path . join ( validation_dir , 'dogs' ) test_cats_dir = os . path . join ( test_dir , 'cats' ) test_dogs_dir = os . path . join ( test_dir , 'dogs' ) print ( 'total training cat images:' , len ( os . listdir ( train_cats_dir ))) print ( 'total training dog images:' , len ( os . listdir ( train_dogs_dir ))) print ( 'total validation cat images:' , len ( os . listdir ( validation_cats_dir ))) print ( 'total validation dog images:' , len ( os . listdir ( validation_dogs_dir ))) print ( 'total test cat images:' , len ( os . listdir ( test_cats_dir ))) print ( 'total test dog images:' , len ( os . listdir ( test_dogs_dir ))) So you do indeed have 2,000 training images, 1,000 validation images, and 1,000 test images. Each split contains the same number of samples from each class: this is a balanced binary-classification problem, which means classification accuracy will be an appropriate measure of success. Building the network In [ ]: from keras import layers from keras import models model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . summary () For the compilation step, you'll go with the RMSprop optimizer. Because you ended the network with a single sigmoid unit, you'll use binary crossentropy as the loss. In [ ]: from keras import optimizers model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) The steps for getting it into the network are roughly as follows: Read the picture files. Decode the JPEG content to RGB grids of pixels. Convert these into floating-point tensors. Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values). It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically with the class ImageDataGenerator , which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors. This is what you'll use here. In [ ]: from keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator ( rescale = 1. / 255 ) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 20 , class_mode = 'binary' ) Let's look at the output of one of these generators: it yields batches of 150×150 RGB images (shape (20, 150, 150, 3)) and binary labels (shape (20,)). There are 20 samples in each batch (the batch size). Note that the generator yields these batches indefinitely: it loops endlessly over the images in the target folder. For this reason, you need to break the iteration loop at some point: In [ ]: for data_batch , labels_batch in train_generator : print ( 'data batch shape:' , data_batch . shape ) print ( 'labels batch shape:' , labels_batch . shape ) break Let's fit the model to the data using the generator. You do so using the .fit_generator method, the equivalent of .fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely, like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring an epoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps - the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples. When using fit_generator, you can pass a validation_data argument, much as with the fit method. It's important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation In [ ]: history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 30 validation_data = validation_generator , validation_steps = 50 ) # It's good practice to always save your models after training. model . save ( 'cats_and_dogs_small_1.h5' ) Let's plot the accuracy of the model over the training and validation data during training: In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) Let's try data augmentation In [ ]: datagen = ImageDataGenerator ( rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True , fill_mode = 'nearest' ) These are just a few of the options available (for more, see the Keras documentation). Let's quickly go over this code: rotation_range is a value in degrees (0–180), a range within which to randomly rotate pictures. width_shift and height_shift are ranges (as a fraction of total width or height) within which to randomly translate pictures vertically or horizontally. shear_range is for randomly applying shearing transformations. zoom_range is for randomly zooming inside pictures. horizontal_flip is for randomly flipping half the images horizontally—relevant when there are no assumptions of - horizontal asymmetry (for example, real-world pictures). fill_mode is the strategy used for filling in newly created pixels, which can appear after a rotation or a width/height shift. Let's look at the augmented images In [ ]: from keras.preprocessing import image fnames = [ os . path . join ( train_dogs_dir , fname ) for fname in os . listdir ( train_dogs_dir )] img_path = fnames [ 3 ] # Chooses one image to augment img = image . load_img ( img_path , target_size = ( 150 , 150 )) # Reads the image and resizes it x = image . img_to_array ( img ) # Converts it to a Numpy array with shape (150, 150, 3) x = x . reshape (( 1 ,) + x . shape ) # Reshapes it to (1, 150, 150, 3) i = 0 for batch in datagen . flow ( x , batch_size = 1 ): plt . figure ( i ) imgplot = plt . imshow ( image . array_to_img ( batch [ 0 ])) i += 1 if i % 4 == 0 : break plt . show () If you train a new network using this data-augmentation configuration, the network will never see the same input twice. But the inputs it sees are still heavily intercorrelated, because they come from a small number of original images—you can't produce new information, you can only remix existing information. As such, this may not be enough to completely get rid of overfitting. To further fight overfitting, you'll also add a Dropout layer to your model right before the densely connected classifier. In [ ]: model = models . Sequential () model . add ( layers . Conv2D ( 32 , ( 3 , 3 ), activation = 'relu' , input_shape = ( 150 , 150 , 3 ))) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Conv2D ( 128 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D (( 2 , 2 ))) model . add ( layers . Flatten ()) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( 512 , activation = 'relu' )) model . add ( layers . Dense ( 1 , activation = 'sigmoid' )) model . compile ( loss = 'binary_crossentropy' , optimizer = optimizers . RMSprop ( lr = 1e-4 ), metrics = [ 'acc' ]) In [ ]: # Let's train the network using data augmentation and dropout. train_datagen = ImageDataGenerator ( rescale = 1. / 255 , rotation_range = 40 , width_shift_range = 0.2 , height_shift_range = 0.2 , shear_range = 0.2 , zoom_range = 0.2 , horizontal_flip = True ,) test_datagen = ImageDataGenerator ( rescale = 1. / 255 ) # Note that the validation data shouldn't be augmented! train_generator = train_datagen . flow_from_directory ( train_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) validation_generator = test_datagen . flow_from_directory ( validation_dir , target_size = ( 150 , 150 ), batch_size = 32 , class_mode = 'binary' ) history = model . fit_generator ( train_generator , steps_per_epoch = 100 , epochs = 5 , # TODO: should be 100 validation_data = validation_generator , validation_steps = 50 ) model . save ( 'cats_and_dogs_small_2.h5' ) And let's plot the results again. Thanks to data augmentation and dropout, you're no longer overfitting: the training curves are closely tracking the validation curves. You now reach an accuracy of 82%, a 15% relative improvement over the non-regularized model. (Note: these numbers are for 100 epochs..) In [ ]: fig , ax = plt . subplots ( 1 , 1 , figsize = ( 10 , 6 )) ax . plot (( history . history [ 'acc' ]), 'r' , label = 'train' ) ax . plot (( history . history [ 'val_acc' ]), 'b' , label = 'val' ) ax . set_xlabel ( r 'Epoch' , fontsize = 20 ) ax . set_ylabel ( r 'Accuracy' , fontsize = 20 ) ax . legend () ax . tick_params ( labelsize = 20 ) By using regularization techniques even further, and by tuning the network's parameters (such as the number of filters per convolution layer, or the number of layers in the network), you may be able to get an even better accuracy, likely up to 86% or 87%. But it would prove difficult to go any higher just by training your own convnet from scratch, because you have so little data to work with. As a next step to improve your accuracy on this problem, you'll have to use a pretrained model. Part 4: keras viz toolkit https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb In [ ]: class_idx = 0 indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] # pick some random input from here. idx = indices [ 0 ] # Lets sanity check the picked image. from matplotlib import pyplot as plt % matplotlib inline plt . rcParams [ 'figure.figsize' ] = ( 18 , 6 ) plt . imshow ( test_images [ idx ][ ... , 0 ]) In [ ]: input_shape = ( 28 , 28 , 1 ) num_classes = 10 batch_size = 128 epochs = 5 model = Sequential () model . add ( layers . Conv2D ( 32 , kernel_size = ( 3 , 3 ), activation = 'relu' , input_shape = input_shape )) model . add ( layers . Conv2D ( 64 , ( 3 , 3 ), activation = 'relu' )) model . add ( layers . MaxPooling2D ( pool_size = ( 2 , 2 ))) model . add ( layers . Dropout ( 0.25 )) model . add ( layers . Flatten ()) model . add ( layers . Dense ( 128 , activation = 'relu' )) model . add ( layers . Dropout ( 0.5 )) model . add ( layers . Dense ( num_classes , activation = 'softmax' , name = 'preds' )) model . compile ( loss = keras . losses . categorical_crossentropy , optimizer = keras . optimizers . Adam (), metrics = [ 'accuracy' ]) model . fit ( train_images , train_labels , batch_size = batch_size , epochs = epochs , verbose = 1 , validation_data = ( test_images , test_labels )) score = model . evaluate ( test_images , test_labels , verbose = 0 ) print ( 'Test loss:' , score [ 0 ]) print ( 'Test accuracy:' , score [ 1 ]) In [ ]: from vis.visualization import visualize_saliency from vis.utils import utils from keras import activations # Utility to search for layer index by name. # Alternatively we can specify this as -1 since it corresponds to the last layer. layer_idx = utils . find_layer_idx ( model , 'preds' ) In [ ]: plt . rcParams [ \"figure.figsize\" ] = ( 5 , 5 ) from vis.visualization import visualize_cam import warnings warnings . filterwarnings ( 'ignore' ) # This corresponds to the Dense linear layer. for class_idx in np . arange ( 10 ): indices = np . where ( test_labels [:, class_idx ] == 1. )[ 0 ] idx = indices [ 0 ] f , ax = plt . subplots ( 1 , 4 ) ax [ 0 ] . imshow ( test_images [ idx ][ ... , 0 ]) for i , modifier in enumerate ([ None , 'guided' , 'relu' ]): grads = visualize_cam ( model , layer_idx , filter_indices = class_idx , seed_input = test_images [ idx ], backprop_modifier = modifier ) if modifier is None : modifier = 'vanilla' ax [ i + 1 ] . set_title ( modifier ) ax [ i + 1 ] . imshow ( grads , cmap = 'jet' ) References and Acknowledgements The cats and dogs part of this lab is based on the book Deep Learning with Python, Chapter 5 written by the Francois Chollet, the author of Keras. It is a very practical introduction to Deep Learning. It is appropriate for those with some Python knowledge who want to start with machine learning. The saliency maps are from https://github.com/raghakot/keras-vis/blob/master/examples/mnist/attention.ipynb if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab5/student/"},{"title":"Advanced Section 1: Optimization/Dropout","text":"Slides PDF Lecture notes PDF","tags":"A-sections","url":"a-sections/a-section1/"},{"title":"Lecture 6: NN Optimization","text":"Slides Lecture 6 PDF Lecture 6 PPTX Associated Materials Labs Lab3 Notebook Advanced Sections Advanced Section 1 Slides PDF Advanced Section 1 Notes PDF Advanced Section 2 Optimal Transport notes slides PDF Advanced Section 2 Optimal Transport notes PDF Advanced Section 2 Intro to optimization Notes PDF","tags":"lectures","url":"lectures/lecture6/"},{"title":"Lecture 5: Review of NN from 109A","text":"Slides Lecture 5 PDF Lecture 5 PPTX Associated Materials Labs Lab3 Notebook","tags":"lectures","url":"lectures/lecture5/"},{"title":"Lab 2: Smooths and GAMs","text":"Lab 2 Notebooks Lab2 Smooths and GAMs Lab2 Smooths and GAMs with solutions","tags":"labs","url":"labs/lab2/"},{"title":"Lab 2: Smooths and GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models Harvard University Spring 2019 Instructors: Mark Glickman and Pavlos Protopapas Lab Instructors: Will Claybaugh Contributors: Paul Tyklin and Will Claybaugh In [ ]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Learning Goals The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves. Key Skills: Importing (base) R functions Importing R library functions Populating vectors R understands Populating dataframes R understands Populating formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation In [ ]: import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Linear/Polynomial Regression (Python, Review) Hopefully, you remember working with Statsmodels during 109a Reading data and (some) exploring in Pandas: In [ ]: diab = pd . read_csv ( \"data/diabetes.csv\" ) print ( \"\"\" # Variables are: # subject: subject ID number # age: age diagnosed with diabetes # acidity: a measure of acidity called base deficit # y: natural log of serum C-peptide concentration # # Original source is Sockett et al. (1987) # mentioned in Hastie and Tibshirani's book # \"Generalized Additive Models\". \"\"\" ) display ( diab . head ()) display ( diab . dtypes ) display ( diab . describe ()) Plotting with matplotlib: In [ ]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear regression with statsmodels. Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). Now, Statsmodels' formula interface can help build the target value and design matrix for you. In [ ]: #Using statsmodels import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Build a data frame to predict values on (sometimes this is just the test or validation set) Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set In [ ]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [ ]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Plot the model and error bars In [ ]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Discussion What are the dark error bars? What are the light error bars? Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars Route1: Build a design df with a column for each of age , age**2 , age**3 Route2: Just edit the formula Answers : 1. In [ ]: # your code here In [ ]: fit2_lm = sm . ols ( formula = \"y ~ age + np.power(age, 2) + np.power(age, 3)\" , data = diab ) . fit () poly_predictions = fit2_lm . get_prediction ( predict_df ) . summary_frame () poly_predictions . head () 2. In [ ]: # your code here In [ ]: ax2 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares cubic fit\" ) ax2 . set_xlabel ( \"Age at Diagnosis\" ) ax2 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean' ], color = \"green\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax2 . plot ( predict_df . age , poly_predictions [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax2 . plot ( predict_df . age , poly_predictions [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Linear/Polynomial Regression, but make it R This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R. What we need to know: Importing (base) R functions Importing R Library functions Populating vectors R understands Populating DataFrames R understands Populating Formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation Importing R functions In [ ]: # if you're on JupyterHub you may need to specify the path to R #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2.robjects as robjects In [ ]: r_lm = robjects . r [ \"lm\" ] r_predict = robjects . r [ \"predict\" ] #r_plot = robjects.r[\"plot\"] # more on plotting later #lm() and predict() are two of the most common functions we'll use Importing R libraries In [ ]: from rpy2.robjects.packages import importr #r_cluster = importr('cluster') #r_cluster.pam; Populating vectors R understands In [ ]: r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) # What happens if we pass the wrong type? # How does r_age display? # How does r_age print? Populating Data Frames R understands In [ ]: diab_r = robjects . DataFrame ({ \"y\" : r_y , \"age\" : r_age }) # How does diab_r display? # How does diab_r print? Populating formulas R understands In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) simple_formula . environment [ \"y\" ] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to simple_formula . environment [ \"age\" ] = r_age Running Models in R In [ ]: diab_lm = r_lm ( formula = simple_formula ) # the formula object is storing all the needed variables In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) # reset the formula diab_lm = r_lm ( formula = simple_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe Getting results back to Python In [ ]: diab_lm #the result is already 'in' python, but it's a special object In [ ]: print ( diab_lm . names ) # view all names In [ ]: diab_lm [ 0 ] #grab the first element In [ ]: diab_lm . rx2 ( \"coefficients\" ) #use rx2 to get elements by name! In [ ]: np . array ( diab_lm . rx2 ( \"coefficients\" )) #r vectors can be converted to numpy (but rarely needed) Getting Predictions In [ ]: # make a df to predict on (might just be the validation or test dataframe) predict_df = robjects . DataFrame ({ \"age\" : robjects . FloatVector ( np . linspace ( 0 , 16 , 100 ))}) # call R's predict() function, passing the model and the data predictions = r_predict ( diab_lm , predict_df ) In [ ]: x_vals = predict_df . rx2 ( \"age\" ) In [ ]: ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); #plt still works with r vectors as input! Plotting in R In [ ]: % load_ext rpy2.ipython The above turns on the %R \"magic\" R's plot() command responds differently based on what you hand to it; Different models get different plots! For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely Ahead of the plot( ) code we pass in the variables R needs to know about ( -i is for \"input\") In [ ]: % R -i diab_lm plot(diab_lm); Reading R's documentation The documentation for the lm() funciton is here , and a prettier version (same content) is here . When googling, perfer rdocumentation.org when possible. Sections: Usage : gives the function signature, including all optional arguments Arguments : What each function input controls Details : additional info on what the funciton does and how arguments interact. Often the right place to start reading Value : the structure of the object returned by the function Refferences : The relevant academic papers See Also : other functions of interest Exercise 2 Add confidence intervals calculated in R to the linear regression plot above. Use the interval= argument to r_predict() (documentation here ). You will have to work with a matrix returned by R. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms. Answers 1. In [ ]: # your code here In [ ]: CI_matrix = np . array ( r_predict ( diab_lm , predict_df , interval = \"confidence\" )) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , CI_matrix [:, 0 ], label = \"prediction\" ) ax . plot ( x_vals , CI_matrix [:, 1 ], label = \"95% CI\" , c = 'g' ) ax . plot ( x_vals , CI_matrix [:, 2 ], label = \"95% CI\" , c = 'g' ) plt . legend (); 2. In [ ]: # your code here In [ ]: ploy5_formula = robjects . Formula ( \"y~poly(age,5)\" ) # reset the formula diab5_lm = r_lm ( formula = ploy5_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe predictions = r_predict ( diab5_lm , predict_df , interval = \"confidence\" ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); Lowess Smoothing Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. Discussion What is lowess smoothing? Which 109a models is it related to? How explainable is lowess? What are the tunable parameters? In Python In [ ]: from statsmodels.nonparametric.smoothers_lowess import lowess as lowess ss1 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.15 ) ss2 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.25 ) ss3 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.7 ) ss4 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 1 ) In [ ]: ss1 [: 10 ,:] # we get back simple a smoothed y value for each x value in the data Notice the clean code to plot different models. We'll see even cleaner code in a minute In [ ]: for cur_model , cur_frac in zip ([ ss1 , ss2 , ss3 , ss4 ],[ 0.15 , 0.25 , 0.7 , 1 ]): ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model [:, 0 ], cur_model [:, 1 ], color = \"blue\" ) plt . show () Discussion Which model has high variance, which has high bias? What makes a model high variance or high bias? In R We need to: Import the loess function Send data over to R Call the function and get results In [ ]: r_loess = robjects . r [ 'loess.smooth' ] #extract R function r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) ss1_r = r_loess ( r_age , r_y , span = 0.15 , degree = 1 ) In [ ]: ss1_r #again, a smoothed y value for each x value in the data Exercise 3 Predict the output of ss1_r[0] ss1_r.rx2(\"y\") 1. your answer here 2. your answer here Varying span Next, some extremely clean code to fit and plot models with various parameter settings. (Though the zip() method seen earlier is great when e.g. the label and the parameter differ) In [ ]: for cur_frac in [ 0.15 , 0.25 , 0.7 , 1 ]: cur_smooth = r_loess ( r_age , r_y , span = cur_frac ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_smooth [ 0 ], cur_smooth [ 1 ], color = \"blue\" ) plt . show () Discussion Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts? Why isn't the bottom plot a straight line? We're using 100% of the data in each window... Smoothing Splines From this point forward, we're working with R functions; these models aren't (well) supported in Python. For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point Discussion Any idea why the winner is cubic? How interpretable is this model? What are the tunable parameters? In [ ]: r_smooth_spline = robjects . r [ 'smooth.spline' ] #extract R function # run smoothing function spline1 = r_smooth_spline ( r_age , r_y , spar = 0 ) Exercise 4 We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$ Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title. 1. In [ ]: # your answer here In [ ]: lambda1 = spline1 . rx2 ( \"lambda\" ) 2. In [ ]: # your answer here In [ ]: for cur_spar in [ 0 , 0.5 , 0.9 , 2 ]: cur_model = r_smooth_spline ( r_age , r_y , spar = cur_spar ) cur_lambda = cur_model . rx2 ( \"lambda\" )[ 0 ] ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"$\\lambda=$\" + str ( cur_lambda )) #can use TeX style in labels ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model . rx2 ( \"x\" ), cur_model . rx2 ( \"y\" ), color = \"darkgreen\" ) plt . show () CV R's smooth_spline funciton has built-in CV to find a good lambda. See package docs . In [ ]: spline_cv = r_smooth_spline ( r_age , r_y , cv = True ) lambda_cv = spline_cv . rx2 ( \"lambda\" )[ 0 ] ax19 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"smoothing spline with $\\lambda=$\" + str ( np . round ( lambda_cv , 4 )) + \", chosen by cross-validation\" ) ax19 . set_xlabel ( \"Age at Diagnosis\" ) ax19 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax19 . plot ( spline_cv . rx2 ( \"x\" ), spline_cv . rx2 ( \"y\" ), color = \"darkgreen\" ); Discussion Does the selected model look reasonable? How would you describe the effect of age at diagnosis on C_peptide concentration? What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above? Natural & Basis Splines Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames. Discussion In what way are Natural and Basis splines less complex than the splines we were just working with? What makes a spline 'natural'? What makes a spline 'basis'? What are the tuning parameters? In [ ]: #We will now work with a new dataset, called GAGurine. #The dataset description (from the R package MASS) is below: #Data were collected on the concentration of a chemical GAG # in the urine of 314 children aged from zero to seventeen years. # The aim of the study was to produce a chart to help a paediatrican # to assess if a child's GAG concentration is ‘normal'. #The variables are: # Age: age of child in years. # GAG: concentration of GAG (the units have been lost). In [ ]: GAGurine = pd . read_csv ( \"data/GAGurine.csv\" ) display ( GAGurine . head ()) ax31 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'black' , title = \"GAG in urine of children\" ) ax31 . set_xlabel ( \"Age\" ); ax31 . set_ylabel ( \"GAG\" ); Standard stuff: import function, convert variables to R format, call function In [ ]: from rpy2.robjects.packages import importr r_splines = importr ( 'splines' ) # populate R variables r_gag = robjects . FloatVector ( GAGurine [ 'GAG' ] . values ) r_age = robjects . FloatVector ( GAGurine [ 'Age' ] . values ) r_quarts = robjects . FloatVector ( np . quantile ( r_age ,[ . 25 , . 5 , . 75 ])) #woah, numpy functions run on R objects! What happens when we call the ns or bs functions from r_splines? In [ ]: ns_design = r_splines . ns ( r_age , knots = r_quarts ) bs_design = r_splines . bs ( r_age , knots = r_quarts ) In [ ]: print ( ns_design ) ns and bs return design matrices, not model objects! That's because they're meant to work with lm 's formula interface. To get a model object we populate a formula including ns( , ) and fit to data In [ ]: r_lm = robjects . r [ 'lm' ] r_predict = robjects . r [ 'predict' ] # populate the formula ns_formula = robjects . Formula ( \"Gag ~ ns(Age, knots=r_quarts)\" ) ns_formula . environment [ 'Gag' ] = r_gag ns_formula . environment [ 'Age' ] = r_age ns_formula . environment [ 'r_quarts' ] = r_quarts # fit the model ns_model = r_lm ( ns_formula ) Predict like usual: build a dataframe to predict on and call predict() In [ ]: # predict predict_frame = robjects . DataFrame ({ \"Age\" : robjects . FloatVector ( np . linspace ( 0 , 20 , 100 ))}) ns_out = r_predict ( ns_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" ]); Exercise 5 Fit a basis spline model with the same knots, and add it to the plot above Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above Answers: 1. In [ ]: # your answer here In [ ]: bs_formula = robjects . Formula ( \"Gag ~ bs(Age, knots=r_quarts)\" ) bs_formula . environment [ 'Gag' ] = r_gag bs_formula . environment [ 'Age' ] = r_age bs_formula . environment [ 'r_quarts' ] = r_quarts bs_model = r_lm ( bs_formula ) bs_out = r_predict ( bs_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), bs_out , color = 'blue' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" , \"B-spline, knots at quartiles\" ]); 2. In [ ]: # your answer here In [ ]: overfit_formula = robjects . Formula ( \"Gag ~ bs(Age, knots=r_quarts)\" ) overfit_formula . environment [ 'Gag' ] = r_gag overfit_formula . environment [ 'Age' ] = r_age overfit_formula . environment [ 'r_quarts' ] = robjects . FloatVector ( np . array ([ 2 , 4 , 6 , 8 , 10 , 12 , 14 , 16 ])) overfit_model = r_lm ( overfit_formula ) overfit_out = r_predict ( overfit_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), bs_out , color = 'blue' ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), overfit_out , color = 'green' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" , \"B-spline, knots at quartiles\" , \"B-spline, lots of knots\" ]); In [ ]: #%R -i overfit_model plot(overfit_model) # we'd get the same diagnostic plot we get from an lm model GAMs We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome. First, let's get our (multivariate!) data In [ ]: kyphosis = pd . read_csv ( \"data/kyphosis.csv\" ) print ( \"\"\" # kyphosis - wherther a particular deformation was present post-operation # age - patient's age in months # number - the number of vertebrae involved in the operation # start - the number of the topmost vertebrae operated on \"\"\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) In [ ]: #If there are errors about missing R packages, run the code below: #r_utils = importr('utils') #r_utils.install_packages('codetools') #r_utils.install_packages('gam') To fit a GAM, we Import the gam library Populate a formula including s( ) on variables we want to fit smooths for Call gam(formula, family= ) where family is a string naming a probability distribution, chosen based on how the response variable is thought to occur. Rough family guidelines: Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose \"binomial\" Response is a count with no logical upper bound, e.g. number of ice creams sold: choose \"poisson\" Response is real, with normally-distributed noise, e.g. person's height: choose \"gaussian\" (the default) In [ ]: #There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM) # but it is not yet as comprehensive as the R GAM library, which we will use here instead. # R also has the mgcv library, which implements some more advanced/flexible fitting methods r_gam_lib = importr ( 'gam' ) r_gam = r_gam_lib . gam r_kyph = robjects . FactorVector ( kyphosis [[ \"Kyphosis\" ]] . values ) r_Age = robjects . FloatVector ( kyphosis [[ \"Age\" ]] . values ) r_Number = robjects . FloatVector ( kyphosis [[ \"Number\" ]] . values ) r_Start = robjects . FloatVector ( kyphosis [[ \"Start\" ]] . values ) kyph1_fmla = robjects . Formula ( \"Kyphosis ~ s(Age) + s(Number) + s(Start)\" ) kyph1_fmla . environment [ 'Kyphosis' ] = r_kyph kyph1_fmla . environment [ 'Age' ] = r_Age kyph1_fmla . environment [ 'Number' ] = r_Number kyph1_fmla . environment [ 'Start' ] = r_Start kyph1_gam = r_gam ( kyph1_fmla , family = \"binomial\" ) The fitted gam model has a lot of interesting data within it In [ ]: print ( kyph1_gam . names ) Remember plotting? Calling R's plot() on a gam model is the easiest way to view the fitted splines In [ ]: % R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20); Prediction works like normal (build a data frame to predict on, if you don't already have one, and call predict() ). However, predict always reports the sum of the individual variable effects. If family is non-default this can be different from the actual prediction for that point. For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in predict(..., type=\"response\") In [ ]: kyph_new = robjects . DataFrame ({ 'Age' : robjects . IntVector (( 84 , 85 , 86 )), 'Start' : robjects . IntVector (( 5 , 3 , 1 )), 'Number' : robjects . IntVector (( 1 , 6 , 10 ))}) print ( \"Raw response (so, Log odds):\" ) display ( r_predict ( kyph1_gam , kyph_new )) print ( \"Scaled response (so, probabilty of kyphosis):\" ) display ( r_predict ( kyph1_gam , kyph_new , type = \"response\" )) Discussion Exercise 6 What lambda did we use? What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM? Critique the model: What is it assuming? Are the assumptions reasonable Are we using the right data? Does the model's story about the world make sense? Appendix GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training and still compare the quality of model A to model B) In [ ]: r_anova = robjects . r [ \"anova\" ] kyph0_fmla = robjects . Formula ( \"Kyphosis~1\" ) kyph0_fmla . environment [ 'Kyphosis' ] = r_kyph kyph0_gam = r_gam ( kyph0_fmla , family = \"binomial\" ) print ( r_anova ( kyph0_gam , kyph1_gam , test = \"Chi\" )) Explicitly joining spline functions In [ ]: def h ( x , xi , pow_arg ): #pow is a reserved keyword in Python if ( x > xi ): return pow (( x - xi ), pow_arg ) else : return 0 h = np . vectorize ( h , otypes = [ np . float ]) #default behavior is to return ints, which gives incorrect answer #also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1) In [ ]: xvals = np . arange ( 0 , 10.1 , 0.1 ) ax20 = plt . plot ( xvals , h ( xvals , 4 , 1 ), color = \"red\" ) _ = plt . title ( \"Truncated linear basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+$\" ) #note the use of TeX in the label In [ ]: ax21 = plt . plot ( xvals , h ( xvals , 4 , 3 ), color = \"red\" ) _ = plt . title ( \"Truncated cubic basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+&#94;3$\" ) In [ ]: ax22 = plt . plot ( xvals , 2 + xvals + 3 * h ( xvals , 2 , 1 ) - 4 * h ( xvals , 5 , 1 ) + 0.5 * h ( xvals , 8 , 1 ), color = \"red\" ) _ = plt . title ( \"Piecewise linear spline with knots at x=2, 5, and 8\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) Comparing splines to the (noisy) model that generated them. In [ ]: x = np . arange ( 0.1 , 10 , 9.9 / 100 ) from scipy.stats import norm #ppf (percent point function) is the rather unusual name for #the quantile or inverse CDF function in SciPy y = norm . ppf ( x / 10 ) + np . random . normal ( 0 , 0.4 , 100 ) ax23 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax24 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax25 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr = 'y~x+' for i in range ( 1 , 26 ): regstr += 'h(x,' + str ( i / 26 * 10 ) + ',1)+' regstr = regstr [: - 1 ] #drop last + ax26 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) Exercise: Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe? In [ ]: # try it here In [ ]: #So, we see that increasing the number of knots results in a more polynomial-like fit In [ ]: #Next, we look at cubic splines with increasing numbers of knots ax27 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax28 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax29 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+' for i in range ( 1 , 26 ): regstr2 += 'h(x,' + str ( i / 26 * 10 ) + ',3)+' regstr2 = regstr2 [: - 1 ] #drop last + ax30 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr2 , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab2/solutions/"},{"title":"Lab 2: Smooths and GAMs","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } CS109B Data Science 2: Advanced Topics in Data Science Lab 2 - Smoothers and Generalized Additive Models Harvard University Spring 2019 Instructors: Mark Glickman and Pavlos Protopapas Lab Instructors: Will Claybaugh Contributors: Paul Tyklin and Will Claybaugh In [1]: ## RUN THIS CELL TO PROPERLY HIGHLIGHT THE EXERCISES import requests from IPython.core.display import HTML styles = requests . get ( \"https://raw.githubusercontent.com/Harvard-IACS/2019-CS109B/master/content/styles/cs109.css\" ) . text HTML ( styles ) Out[1]: blockquote { background: #AEDE94; } h1 { padding-top: 25px; padding-bottom: 25px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } h2 { padding-top: 10px; padding-bottom: 10px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } div.exercise { background-color: #ffcccc; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; } div.discussion { background-color: #ccffcc; border-color: #88E97A; border-left: 5px solid #0A8000; padding: 0.5em; } div.theme { background-color: #DDDDDD; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 18pt; } div.gc { background-color: #AEDE94; border-color: #E9967A; border-left: 5px solid #800080; padding: 0.5em; font-size: 12pt; } p.q1 { padding-top: 5px; padding-bottom: 5px; text-align: left; padding-left: 5px; background-color: #EEEEEE; color: black; } header { padding-top: 35px; padding-bottom: 35px; text-align: left; padding-left: 10px; background-color: #DDDDDD; color: black; } Learning Goals The main goal of this lab is to get familiar with calling R functions within Python. Along the way, we'll learn about the \"formula\" interface to statsmodels, which gives an intuitive way of specifying regression models, and we'll review the different approaches to fitting curves. Key Skills: Importing (base) R functions Importing R library functions Populating vectors R understands Populating dataframes R understands Populating formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation In [ ]: import numpy as np import pandas as pd import matplotlib.pyplot as plt % matplotlib inline Linear/Polynomial Regression (Python, Review) Hopefully, you remember working with Statsmodels during 109a Reading data and (some) exploring in Pandas: In [ ]: diab = pd . read_csv ( \"data/diabetes.csv\" ) print ( \"\"\" # Variables are: # subject: subject ID number # age: age diagnosed with diabetes # acidity: a measure of acidity called base deficit # y: natural log of serum C-peptide concentration # # Original source is Sockett et al. (1987) # mentioned in Hastie and Tibshirani's book # \"Generalized Additive Models\". \"\"\" ) display ( diab . head ()) display ( diab . dtypes ) display ( diab . describe ()) Plotting with matplotlib: In [ ]: ax0 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) #plotting direclty from pandas! ax0 . set_xlabel ( \"Age at Diagnosis\" ) ax0 . set_ylabel ( \"Log C-Peptide Concentration\" ); Linear regression with statsmodels. Previously, we worked from a vector of target values and a design matrix we built ourself (e.g. from PolynomialFeatures). Now, Statsmodels' formula interface can help build the target value and design matrix for you. In [ ]: #Using statsmodels import statsmodels.formula.api as sm model1 = sm . ols ( 'y ~ age' , data = diab ) fit1_lm = model1 . fit () Build a data frame to predict values on (sometimes this is just the test or validation set) Very useful for making pretty plots of the model predcitions -- predict for TONS of values, not just whatever's in the training set In [ ]: x_pred = np . linspace ( 0 , 16 , 100 ) predict_df = pd . DataFrame ( data = { \"age\" : x_pred }) predict_df . head () Use get_prediction( ).summary_frame() to get the model's prediction (and error bars!) In [ ]: prediction_output = fit1_lm . get_prediction ( predict_df ) . summary_frame () prediction_output . head () Plot the model and error bars In [ ]: ax1 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data with least-squares linear fit\" ) ax1 . set_xlabel ( \"Age at Diagnosis\" ) ax1 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean' ], color = \"green\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_lower' ], color = \"blue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'mean_ci_upper' ], color = \"blue\" , linestyle = \"dashed\" ); ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_lower' ], color = \"skyblue\" , linestyle = \"dashed\" ) ax1 . plot ( predict_df . age , prediction_output [ 'obs_ci_upper' ], color = \"skyblue\" , linestyle = \"dashed\" ); Discussion What are the dark error bars? What are the light error bars? Exercise 1 Fit a 3rd degree polynomial model and plot the model+error bars Route1: Build a design df with a column for each of age , age**2 , age**3 Route2: Just edit the formula Answers : 1. In [ ]: # your code here 2. In [ ]: # your code here Linear/Polynomial Regression, but make it R This is the meat of the lab. After this section we'll know everything we need to in order to work with R models. The rest of the lab is just applying these concepts to run particular models. This section therefore is your 'cheat sheet' for working in R. What we need to know: Importing (base) R functions Importing R Library functions Populating vectors R understands Populating DataFrames R understands Populating Formulas R understands Running models in R Getting results back to Python Getting model predictions in R Plotting in R Reading R's documentation Importing R functions In [ ]: # if you're on JupyterHub you may need to specify the path to R #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2.robjects as robjects In [ ]: r_lm = robjects . r [ \"lm\" ] r_predict = robjects . r [ \"predict\" ] #r_plot = robjects.r[\"plot\"] # more on plotting later #lm() and predict() are two of the most common functions we'll use Importing R libraries In [ ]: from rpy2.robjects.packages import importr #r_cluster = importr('cluster') #r_cluster.pam; Populating vectors R understands In [ ]: r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) # What happens if we pass the wrong type? # How does r_age display? # How does r_age print? Populating Data Frames R understands In [ ]: diab_r = robjects . DataFrame ({ \"y\" : r_y , \"age\" : r_age }) # How does diab_r display? # How does diab_r print? Populating formulas R understands In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) simple_formula . environment [ \"y\" ] = r_y #populate the formula's .environment, so it knows what 'y' and 'age' refer to simple_formula . environment [ \"age\" ] = r_age Running Models in R In [ ]: diab_lm = r_lm ( formula = simple_formula ) # the formula object is storing all the needed variables In [ ]: simple_formula = robjects . Formula ( \"y~age\" ) # reset the formula diab_lm = r_lm ( formula = simple_formula , data = diab_r ) #can also use a 'dumb' formula and pass a dataframe Getting results back to Python In [ ]: diab_lm #the result is already 'in' python, but it's a special object In [ ]: print ( diab_lm . names ) # view all names In [ ]: diab_lm [ 0 ] #grab the first element In [ ]: diab_lm . rx2 ( \"coefficients\" ) #use rx2 to get elements by name! In [ ]: np . array ( diab_lm . rx2 ( \"coefficients\" )) #r vectors can be converted to numpy (but rarely needed) Getting Predictions In [ ]: # make a df to predict on (might just be the validation or test dataframe) predict_df = robjects . DataFrame ({ \"age\" : robjects . FloatVector ( np . linspace ( 0 , 16 , 100 ))}) # call R's predict() function, passing the model and the data predictions = r_predict ( diab_lm , predict_df ) In [ ]: x_vals = predict_df . rx2 ( \"age\" ) In [ ]: ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Diabetes data\" ) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ); ax . plot ( x_vals , predictions ); #plt still works with r vectors as input! Plotting in R In [ ]: % load_ext rpy2.ipython The above turns on the %R \"magic\" R's plot() command responds differently based on what you hand to it; Different models get different plots! For any specific model search for plot.modelname. E.g. for a GAM model, search plot.gam for any details of plotting a GAM model The %R \"magic\" runs R code in 'notebook' mode, so figures display nicely Ahead of the plot( ) code we pass in the variables R needs to know about ( -i is for \"input\") In [ ]: % R -i diab_lm plot(diab_lm); Reading R's documentation The documentation for the lm() funciton is here , and a prettier version (same content) is here . When googling, perfer rdocumentation.org when possible. Sections: Usage : gives the function signature, including all optional arguments Arguments : What each function input controls Details : additional info on what the funciton does and how arguments interact. Often the right place to start reading Value : the structure of the object returned by the function Refferences : The relevant academic papers See Also : other functions of interest Exercise 2 Add confidence intervals calculated in R to the linear regression plot above. Use the interval= argument to r_predict() (documentation here ). You will have to work with a matrix returned by R. Fit a 5th degree polynomial to the diabetes data in R. Search the web for an easier method than writing out a formula with all 5 polynomial terms. Answers 1. In [ ]: # your code here 2. In [ ]: # your code here Lowess Smoothing Lowess Smoothing is implemented in both Python and R. We'll use it as another example as we transition languages. Discussion What is lowess smoothing? Which 109a models is it related to? How explainable is lowess? What are the tunable parameters? In Python In [ ]: from statsmodels.nonparametric.smoothers_lowess import lowess as lowess ss1 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.15 ) ss2 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.25 ) ss3 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 0.7 ) ss4 = lowess ( diab [ 'y' ], diab [ 'age' ], frac = 1 ) In [ ]: ss1 [: 10 ,:] # we get back simple a smoothed y value for each x value in the data Notice the clean code to plot different models. We'll see even cleaner code in a minute In [ ]: for cur_model , cur_frac in zip ([ ss1 , ss2 , ss3 , ss4 ],[ 0.15 , 0.25 , 0.7 , 1 ]): ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_model [:, 0 ], cur_model [:, 1 ], color = \"blue\" ) plt . show () Discussion Which model has high variance, which has high bias? What makes a model high variance or high bias? In R We need to: Import the loess function Send data over to R Call the function and get results In [ ]: r_loess = robjects . r [ 'loess.smooth' ] #extract R function r_y = robjects . FloatVector ( diab [ 'y' ]) r_age = robjects . FloatVector ( diab [ 'age' ]) ss1_r = r_loess ( r_age , r_y , span = 0.15 , degree = 1 ) In [ ]: ss1_r #again, a smoothed y value for each x value in the data Exercise 3 Predict the output of ss1_r[0] ss1_r.rx2(\"y\") 1. your answer here 2. your answer here Varying span Next, some extremely clean code to fit and plot models with various parameter settings. (Though the zip() method seen earlier is great when e.g. the label and the parameter differ) In [ ]: for cur_frac in [ 0.15 , 0.25 , 0.7 , 1 ]: cur_smooth = r_loess ( r_age , r_y , span = cur_frac ) ax = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"Lowess Fit, Fraction = {} \" . format ( cur_frac )) ax . set_xlabel ( \"Age at Diagnosis\" ) ax . set_ylabel ( \"Log C-Peptide Concentration\" ) ax . plot ( cur_smooth [ 0 ], cur_smooth [ 1 ], color = \"blue\" ) plt . show () Discussion Mark wasn't kidding; the Python and R results differ for frac=.15. Thoughts? Why isn't the bottom plot a straight line? We're using 100% of the data in each window... Smoothing Splines From this point forward, we're working with R functions; these models aren't (well) supported in Python. For clarity: this is the fancy spline model that minimizes $MSE - \\lambda\\cdot\\text{wiggle penalty}$ $=$ $\\sum_{i=1}&#94;N \\left(y_i - f(x_i)\\right)&#94;2 - \\lambda \\int \\left(f''(x)\\right)&#94;2$, across all possible functions $f$. The winner will always be a continuous, cubic polynomial with a knot at each data point Discussion Any idea why the winner is cubic? How interpretable is this model? What are the tunable parameters? In [ ]: r_smooth_spline = robjects . r [ 'smooth.spline' ] #extract R function # run smoothing function spline1 = r_smooth_spline ( r_age , r_y , spar = 0 ) Exercise 4 We actually set the spar parameter, a scale-free value that translates to a $\\lambda$ through a complex expression. Inspect the 'spline1' result and extract the implied value of $\\lambda$ Working from the fitting/plotting loop examples above, produce a plot like the one below for spar = [0,.5,.9,2], including axes labels and title. 1. In [ ]: # your answer here 2. In [ ]: # your answer here CV R's smooth_spline funciton has built-in CV to find a good lambda. See package docs . In [ ]: spline_cv = r_smooth_spline ( r_age , r_y , cv = True ) lambda_cv = spline_cv . rx2 ( \"lambda\" )[ 0 ] ax19 = diab . plot . scatter ( x = 'age' , y = 'y' , c = 'Red' , title = \"smoothing spline with $\\lambda=$\" + str ( np . round ( lambda_cv , 4 )) + \", chosen by cross-validation\" ) ax19 . set_xlabel ( \"Age at Diagnosis\" ) ax19 . set_ylabel ( \"Log C-Peptide Concentration\" ) ax19 . plot ( spline_cv . rx2 ( \"x\" ), spline_cv . rx2 ( \"y\" ), color = \"darkgreen\" ); Discussion Does the selected model look reasonable? How would you describe the effect of age at diagnosis on C_peptide concentration? What are the costs/benefits of the (fancy) spline model, relative to the linear regression we fit above? Natural & Basis Splines Here, we take a step backward on model complexity, but a step forward in coding complexity. We'll be working with R's formula interface again, so we will need to populate Formulas and DataFrames. Discussion In what way are Natural and Basis splines less complex than the splines we were just working with? What makes a spline 'natural'? What makes a spline 'basis'? What are the tuning parameters? In [ ]: #We will now work with a new dataset, called GAGurine. #The dataset description (from the R package MASS) is below: #Data were collected on the concentration of a chemical GAG # in the urine of 314 children aged from zero to seventeen years. # The aim of the study was to produce a chart to help a paediatrican # to assess if a child's GAG concentration is ‘normal'. #The variables are: # Age: age of child in years. # GAG: concentration of GAG (the units have been lost). In [ ]: GAGurine = pd . read_csv ( \"data/GAGurine.csv\" ) display ( GAGurine . head ()) ax31 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'black' , title = \"GAG in urine of children\" ) ax31 . set_xlabel ( \"Age\" ); ax31 . set_ylabel ( \"GAG\" ); Standard stuff: import function, convert variables to R format, call function In [ ]: from rpy2.robjects.packages import importr r_splines = importr ( 'splines' ) # populate R variables r_gag = robjects . FloatVector ( GAGurine [ 'GAG' ] . values ) r_age = robjects . FloatVector ( GAGurine [ 'Age' ] . values ) r_quarts = robjects . FloatVector ( np . quantile ( r_age ,[ . 25 , . 5 , . 75 ])) #woah, numpy functions run on R objects! What happens when we call the ns or bs functions from r_splines? In [ ]: ns_design = r_splines . ns ( r_age , knots = r_quarts ) bs_design = r_splines . bs ( r_age , knots = r_quarts ) In [ ]: print ( ns_design ) ns and bs return design matrices, not model objects! That's because they're meant to work with lm 's formula interface. To get a model object we populate a formula including ns( , ) and fit to data In [ ]: r_lm = robjects . r [ 'lm' ] r_predict = robjects . r [ 'predict' ] # populate the formula ns_formula = robjects . Formula ( \"Gag ~ ns(Age, knots=r_quarts)\" ) ns_formula . environment [ 'Gag' ] = r_gag ns_formula . environment [ 'Age' ] = r_age ns_formula . environment [ 'r_quarts' ] = r_quarts # fit the model ns_model = r_lm ( ns_formula ) Predict like usual: build a dataframe to predict on and call predict() In [ ]: # predict predict_frame = robjects . DataFrame ({ \"Age\" : robjects . FloatVector ( np . linspace ( 0 , 20 , 100 ))}) ns_out = r_predict ( ns_model , predict_frame ) In [ ]: ax32 = GAGurine . plot . scatter ( x = 'Age' , y = 'GAG' , c = 'grey' , title = \"GAG in urine of children\" ) ax32 . set_xlabel ( \"Age\" ) ax32 . set_ylabel ( \"GAG\" ) ax32 . plot ( predict_frame . rx2 ( \"Age\" ), ns_out , color = 'red' ) ax32 . legend ([ \"Natural spline, knots at quartiles\" ]); Exercise 5 Fit a basis spline model with the same knots, and add it to the plot above Fit a basis spline with 8 knots placed at [2,4,6...14,16] and add it to the plot above Answers: 1. In [ ]: # your answer here 2. In [ ]: # your answer here In [ ]: #%R -i overfit_model plot(overfit_model) # we'd get the same diagnostic plot we get from an lm model GAMs We come, at last, to our most advanced model. The coding here isn't any more complex than we've done before, though the behind-the-scenes is awesome. First, let's get our (multivariate!) data In [ ]: kyphosis = pd . read_csv ( \"data/kyphosis.csv\" ) print ( \"\"\" # kyphosis - wherther a particular deformation was present post-operation # age - patient's age in months # number - the number of vertebrae involved in the operation # start - the number of the topmost vertebrae operated on \"\"\" ) display ( kyphosis . head ()) display ( kyphosis . describe ( include = 'all' )) display ( kyphosis . dtypes ) In [ ]: #If there are errors about missing R packages, run the code below: #r_utils = importr('utils') #r_utils.install_packages('codetools') #r_utils.install_packages('gam') To fit a GAM, we Import the gam library Populate a formula including s( ) on variables we want to fit smooths for Call gam(formula, family= ) where family is a string naming a probability distribution, chosen based on how the response variable is thought to occur. Rough family guidelines: Response is binary or \"N occurances out of M tries\", e.g. number of lab rats (out of 10) developing disease: chooose \"binomial\" Response is a count with no logical upper bound, e.g. number of ice creams sold: choose \"poisson\" Response is real, with normally-distributed noise, e.g. person's height: choose \"gaussian\" (the default) In [ ]: #There is a Python library in development for using GAMs (https://github.com/dswah/pyGAM) # but it is not yet as comprehensive as the R GAM library, which we will use here instead. # R also has the mgcv library, which implements some more advanced/flexible fitting methods r_gam_lib = importr ( 'gam' ) r_gam = r_gam_lib . gam r_kyph = robjects . FactorVector ( kyphosis [[ \"Kyphosis\" ]] . values ) r_Age = robjects . FloatVector ( kyphosis [[ \"Age\" ]] . values ) r_Number = robjects . FloatVector ( kyphosis [[ \"Number\" ]] . values ) r_Start = robjects . FloatVector ( kyphosis [[ \"Start\" ]] . values ) kyph1_fmla = robjects . Formula ( \"Kyphosis ~ s(Age) + s(Number) + s(Start)\" ) kyph1_fmla . environment [ 'Kyphosis' ] = r_kyph kyph1_fmla . environment [ 'Age' ] = r_Age kyph1_fmla . environment [ 'Number' ] = r_Number kyph1_fmla . environment [ 'Start' ] = r_Start kyph1_gam = r_gam ( kyph1_fmla , family = \"binomial\" ) The fitted gam model has a lot of interesting data within it In [ ]: print ( kyph1_gam . names ) Remember plotting? Calling R's plot() on a gam model is the easiest way to view the fitted splines In [ ]: % R -i kyph1_gam plot(kyph1_gam, residuals=TRUE,se=TRUE, scale=20); Prediction works like normal (build a data frame to predict on, if you don't already have one, and call predict() ). However, predict always reports the sum of the individual variable effects. If family is non-default this can be different from the actual prediction for that point. For instance, we're doing a 'logistic regression' so the raw prediction is log odds, but we can get probability by using in predict(..., type=\"response\") In [ ]: kyph_new = robjects . DataFrame ({ 'Age' : robjects . IntVector (( 84 , 85 , 86 )), 'Start' : robjects . IntVector (( 5 , 3 , 1 )), 'Number' : robjects . IntVector (( 1 , 6 , 10 ))}) print ( \"Raw response (so, Log odds):\" ) display ( r_predict ( kyph1_gam , kyph_new )) print ( \"Scaled response (so, probabilty of kyphosis):\" ) display ( r_predict ( kyph1_gam , kyph_new , type = \"response\" )) Discussion Exercise 6 What lambda did we use? What is the model telling us about the effects of age, starting vertebrae, and number of vertebae operated on If we fit a logistic regression instead, which variables might want quadratic terms. What is the cost and benefit of a logistic regression model versus a GAM? Critique the model: What is it assuming? Are the assumptions reasonable Are we using the right data? Does the model's story about the world make sense? Appendix GAMs and smoothing splines support hypothesis tets to compare models. (We can always compare models via out-of-sample prediction quality (i.e. performance on a validation set), but statistical ideas like hypothesis tests yet information criteria allow us to use all data for training and still compare the quality of model A to model B) In [ ]: r_anova = robjects . r [ \"anova\" ] kyph0_fmla = robjects . Formula ( \"Kyphosis~1\" ) kyph0_fmla . environment [ 'Kyphosis' ] = r_kyph kyph0_gam = r_gam ( kyph0_fmla , family = \"binomial\" ) print ( r_anova ( kyph0_gam , kyph1_gam , test = \"Chi\" )) Explicitly joining spline functions In [ ]: def h ( x , xi , pow_arg ): #pow is a reserved keyword in Python if ( x > xi ): return pow (( x - xi ), pow_arg ) else : return 0 h = np . vectorize ( h , otypes = [ np . float ]) #default behavior is to return ints, which gives incorrect answer #also, vectorize does not play nicely with default arguments, so better to set directly (e.g., pow_arg=1) In [ ]: xvals = np . arange ( 0 , 10.1 , 0.1 ) ax20 = plt . plot ( xvals , h ( xvals , 4 , 1 ), color = \"red\" ) _ = plt . title ( \"Truncated linear basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+$\" ) #note the use of TeX in the label In [ ]: ax21 = plt . plot ( xvals , h ( xvals , 4 , 3 ), color = \"red\" ) _ = plt . title ( \"Truncated cubic basis function with knot at x=4\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$(x-4)_+&#94;3$\" ) In [ ]: ax22 = plt . plot ( xvals , 2 + xvals + 3 * h ( xvals , 2 , 1 ) - 4 * h ( xvals , 5 , 1 ) + 0.5 * h ( xvals , 8 , 1 ), color = \"red\" ) _ = plt . title ( \"Piecewise linear spline with knots at x=2, 5, and 8\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) Comparing splines to the (noisy) model that generated them. In [ ]: x = np . arange ( 0.1 , 10 , 9.9 / 100 ) from scipy.stats import norm #ppf (percent point function) is the rather unusual name for #the quantile or inverse CDF function in SciPy y = norm . ppf ( x / 10 ) + np . random . normal ( 0 , 0.4 , 100 ) ax23 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,2,1)+h(x,5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax24 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3.5,1)+h(x,5,1)+h(x,6.5,1)+h(x,8,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax25 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+h(x,1,1)+h(x,2,1)+h(x,3,1)+h(x,4,1)+h(x,5,1)+h(x,6,1)+h(x,7,1)+h(x,8,1)+h(x,9,1)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr = 'y~x+' for i in range ( 1 , 26 ): regstr += 'h(x,' + str ( i / 26 * 10 ) + ',1)+' regstr = regstr [: - 1 ] #drop last + ax26 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) Exercise: Try generating random data from different distributions and fitting polynomials of different degrees to it. What do you observe? In [ ]: # try it here In [ ]: #So, we see that increasing the number of knots results in a more polynomial-like fit In [ ]: #Next, we look at cubic splines with increasing numbers of knots ax27 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"3 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,2,3)+h(x,5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax28 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"6 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3.5,3)+h(x,5,3)+h(x,6.5,3)+h(x,8,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: ax29 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"9 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( 'y~x+np.power(x,2)+np.power(x,3)+h(x,1,3)+h(x,2,3)+h(x,3,3)+h(x,4,3)+h(x,5,3)+h(x,6,3)+h(x,7,3)+h(x,8,3)+h(x,9,3)' , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) In [ ]: regstr2 = 'y~x+np.power(x,2)+np.power(x,3)+' for i in range ( 1 , 26 ): regstr2 += 'h(x,' + str ( i / 26 * 10 ) + ',3)+' regstr2 = regstr2 [: - 1 ] #drop last + ax30 = plt . scatter ( x , y , facecolors = 'none' , edgecolors = 'black' ) _ = plt . title ( \"25 knots\" ) _ = plt . xlabel ( \"$x$\" ) _ = plt . ylabel ( \"$y$\" ) _ = plt . plot ( x , sm . ols ( regstr2 , data = { 'x' : x , 'y' : y }) . fit () . predict (), color = \"darkblue\" , linewidth = 2 ) _ = plt . plot ( x , norm . ppf ( x / 10 ), color = \"red\" ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab2/students/"},{"title":"Lecture 4: Smoothing and Additive 3/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture4/"},{"title":"Lecture 2: Smoothing and Additive 1/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture2/"},{"title":"Lecture 3: Smoothing and Additive 2/3","text":"Slides This lecture is only available to registered students Lecture 2-4 PDF Associated Material Lab 2 Lab 2 solutions","tags":"pages","url":"pages/lecture3/"},{"title":"Lab 1: Setting up environment","text":"Slides PDF PPTX Notebooks R_setup Notes Installation Instructions for JupyterHub","tags":"labs","url":"labs/lab1/"},{"title":"Lab 1: R set up","text":"/*! * * IPython notebook * */ /* CSS font colors for translated ANSI colors. */ .ansibold { font-weight: bold; } /* use dark versions for foreground, to improve visibility */ .ansiblack { color: black; } .ansired { color: darkred; } .ansigreen { color: darkgreen; } .ansiyellow { color: #c4a000; } .ansiblue { color: darkblue; } .ansipurple { color: darkviolet; } .ansicyan { color: steelblue; } .ansigray { color: gray; } /* and light for background, for the same reason */ .ansibgblack { background-color: black; } .ansibgred { background-color: red; } .ansibggreen { background-color: green; } .ansibgyellow { background-color: yellow; } .ansibgblue { background-color: blue; } .ansibgpurple { background-color: magenta; } .ansibgcyan { background-color: cyan; } .ansibggray { background-color: gray; } div.cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; border-radius: 2px; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; border-width: 1px; border-style: solid; border-color: transparent; width: 100%; padding: 5px; /* This acts as a spacer between cells, that is outside the border */ margin: 0px; outline: none; border-left-width: 1px; padding-left: 5px; background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%); } div.cell.jupyter-soft-selected { border-left-color: #90CAF9; border-left-color: #E3F2FD; border-left-width: 1px; padding-left: 5px; border-right-color: #E3F2FD; border-right-width: 1px; background: #E3F2FD; } @media print { div.cell.jupyter-soft-selected { border-color: transparent; } } div.cell.selected { border-color: #ababab; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%); } @media print { div.cell.selected { border-color: transparent; } } div.cell.selected.jupyter-soft-selected { border-left-width: 0; padding-left: 6px; background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%); } .edit_mode div.cell.selected { border-color: #66BB6A; border-left-width: 0px; padding-left: 6px; background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%); } @media print { .edit_mode div.cell.selected { border-color: transparent; } } .prompt { /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */ min-width: 14ex; /* This padding is tuned to match the padding on the CodeMirror editor. */ padding: 0.4em; margin: 0px; font-family: monospace; text-align: right; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; /* Don't highlight prompt number selection */ -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; /* Use default cursor */ cursor: default; } @media (max-width: 540px) { .prompt { text-align: left; } } div.inner_cell { min-width: 0; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_area { border: 1px solid #cfcfcf; border-radius: 2px; background: #f7f7f7; line-height: 1.21429em; } /* This is needed so that empty prompt areas can collapse to zero height when there is no content in the output_subarea and the prompt. The main purpose of this is to make sure that empty JavaScript output_subareas have no height. */ div.prompt:empty { padding-top: 0; padding-bottom: 0; } div.unrecognized_cell { padding: 5px 5px 5px 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.unrecognized_cell .inner_cell { border-radius: 2px; padding: 5px; font-weight: bold; color: red; border: 1px solid #cfcfcf; background: #eaeaea; } div.unrecognized_cell .inner_cell a { color: inherit; text-decoration: none; } div.unrecognized_cell .inner_cell a:hover { color: inherit; text-decoration: none; } @media (max-width: 540px) { div.unrecognized_cell > div.prompt { display: none; } } div.code_cell { /* avoid page breaking on code cells when printing */ } @media print { div.code_cell { page-break-inside: avoid; } } /* any special styling for code cells that are currently running goes here */ div.input { page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.input { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } /* input_area and input_prompt must match in top border and margin for alignment */ div.input_prompt { color: #303F9F; border-top: 1px solid transparent; } div.input_area > div.highlight { margin: 0.4em; border: none; padding: 0px; background-color: transparent; } div.input_area > div.highlight > pre { margin: 0px; border: none; padding: 0px; background-color: transparent; } /* The following gets added to the <head> if it is detected that the user has a * monospace font with inconsistent normal/bold/italic height. See * notebookmain.js. Such fonts will have keywords vertically offset with * respect to the rest of the text. The user should select a better font. * See: https://github.com/ipython/ipython/issues/1503 * * .CodeMirror span { * vertical-align: bottom; * } */ .CodeMirror { line-height: 1.21429em; /* Changed from 1em to our global default */ font-size: 14px; height: auto; /* Changed to auto to autogrow */ background: none; /* Changed from white to allow our bg to show through */ } .CodeMirror-scroll { /* The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/ /* We have found that if it is visible, vertical scrollbars appear with font size changes.*/ overflow-y: hidden; overflow-x: auto; } .CodeMirror-lines { /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */ /* we have set a different line-height and want this to scale with that. */ padding: 0.4em; } .CodeMirror-linenumber { padding: 0 8px 0 4px; } .CodeMirror-gutters { border-bottom-left-radius: 2px; border-top-left-radius: 2px; } .CodeMirror pre { /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */ /* .CodeMirror-lines */ padding: 0; border: 0; border-radius: 0; } /* Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org> Adapted from GitHub theme */ .highlight-base { color: #000; } .highlight-variable { color: #000; } .highlight-variable-2 { color: #1a1a1a; } .highlight-variable-3 { color: #333333; } .highlight-string { color: #BA2121; } .highlight-comment { color: #408080; font-style: italic; } .highlight-number { color: #080; } .highlight-atom { color: #88F; } .highlight-keyword { color: #008000; font-weight: bold; } .highlight-builtin { color: #008000; } .highlight-error { color: #f00; } .highlight-operator { color: #AA22FF; font-weight: bold; } .highlight-meta { color: #AA22FF; } /* previously not defined, copying from default codemirror */ .highlight-def { color: #00f; } .highlight-string-2 { color: #f50; } .highlight-qualifier { color: #555; } .highlight-bracket { color: #997; } .highlight-tag { color: #170; } .highlight-attribute { color: #00c; } .highlight-header { color: blue; } .highlight-quote { color: #090; } .highlight-link { color: #00c; } /* apply the same style to codemirror */ .cm-s-ipython span.cm-keyword { color: #008000; font-weight: bold; } .cm-s-ipython span.cm-atom { color: #88F; } .cm-s-ipython span.cm-number { color: #080; } .cm-s-ipython span.cm-def { color: #00f; } .cm-s-ipython span.cm-variable { color: #000; } .cm-s-ipython span.cm-operator { color: #AA22FF; font-weight: bold; } .cm-s-ipython span.cm-variable-2 { color: #1a1a1a; } .cm-s-ipython span.cm-variable-3 { color: #333333; } .cm-s-ipython span.cm-comment { color: #408080; font-style: italic; } .cm-s-ipython span.cm-string { color: #BA2121; } .cm-s-ipython span.cm-string-2 { color: #f50; } .cm-s-ipython span.cm-meta { color: #AA22FF; } .cm-s-ipython span.cm-qualifier { color: #555; } .cm-s-ipython span.cm-builtin { color: #008000; } .cm-s-ipython span.cm-bracket { color: #997; } .cm-s-ipython span.cm-tag { color: #170; } .cm-s-ipython span.cm-attribute { color: #00c; } .cm-s-ipython span.cm-header { color: blue; } .cm-s-ipython span.cm-quote { color: #090; } .cm-s-ipython span.cm-link { color: #00c; } .cm-s-ipython span.cm-error { color: #f00; } .cm-s-ipython span.cm-tab { background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=); background-position: right; background-repeat: no-repeat; } div.output_wrapper { /* this position must be relative to enable descendents to be absolute within it */ position: relative; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; z-index: 1; } /* class for the output area when it should be height-limited */ div.output_scroll { /* ideally, this would be max-height, but FF barfs all over that */ height: 24em; /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */ width: 100%; overflow: auto; border-radius: 2px; -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8); display: block; } /* output div while it is collapsed */ div.output_collapsed { margin: 0px; padding: 0px; /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } div.out_prompt_overlay { height: 100%; padding: 0px 0.4em; position: absolute; border-radius: 2px; } div.out_prompt_overlay:hover { /* use inner shadow to get border that is computed the same on WebKit/FF */ -webkit-box-shadow: inset 0 0 1px #000; box-shadow: inset 0 0 1px #000; background: rgba(240, 240, 240, 0.5); } div.output_prompt { color: #D84315; } /* This class is the outer container of all output sections. */ div.output_area { padding: 0px; page-break-inside: avoid; /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } div.output_area .MathJax_Display { text-align: left !important; } div.output_area div.output_area div.output_area img, div.output_area svg { max-width: 100%; height: auto; } div.output_area img.unconfined, div.output_area svg.unconfined { max-width: none; } /* This is needed to protect the pre formating from global settings such as that of bootstrap */ .output { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } @media (max-width: 540px) { div.output_area { /* Old browsers */ display: -webkit-box; -webkit-box-orient: vertical; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: vertical; -moz-box-align: stretch; display: box; box-orient: vertical; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: column; align-items: stretch; } } div.output_area pre { margin: 0; padding: 0; border: 0; vertical-align: baseline; color: black; background-color: transparent; border-radius: 0; } /* This class is for the output subarea inside the output_area and after the prompt div. */ div.output_subarea { overflow-x: auto; padding: 0.4em; /* Old browsers */ -webkit-box-flex: 1; -moz-box-flex: 1; box-flex: 1; /* Modern browsers */ flex: 1; max-width: calc(100% - 14ex); } div.output_scroll div.output_subarea { overflow-x: visible; } /* The rest of the output_* classes are for special styling of the different output types */ /* all text output has this class: */ div.output_text { text-align: left; color: #000; /* This has to match that of the the CodeMirror class line-height below */ line-height: 1.21429em; } /* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */ div.output_stderr { background: #fdd; /* very light red background for stderr */ } div.output_latex { text-align: left; } /* Empty output_javascript divs should have no height */ div.output_javascript:empty { padding: 0; } .js-error { color: darkred; } /* raw_input styles */ div.raw_input_container { line-height: 1.21429em; padding-top: 5px; } pre.raw_input_prompt { /* nothing needed here. */ } input.raw_input { font-family: monospace; font-size: inherit; color: inherit; width: auto; /* make sure input baseline aligns with prompt */ vertical-align: baseline; /* padding + margin = 0.5em between prompt and cursor */ padding: 0em 0.25em; margin: 0em 0.25em; } input.raw_input:focus { box-shadow: none; } p.p-space { margin-bottom: 10px; } div.output_unrecognized { padding: 5px; font-weight: bold; color: red; } div.output_unrecognized a { color: inherit; text-decoration: none; } div.output_unrecognized a:hover { color: inherit; text-decoration: none; } .rendered_html { color: #000; /* any extras will just be numbers: */ } .rendered_html :link { text-decoration: underline; } .rendered_html :visited { text-decoration: underline; } .rendered_html h1:first-child { margin-top: 0.538em; } .rendered_html h2:first-child { margin-top: 0.636em; } .rendered_html h3:first-child { margin-top: 0.777em; } .rendered_html h4:first-child { margin-top: 1em; } .rendered_html h5:first-child { margin-top: 1em; } .rendered_html h6:first-child { margin-top: 1em; } .rendered_html * + ul { margin-top: 1em; } .rendered_html * + ol { margin-top: 1em; } .rendered_html pre, .rendered_html tr, .rendered_html th, .rendered_html td, .rendered_html * + table { margin-top: 1em; } .rendered_html * + p { margin-top: 1em; } .rendered_html * + img { margin-top: 1em; } .rendered_html img, .rendered_html img.unconfined, div.text_cell { /* Old browsers */ display: -webkit-box; -webkit-box-orient: horizontal; -webkit-box-align: stretch; display: -moz-box; -moz-box-orient: horizontal; -moz-box-align: stretch; display: box; box-orient: horizontal; box-align: stretch; /* Modern browsers */ display: flex; flex-direction: row; align-items: stretch; } @media (max-width: 540px) { div.text_cell > div.prompt { display: none; } } div.text_cell_render { /*font-family: \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;*/ outline: none; resize: none; width: inherit; border-style: none; padding: 0.5em 0.5em 0.5em 0.4em; color: #000; box-sizing: border-box; -moz-box-sizing: border-box; -webkit-box-sizing: border-box; } a.anchor-link:link { text-decoration: none; padding: 0px 20px; visibility: hidden; } h1:hover .anchor-link, h2:hover .anchor-link, h3:hover .anchor-link, h4:hover .anchor-link, h5:hover .anchor-link, h6:hover .anchor-link { visibility: visible; } .text_cell.rendered .input_area { display: none; } .text_cell.rendered .text_cell.unrendered .text_cell_render { display: none; } .cm-header-1, .cm-header-2, .cm-header-3, .cm-header-4, .cm-header-5, .cm-header-6 { font-weight: bold; font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif; } .cm-header-1 { font-size: 185.7%; } .cm-header-2 { font-size: 157.1%; } .cm-header-3 { font-size: 128.6%; } .cm-header-4 { font-size: 110%; } .cm-header-5 { font-size: 100%; font-style: italic; } .cm-header-6 { font-size: 100%; font-style: italic; } .highlight .hll { background-color: #ffffcc } .highlight { background: #f8f8f8; } .highlight .c { color: #408080; font-style: italic } /* Comment */ .highlight .err { border: 1px solid #FF0000 } /* Error */ .highlight .k { color: #008000; font-weight: bold } /* Keyword */ .highlight .o { color: #666666 } /* Operator */ .highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */ .highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */ .highlight .cp { color: #BC7A00 } /* Comment.Preproc */ .highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */ .highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */ .highlight .cs { color: #408080; font-style: italic } /* Comment.Special */ .highlight .gd { color: #A00000 } /* Generic.Deleted */ .highlight .ge { font-style: italic } /* Generic.Emph */ .highlight .gr { color: #FF0000 } /* Generic.Error */ .highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */ .highlight .gi { color: #00A000 } /* Generic.Inserted */ .highlight .go { color: #888888 } /* Generic.Output */ .highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */ .highlight .gs { font-weight: bold } /* Generic.Strong */ .highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */ .highlight .gt { color: #0044DD } /* Generic.Traceback */ .highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */ .highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */ .highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */ .highlight .kp { color: #008000 } /* Keyword.Pseudo */ .highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */ .highlight .kt { color: #B00040 } /* Keyword.Type */ .highlight .m { color: #666666 } /* Literal.Number */ .highlight .s { color: #BA2121 } /* Literal.String */ .highlight .na { color: #7D9029 } /* Name.Attribute */ .highlight .nb { color: #008000 } /* Name.Builtin */ .highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */ .highlight .no { color: #880000 } /* Name.Constant */ .highlight .nd { color: #AA22FF } /* Name.Decorator */ .highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */ .highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */ .highlight .nf { color: #0000FF } /* Name.Function */ .highlight .nl { color: #A0A000 } /* Name.Label */ .highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */ .highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */ .highlight .nv { color: #19177C } /* Name.Variable */ .highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */ .highlight .w { color: #bbbbbb } /* Text.Whitespace */ .highlight .mb { color: #666666 } /* Literal.Number.Bin */ .highlight .mf { color: #666666 } /* Literal.Number.Float */ .highlight .mh { color: #666666 } /* Literal.Number.Hex */ .highlight .mi { color: #666666 } /* Literal.Number.Integer */ .highlight .mo { color: #666666 } /* Literal.Number.Oct */ .highlight .sa { color: #BA2121 } /* Literal.String.Affix */ .highlight .sb { color: #BA2121 } /* Literal.String.Backtick */ .highlight .sc { color: #BA2121 } /* Literal.String.Char */ .highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */ .highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */ .highlight .s2 { color: #BA2121 } /* Literal.String.Double */ .highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */ .highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */ .highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */ .highlight .sx { color: #008000 } /* Literal.String.Other */ .highlight .sr { color: #BB6688 } /* Literal.String.Regex */ .highlight .s1 { color: #BA2121 } /* Literal.String.Single */ .highlight .ss { color: #19177C } /* Literal.String.Symbol */ .highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */ .highlight .fm { color: #0000FF } /* Name.Function.Magic */ .highlight .vc { color: #19177C } /* Name.Variable.Class */ .highlight .vg { color: #19177C } /* Name.Variable.Global */ .highlight .vi { color: #19177C } /* Name.Variable.Instance */ .highlight .vm { color: #19177C } /* Name.Variable.Magic */ .highlight .il { color: #666666 } /* Literal.Number.Integer.Long */ /* Temporary definitions which will become obsolete with Notebook release 5.0 */ .ansi-black-fg { color: #3E424D; } .ansi-black-bg { background-color: #3E424D; } .ansi-black-intense-fg { color: #282C36; } .ansi-black-intense-bg { background-color: #282C36; } .ansi-red-fg { color: #E75C58; } .ansi-red-bg { background-color: #E75C58; } .ansi-red-intense-fg { color: #B22B31; } .ansi-red-intense-bg { background-color: #B22B31; } .ansi-green-fg { color: #00A250; } .ansi-green-bg { background-color: #00A250; } .ansi-green-intense-fg { color: #007427; } .ansi-green-intense-bg { background-color: #007427; } .ansi-yellow-fg { color: #DDB62B; } .ansi-yellow-bg { background-color: #DDB62B; } .ansi-yellow-intense-fg { color: #B27D12; } .ansi-yellow-intense-bg { background-color: #B27D12; } .ansi-blue-fg { color: #208FFB; } .ansi-blue-bg { background-color: #208FFB; } .ansi-blue-intense-fg { color: #0065CA; } .ansi-blue-intense-bg { background-color: #0065CA; } .ansi-magenta-fg { color: #D160C4; } .ansi-magenta-bg { background-color: #D160C4; } .ansi-magenta-intense-fg { color: #A03196; } .ansi-magenta-intense-bg { background-color: #A03196; } .ansi-cyan-fg { color: #60C6C8; } .ansi-cyan-bg { background-color: #60C6C8; } .ansi-cyan-intense-fg { color: #258F8F; } .ansi-cyan-intense-bg { background-color: #258F8F; } .ansi-white-fg { color: #C5C1B4; } .ansi-white-bg { background-color: #C5C1B4; } .ansi-white-intense-fg { color: #A1A6B2; } .ansi-white-intense-bg { background-color: #A1A6B2; } .ansi-bold { font-weight: bold; } In [ ]: #---------Test Imports------------- import numpy as np import keras import gensim import nltk keras . layers . Dense ( 20 ) In [ ]: #-------Download R packages--------- ## these two lines for JupyterHub only #import os #os.environ['R_HOME'] = \"/usr/share/anaconda3/lib/R\" import rpy2 from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) package_list = [ 'aplpack' , 'cluster' , 'codetools' , 'dbscan' , 'factoextra' , 'gam' , 'ggplot2' , 'splines' , 'TeachingDemos' ] for name in package_list : r_utils . install_packages ( name ) import rpy2 from rpy2.robjects.packages import importr r_utils = importr ( 'utils' ) package_list = [ 'aplpack' , 'cluster' , 'codetools' , 'dbscan' , 'factoextra' , 'gam' , 'ggplot2' , 'splines' , 'TeachingDemos' ] for name in package_list : r_utils . install_packages ( name ) if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML'; mathjaxscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: 'center',\" + \" displayIndent: '0em',\" + \" showMathMenu: true,\" + \" tex2jax: { \" + \" inlineMath: [ ['$','$'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" linebreaks: { automatic: true, width: '95% container' }, \" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }\" + \" } \" + \"}); \"; (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","tags":"labs","url":"labs/lab1/Rset/"},{"title":"Lecture 1:  Introduction, Review of 109A and preview of 109B","text":"Slides PDF PPTX","tags":"lectures","url":"lectures/lecture1/"},{"title":"Lecture 24","text":"Lecture 24","tags":"pages","url":"pages/lecture24/"},{"title":"Lecture 25","text":"Lecture 25","tags":"pages","url":"pages/lecture25/"},{"title":"CS 109B: Advanced Topics in Data Science","text":"Spring 2019 Pavlos Protopapas and Mark Glickman pavlos@seas.harvard.edu glickman@fas.harvard.edu Pavlos: Mondays 3-4pm at MD G108 Mark: By appointment Head TFs: Eleni Kaxiras eleni@seas.harvard.edu Head TF for DCE: Sol Girouard solgirouard@g.harvard.edu Lectures: Mon and Wed 1:30‐2:45pm in Maxwell-Dworkin G-115 Labs: Thur 4:30-6:00pm in Pierce 301 Advanced Sections: Wed. 3:00pm-4:15pm, location TBD (starting 2/13) Prerequisites: CS 109a, AC 209a, Stat 121a, CSCI E-109a or equivalent. Data Science 2 is the second half of a one-year introduction to data science. Building upon the material in Data Science 1, the course introduces advanced methods for data wrangling, data visualization, and deep neural networks, statistical modeling, and prediction. Topics include big data and database management, multiple deep learning subjects such as CNNs, RNNs, autoencoders, and generative models as well as basic Bayesian methods, nonlinear statistical models and unsupervised learning. Announcements: NOTE: The Modules have concluded. There is no class on Wed. HAPPY PROJECTS! Module 1: A Real-Bogus Classifier (1:30 - 2:45pm) - Mon. 4/22, and Wed. 4/24 in NW B-103? Module 2 : Microbiome (1:30 - 2:45pm) - Mon. 4/22, Wed. 4/24, and Mon. 4/29 in MD-115 Due Dates for the Final Project/Modules deliverables 4/17 - Milestone #1 4/27 - Milestone #2 5/12 - Peer Evaluation 5/12 - Milestone #3 (Final) 5/13 and 5/14 - Ignite Talks Presentation (each group will choose ONE date of the two) Instructions for using JupyterHub: Instructions for Using SEAS JupyterHub Video-recorded Lectures from CS109A Fall '18 Advanced Sections take place in NW B-103 Pierce Hall is at 29 Oxford St in Cambridge. Maxwell Dworkin (MD) is at 33 Oxford St, Cambridge. Northwest Building (NW) is at 52 Oxford St, Cambridge. HELPLINE: cs109b2019@gmail.com Office Hours : Weekly Schedule For enrollment issues including cross-registration: contact the FAS Registrar's Office either in person at the Smith Campus Center (1350 Massachusetts Avenue, Suite 450) or by sending an email to registrar@fas.harvard.ed Previous Material: 2018 pre { background-color: #F5F5F5; display: block; font-family: monospace; font-size: 14px; white-space: pre; border-color: #999999; border-width: 1px; border-style: solid; border-radius: 6px; margin: 1em 0; padding: 5px; white-space: pre-wrap; } .containerMain { display: flex; width: 100%; height: 300px; } .contentA { flex: 1; flex-direction:column; } .contentB { flex: 3; }","tags":"pages","url":"pages/cs-109b-advanced-topics-in-data-science/"}]}